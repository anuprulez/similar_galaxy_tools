,description,edam_topics,help,id,inputs,name,outputs
0,,,Given a FASTA contig file or a genbank file  ABRicate will perform a mass screening of contigs and identify the presence of antibiotic resistance genes  The user can choose which database to search from a list of available AMR databases ,abricate,"fasta,genbank,embl",ABRicate,tabular
1,,,ABRicate List will list all the antibiotic databases used by ABRicate  The database of these genes is built from ResFinder      ,abricate_list,,ABRicate List,txt
2,de novo sequence assembler,, ABySS   is a de novo sequence assembler intended for short paired end reads and large genomes ,abyss-pe,"fasta,fastq,fastqsanger,fastqillumina",ABySS,"fasta,tabular"
3,Linkage and Haplotype analysis,, Allegro is a computer program for multipoint genetic linkage analysis and related calculations  Allegro can do both classical parametric linkage analysis and analysis based on allele sharing models  In addition  Allegro estimates total number of recombinations between markers  computes posterior IBD sharing probabilities  re constructs haplotypes and does two types of simulation  Thus Allegro includes the basic functionality of the well known Genehunter program  Kruglyak et al  1996   It can analyse pedigrees of moderate size and it can handle many markers  The biggest advantages of Allegro over Genehunterar the allele sharing models that it provides and a much shorter execution time      ,allegro,"linkage_pedin,linkage_recomb,linkage_map,txt",Allegro,"allegro_haplo,allegro_linkage,allegro_descent,txt"
4,annotate a generic set of identifiers,,This tool can get annotation for a generic set of IDs  using the Bioconductor  annotation data packages  Supported organisms are human  mouse  fruit fly and zebrafish  The org db packages that are used here are primarily based on mapping using Entrez Gene identifiers  More information on the annotation packages can be found at the Bioconductor website  for example  information on the human annotation package  org Hs eg db  can be found here  ,annotatemyids,tabular,annotateMyIDs,"tabular,txt"
5,simulates pyrosequencing data,, Art 454 Pyrosequencing Simulator                                   ART 454 is a simulation program to generate sequence read data of Roche 454 Pyrosequencing sequencers  ART generates reads according to the empirical read quality profile and the calibrated error profile of uncall overcall homopolymers from real 454 read data  ART has been using for testing or benchmarking a variety of method or tools for next generation sequencing data analysis  including read alignment  de novo assembly  detection of SNP  CNV  or other structure variation   art 454 can generate both single end and paired end of 454 sequencing platform  Besides for regular genome DNA and cDNA sequencing simulation  art 454 also supports amplicon sequencing  The reference sequences can be either DNA or RNA        ,art_454,fasta,ART 454,"fastq,sam,aln"
6,simulates sequencing data,, Art Illumina Simulator                         ART  art Illumina Q version  is a simulation program to generate sequence read data of Illumina sequencers  ART generates reads according to the empirical read quality profile summarized from large real read data  ART has been using for testing or benchmarking a variety of methods or tools for next generation sequencing data analysis  including read alignment  de novo assembly  detection of SNP  CNV  or other structure variation   art Illumina can generate single end  paired end   mate pair reads  and amplicon sequencing simulation of Illumina sequencing platform  Its outputs include FASTQ read  ALN and or SAM alignment files         ,art_illumina,fasta,ART Illumina,"fastq,sam,aln"
7,simulates SOLiD data,, Art SOLiD Simulator                      ART SOLiD  is a simulation program to generate sequence read data of SOLiD sequencing reads  ART generates reads according to a SOLiD read error profile  The built in error profile is an empiricial error profile summarized from large SOLiD sequencing data  ART has been using for testing or benchmarking a variety of method or tools for next generation sequencing data analysis  including read alignment  de novo assembly  detection of SNP  CNV  or other structure variation   art SOLiD can generate both single end  matepair  and paired end of SOLiD sequencing platform  art SOLiD also support amplicon sequencing simulation with RNA references        ,art_solid,fasta,ART SOLiD,"fastq,sam"
8,gene prediction for prokaryotic and eukaryotic genomes,,AUGUSTUS is a gene prediction program for prokaryotes and eukaryotes written by Mario Stanke and Oliver Keller  It can be used as an ab initio program  which means it bases its prediction purely on the sequence  AUGUSTUS may also incorporate hints on the gene structure coming from extrinsic sources such as EST  MS MS  protein alignments and synthenic genomic alignments ,augustus,"fasta,augustus",Augustus,"gtf,fasta"
9,ab-initio gene predictor,,         This tool allows to train Augustus  the ab initio gene predictor  based on a previous prediction  e g  made with Maker       ,augustus_training,"fasta,gff",Train Augustus,augustus
10,,,Converts BAM data to ScIdx  the Strand specific coordinate count format  which is used by tools within the Chip exo Galaxy flavor   ScIdx files are 1 based   The format consists of 5 columns  the chromosome  the position of the genomic coordinate  the number of tags on the forward strand  the number of tags on the reverse strand and the number of total tags on the position   With pair end reads  only the 5  end of READ1 will be used to create the ScIdx data file   Tools that use this format include GeneTrack and MultiGPS ,bam_to_scidx,bam,Convert BAM to ScIdx,scidx
11,Locate ribosomal RNA's in a fasta file. (GFF output),,    barrnap    barrnap  predicts the location of 5S  16S and 23S ribosomal RNA genes in Bacterial genome sequences  Barrnap now supports Archaea  Eukaryota and Mitochondria  It takes FASTA DNA sequence as input  and write GFF3 as output  It uses the new NHMMER tool that comes with HMMER 3 1 dev for HMM searching in DNA DNA style  NHMMER binaries for 64 bit Linux and Mac OS X are included and will be auto detected  Multithreading is supported and one can expect roughly linear speed ups with more CPUs  This tool is designed to be a substitute for RNAmmer  It was motivated by my desire to remove Prokka s dependency on RNAmmer which is encumbered by an free for academic sign up license  and by the needed legacy HMMER 2 x which conflicts with HMMER 3 x that most people are using now   RNAmmer is more sophisticated than Barrnap  and more accurate  because it uses HMMER 2 x in glocal alignment mode  whereas HMMER 3 x currently only supports local alignment  Sean Eddy expects glocal to be supported in 2014   In practice  Barrnap will find all the typical 5 16 23S genes in bacteria  but may get the end points out by a few bases and will probably miss wierd rRNAs  The HMM models it uses are derived from RFAM  Silva  and GreenGenes   The name Barrnap is derived from BActerial Ribosomal RNA Predictor  It was spawned at CodeFest 2013 in Berlin  Germany by Torsten Seemann and Tim Booth       barrnap      Inputs Parameters     Fasta file   The fasta file whose contents you want to search for ribosomal RNA s    Kingdom   Select the Kingdom of the organism  Bacteria  Eukarote  Mitochondria or Archaea    Length cutoff   Proportional length threshold to tag a possible rRNA as pseudo    Reject length threshold   Proportional length threshold to reject prediction   E value   Similarity cutoff e value    Include Sequences in GFF   This includes the original fasta sequence in the GFF file below the  FASTA tag  ,barrnap,fasta,barrnap,gff3
12,Detecting natural selection from population-based genetic data,,This program  BayeScan aims at identifying candidate loci under natural selection from genetic data  using differences in allele frequencies between populations ,BayeScan,"tabular,txt",BayeScan,txt
13,Annotate and edit VCF/BCF files,,                                     bcftools  EXECUTABLE                                      Annotate and edit VCF BCF files   Examples         Remove three fields     bcftools annotate  x ID INFO DP FORMAT DP file vcf gz        Remove all INFO fields and all FORMAT fields except for GT and PL     bcftools annotate  x INFO  FORMAT GT FORMAT PL file vcf        Add ID  QUAL and INFO TAG  not replacing TAG if already present     bcftools annotate  a src bcf  c ID QUAL  TAG dst bcf        Carry over all INFO and FORMAT annotations except FORMAT GT     bcftools annotate  a src bcf  c INFO  FORMAT GT dst bcf        Annotate from a tab delimited file with six columns  the fifth is ignored         first indexing with tabix  The coordinates are 1 based      tabix  s1  b2  e2 annots tab gz     bcftools annotate  a annots tab gz  h annots hdr  c CHROM POS REF ALT   TAG file vcf        Annotate from a tab delimited file with regions  1 based coordinates  inclusive      tabix  s1  b2  e3 annots tab gz     bcftools annotate  a annots tab gz  h annots hdr  c CHROM FROM TO TAG inut vcf        Annotate from a bed file  0 based coordinates  half closed  half open intervals      bcftools annotate  a annots bed gz  h annots hdr  c CHROM FROM TO TAG input vcf   REGIONS HELP   EXPRESSIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,"vcf,tabular,bed,txt,tabular",bcftools @EXECUTABLE@,
14,SNP/indel variant calling from VCF/BCF,,                                     bcftools  EXECUTABLE                                      SNP indel variant calling from VCF BCF  To be used in conjunction with samtools mpileup        This command replaces the former  bcftools view  caller       Some of the original functionality has been temporarily lost in the process of transition to htslib  but will be added back on popular demand       The original calling model can be invoked with the  c option   The novel rate option can be set to modify the likelihood of novel mutation for constrained  C trio calling  The trio genotype calling maximizes likelihood of a particular combination of genotypes for father  mother and the child P F i M j C k    P unconstrained    Pn   P constrained     1 Pn   By providing three values  the mutation rate Pn is set explicitly for SNPs  deletions and insertions  respectively  If two values are given  the first is interpreted as the mutation rate of SNPs and the second is used to calculate the mutation rate of indels according to their length as Pn float exp  a b len   where a 22 8689  b 0 2994 for insertions and a 21 9313  b 0 2856 for deletions  pubmed 23975140   If only one value is given  the same mutation rate Pn is used for SNPs and indels      REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,tabular,bcftools @EXECUTABLE@,
15,"Copy number variation caller, requires Illumina's B-allele frequency (BAF) and Log R Ratio intensity (LRR)",,                                        bcftools  EXECUTABLE                                         Copy number variation caller  requires Illumina s B allele frequency  BAF  and Log R Ratio intensity  LRR    The HMM considers the following copy number states  CN 2  normal   1  single copy loss   0  complete loss   3  single copy gain    REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,fasta,bcftools @EXECUTABLE@,tabular
16,Concatenate or combine VCF/BCF files,,                                        bcftools  EXECUTABLE  plugin                                        Concatenate or combine VCF BCF files  All source files must have the same sample columns appearing in the same order  The program can be used  for example  to concatenate chromosome VCFs into one VCF  or combine a SNP VCF and an indel VCF into one  The input files must be sorted by chr and position  The files must be given in the correct order to produce sorted VCF on output unless the  a    allow overlaps option is specified    Naive concatenation is useful when using a galaxy workflow that splits a BAM file by chromosome  processes each in parallel  then bcftools concat merges the results into a single VCF file    BAM    bamtools split    bcftools mpileup    bcftools call    bcftools concat    VCF    REGIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,,bcftools @EXECUTABLE@,
17,Create consensus sequence by applying VCF variants to a reference fasta file,,                                        bcftools  EXECUTABLE  plugin                                         Create consensus sequence by applying VCF variants to a reference fasta file    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,tabular,bcftools @EXECUTABLE@,"fasta,txt"
18,Converts VCF/BCF to IMPUTE2/SHAPEIT formats,,                                        bcftools  EXECUTABLE  from vcf                                        Converts VCF BCF to other formats  See man page for file formats details     REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@_from_vcf,,bcftools @EXECUTABLE@ from vcf,tabular
19,Converts other formats to VCF/BCFk,,                                        bcftools  EXECUTABLE  plugin                                        Converts other variant formats to vcf   See man page for file formats details    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@_to_vcf,"tabular,gvcf",bcftools @EXECUTABLE@ to vcf,
20,Haplotype aware consequence predictor,,                                        bcftools  EXECUTABLE                                         Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records  SNPs separated by an intron  but adjacent in the spliced transcript  or nearby frame shifting indels which in combination in fact are not frame shifting   The output VCF is annotated with INFO BCSQ and FORMAT BCSQ tag  configurable with the  c option   The latter is a bitmask of indexes to INFO BCSQ  with interleaved haplotypes  See the usage examples below for using the  TBCSQ converter in query for extracting a more human readable form from this bitmask  The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT BCSQ tags  By default this is 16  but if more are required  see the   ncsq option   The program requires on input a VCF BCF file  the reference genome in fasta format    fasta ref  and genomic features in the GFF3 format downloadable from the Ensembl website    gff annot   and outputs an annotated VCF BCF file  Currently  only Ensembl GFF3 files are supported   By default  the input VCF should be phased  If phase is unknown  or only partially known  the   phase option can be used to indicate how to handle unphased data  Alternatively  haplotype aware calling can be turned off with the   local csq option   If conflicting  overlapping  variants within one haplotype are detected  a warning will be emitted and predictions will be based on only the first variant in the analysis   Symbolic alleles are not supported  They will remain unannotated in the output VCF and are ignored for the prediction analysis     REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,gff3,bcftools @EXECUTABLE@,
21,Apply fixed-threshold filters,,                                        bcftools  EXECUTABLE                                         Apply fixed threshold filters    REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP     BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,,bcftools @EXECUTABLE@,
22,Check sample identity,,                                        bcftools  EXECUTABLE                                         Check sample identity  With no  g BCF given  multi sample cross check is performed    REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI        ,bcftools_@EXECUTABLE@,"vcf,bcf",bcftools @EXECUTABLE@,tabular
23,"Create intersections, unions and complements of VCF files",,                                        bcftools  EXECUTABLE                                         Create intersections  unions and complements of VCF files    COLLAPSE HELP   REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,,bcftools @EXECUTABLE@,
24,Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file,,                                        bcftools  EXECUTABLE                                          Merge multiple VCF BCF files from non overlapping sample sets to create one multi sample file    Note that only records from different files can be merged  never from the same file   For  vertical  merge take a look at  bcftools norm  instead    REGIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,vcf,bcftools @EXECUTABLE@,
25,Generate VCF or BCF containing genotype likelihoods for one or multiple alignment (BAM or CRAM) files,,                                        bcftools  EXECUTABLE                                         Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records  SNPs separated by an intron  but adjacent in the spliced transcript  or nearby frame shifting indels which in combination in fact are not frame shifting   The output VCF is annotated with INFO BCSQ and FORMAT BCSQ tag  configurable with the  c option   The latter is a bitmask of indexes to INFO BCSQ  with interleaved haplotypes  See the usage examples below for using the  TBCSQ converter in query for extracting a more human readable form from this bitmask  The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT BCSQ tags  By default this is 16  but if more are required  see the   ncsq option   The program requires on input a VCF BCF file  the reference genome in fasta format    fasta ref  and genomic features in the GFF3 format downloadable from the Ensembl website    gff annot   and outputs an annotated VCF BCF file  Currently  only Ensembl GFF3 files are supported   By default  the input VCF should be phased  If phase is unknown  or only partially known  the   phase option can be used to indicate how to handle unphased data  Alternatively  haplotype aware calling can be turned off with the   local csq option   If conflicting  overlapping  variants within one haplotype are detected  a warning will be emitted and predictions will be based on only the first variant in the analysis   Symbolic alleles are not supported  They will remain unannotated in the output VCF and are ignored for the prediction analysis     REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,"bam,cram,fasta,txt",bcftools @EXECUTABLE@,
26,Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows,,                                        bcftools  EXECUTABLE                                          Left align and normalize indels  check if REF alleles match the reference  split multiallelic sites into multiple rows  recover multiallelics from multiple rows    REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,,bcftools @EXECUTABLE@,
27,"plugin Color shared chromosomal segments, requires phased GTs",,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP    ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,svg
28,"plugin  counts number of samples, SNPs, INDELs, MNPs and total sites",,                                        bcftools  EXECUTABLE  plugin                                        Counts number of samples  SNPs  INDELs  MNPs and total number of sites    REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP         ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,tabular
29,plugin genotype dosage,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,tabular
30,plugin Fill INFO fields AN and AC,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,
31,"plugin Set INFO tags AF, AN, AC, AC_Hom, AC_Het, AC_Hemi",,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,
32,plugin  Fix ploidy,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,tabular,bcftools @EXECUTABLE@,
33,plugin Annotate frameshift indels,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,bed,bcftools @EXECUTABLE@,
34,plugin Add imputation information metrics to the INFO field,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,
35,plugin Count Mendelian consistent / inconsistent genotypes,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,txt,bcftools @EXECUTABLE@,
36,plugin Set missing genotypes,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,
37,plugin Sets genotypes,,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,
38,"plugin Convert between similar tags, such as GL and GP",,                                        bcftools  EXECUTABLE  plugin                                         REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP       ,bcftools_plugin_@PLUGIN_ID@,,bcftools @EXECUTABLE@,
39,Extracts fields from VCF/BCF file and prints them in user-defined format,,                                         bcftools  EXECUTABLE                                         Extracts fields from VCF BCF file and prints them in user defined format    Format                CHROM            The CHROM column  similarly also other columns  POS  ID  REF  ALT  QUAL  FILTER         INFO TAG         Any tag in the INFO column        TYPE             Variant type  REF  SNP  MNP  INDEL  OTHER         MASK             Indicates presence of the site in other files  with multiple files         TAG INT          Curly brackets to subscript vectors  0 based         FIRST ALT        Alias for  ALT 0                          The brackets loop over all samples        GT               Genotype  e g  0 1         TBCSQ            Translated FORMAT BCSQ  See the csq command above for explanation and examples         TGT              Translated genotype  e g  C A         IUPACGT          Genotype translated to IUPAC ambiguity codes  e g  M instead of C A         LINE             Prints the whole line        SAMPLE           Sample name        POS0             POS in 0 based coordinates        END              End position of the REF allele        END0             End position of the REF allele in 0 based cordinates        n                new line        t                tab character     Examples               Print chromosome  position  ref allele and the first alternate allele     bcftools query  f   CHROM   POS   REF   ALT 0  n  file vcf gz        Similar to above  but use tabs instead of spaces  add sample name and genotype     bcftools query  f   CHROM t POS t REF t ALT  t SAMPLE  GT  n  file vcf gz        Print FORMAT GT fields followed by FORMAT GT fields     bcftools query  f  GQ    GQ   t GT    GT  n  file vcf        Make a BED file  chr  pos  0 based   end pos  1 based   id     bcftools query  f  CHROM t POS0 t END t ID n  file bcf    COLLAPSE HELP   REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,,bcftools @EXECUTABLE@,txt
40,in VCF/BCF file,,                                        bcftools List Samples  EXECUTABLE                                         Lists Samples from a VCF BCF file   BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@_list_samples,,bcftools List Samples,tabular
41,"Modify header of VCF/BCF files, change sample names",,                                         bcftools  EXECUTABLE                                         Modify header of VCF BCF files  change sample names    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,"vcf,tabular",bcftools @EXECUTABLE@,
42,HMM model for detecting runs of homo/autozygosity,,                                        bcftools  EXECUTABLE                                         HMM model for detecting runs of autozygosity    REGIONS HELP   TARGETS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI      ,bcftools_@EXECUTABLE@,data,bcftools @EXECUTABLE@,tabular
43,Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats,,                                        bcftools  EXECUTABLE                                         Parses VCF or BCF and produces stats which can be plotted using plot vcfstats    When two files are given  the program generates separate stats for intersection and the complements   By default only sites are compared   s  S must given to include also sample columns    COLLAPSE HELP   REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI   ,bcftools_@EXECUTABLE@,tabular,bcftools @EXECUTABLE@,"txt,pdf"
44,"VCF/BCF conversion, view, subset and filter VCF/BCF files",,                                        bcftools  EXECUTABLE                                         VCF BCF conversion  view  subset and filter VCF BCF files    REGIONS HELP   TARGETS HELP   EXPRESSIONS HELP    BCFTOOLS MANPAGE   EXECUTABLE    BCFTOOLS WIKI       ,bcftools_@EXECUTABLE@,,bcftools @EXECUTABLE@,
45,from regular barcodes.,,  bctools   Create binary barcodes from regular barcodes                                                         This tool converts standard nucleotide codes to the IUPAC nucleotide codes used for binary barcodes  A and G are converted to nucleotide code R  T  U and C are converted to Y   Input        The input for this tool is a FASTQ file   Output         This tool produces a single FASTQ file containing the converted barcodes       ,bctools_convert_to_binary_barcode,fastq,Create binary barcodes,fastq
46,from full alignments,,  bctools   Get crosslinked nucleotides from full alignments                                                             Given coordinates of aligned reads in BED format  calculate positions of the crosslinked nucleotides  Crosslinked nts are assumed to be one nt upstream of the 5  end of the read   Input          six column BED file containing coordinates of aligned reads  Output           six column BED file containing coordinates of crosslinking events      ,bctools_extract_crosslinked_nucleotides,bed,Get crosslinked nucleotides,bed
47,from SAM or BAM,,  bctools   Extract alignment ends from from SAM or BAM alignments                                                                   The resulting BED file contains the outer coordinates of the alignments  The BED name field is set to the read id and the score field is set to the edit distance of the alignment  The crosslinked nucleotide is one nt upstream of the 5  end of the BED entries   This tool only reports results for alignments that are properly aligned in FR   forward reverse   direction   Input            BAM file containing alignments  paired end sequencing   Output             BED file containing outer coordinates  sorted by read id       ,bctools_extract_alignment_ends,"sam,bam",Extract alignment ends,bed
48,according to pattern,,  bctools   Extract barcodes according to pattern                                                  Exract barcodes from a FASTQ file according to a user specified pattern and write them to a separate FASTQ file       ,bctools_extract_barcodes,fastq,Extract barcodes,fastq
49,according to UMIs,,  bctools   Merge PCR duplicates according to UMIs                                                   Merge PCR duplicates according to unique molecular identifier  UMI  library  All alignments with same outer coordinates and barcode will be merged into a single crosslinking event   Barcodes containing uncalled base  N  are removed   Input            BED6 file containing alignments with FASTQ read id in name field   FASTQ library of UMIs  Output             BED6 file with a read id from a representative alignment in the name field and number of PCR duplicates as score  sorted by fields chrom  start  stop  strand  name      ,bctools_merge_pcr_duplicates,"bed,fastq",Merge PCR duplicates,bed
50,from FASTQ,,  bctools   Remove 3  end nts from FASTQ                                         Remove a certain number of nucleotides from the 3  tails of sequences in FASTQ format       ,bctools_remove_tail,fastq,Remove 3'-end nts,fastq
51,crosslinking events,,  bctools   Remove spurious events originating from errors in unique molecular identifiers  UMIs                                                                                                   This tool compares all events sharing the same coordinates  Among each group of events the maximum number of PCR duplicates is determined  By default  all events that are supported by less than 10 percent of this maximum count are removed   Input          BED6 containing crosslinking events with score field set to number of PCR duplicates  Output           BED6 with spurious crosslinking events removed  sorted by fields chrom  start  stop  strand      ,bctools_remove_spurious_events,bed,Remove spurious,bed
52,annotate coverage of features from multiple files,,bedtools annotate  well  annotates one BED VCF GFF file with the coverage and number of overlaps observed from multiple other BED VCF GFF files  In this way  it allows one to ask to what degree one feature coincides with multiple other feature types with a single command ,bedtools_annotatebed,"bed,vcf,gff,gff3,bed",AnnotateBed,bed
53,converter,,bedtools bamtobed is a conversion utility that converts sequence alignments in BAM format into BED  BED12  and or BEDPE records ,bedtools_bamtobed,bam,BAM to BED,bed
54,,,bedtools bamtofastq is a conversion utility for extracting FASTQ records from sequence alignments in BAM format ,bedtools_bamtofastq,bam,Convert from BAM to FastQ,fastq
55,converter,,bed12ToBed6 is a convenience tool that converts BED features in BED12  a k a   blocked  BED features such as genes  to discrete BED6 features  For example  in the case of a gene with six exons  bed12ToBed6 would create six separate BED6 features  i e   one for each exon  ,bedtools_bed12tobed6,bed,BED12 to BED6,bed
56,converter,,bedToBam converts features in a feature file to BAM format  This is useful as an efficient means of storing large genome annotations in a compact  indexed format for visualization purposes ,bedtools_bedtobam,bed,BED to BAM,bam
57,create batch script for taking IGV screenshots,,Creates a batch script to create IGV images at each interval defined in a BED GFF VCF file ,bedtools_bedtoigv,"bed,gff,gff3,vcf",BED to IGV,txt
58,converter,,Converts feature records to BAM format ,bedtools_bedpetobam,"bed,gff,vcf",BEDPE to BAM,bam
59,"find the closest, potentially non-overlapping interval",,Similar to intersectBed  closestBed searches for overlapping features in A and B  In the event that no feature in B overlaps the current feature in A  closestBed will report the closest  that is  least genomic distance from the start or end of A  feature in B  For example  one might want to find which is the closest gene to a significant GWAS polymorphism  Note that closestBed will report an overlapping feature as the closest that is  it does not restrict to closest non overlapping feature ,bedtools_closestbed,"bed,vcf,gff,gff3,bed,gff,vcf,gff3",ClosestBed,
60,cluster overlapping/nearby intervals,,Similar to merge  cluster report each set of overlapping or  book ended  features in an interval file  In contrast to merge  cluster does not flatten the cluster of intervals into a new meta interval  instead  it assigns an unique cluster ID to each record in each cluster  This is useful for having fine control over how sets of overlapping intervals in a single interval file are combined ,bedtools_clusterbed,"bed,vcf,gff,gff3",ClusterBed,
61,Extract intervals not represented by an interval file,,bedtools complement returns all intervals in a genome that are not covered by at least one interval in the input BED GFF VCF file ,bedtools_complementbed,"bed,vcf,gff,gff3",ComplementBed,
62,of features in file B on the features in file A (bedtools coverage),, bedtools coverage   computes both the  depth  and  breadth  of coverage of features in file B on the features in file A  For example    bedtools coverage   can compute the coverage of sequence alignments  file B  across 1 kilobase  arbitrary  windows  file A  tiling a genome of interest  One advantage that   bedtools coverage   offers is that it not only  counts  the number of features that overlap an interval in file A  it also computes the fraction of bases in the interval in A that were overlapped by one or more features  Thus    bedtools coverage   also computes the  breadth  of coverage for each interval in A ,bedtools_coveragebed,"bam,bed,gff,gff3,vcf",Compute both the depth and breadth of coverage,bed
63,replicate lines based on lists of values in columns,,Replicate lines in a file based on columns of comma separated values ,bedtools_expandbed,"bed,vcf,gff,gff3",ExpandBed,
64,calculate Fisher statistic between two feature files,,Perform fisher s exact test on the number of overlaps unique intervals between 2 files ,bedtools_fisher,"bed,vcf,gff,gff3,bed,gff,vcf,gff3",FisherBed,
65,create new intervals from the flanks of existing intervals,,bedtools flank will optionally create flanking intervals whose size is user specified fraction of the original interval ,bedtools_flankbed,"bed,vcf,gff,gff3",FlankBed,
66,compute the coverage over an entire genome,,This tool calculates the genome wide coverage of intervals defined in a BAM or BED file and reports them in BedGraph format ,bedtools_genomecoveragebed,"bed,vcf,gff,gff3,bam",Genome Coverage,bedgraph
67,use intervals to extract sequences from a FASTA file,,bedtools getfasta will extract the sequence defined by the coordinates in a BED interval and create a new FASTA entry in the output file for each extracted sequence  By default  the FASTA header for each extracted sequence will be formatted as follows    chrom   lt start   lt end   ,bedtools_getfastabed,"bed,vcf,gff,gff3,fasta",GetFastaBed,fasta
68,group by common cols and summarize other cols,,Replicate lines in a file based on columns of comma separated values ,bedtools_groupbybed,bed,GroupByBed,
69,find overlapping intervals in various ways,,By far  the most common question asked of two sets of genomic features is whether or not any of the features in the two sets  overlap  with one another  This is known as feature intersection  bedtools intersect allows one to screen for overlaps between two sets of genomic features  Moreover  it allows one to have fine control as to how the intersections are reported  bedtools intersect works with both BED GFF VCF and BAM files as input ,bedtools_intersectbed,"bed,bam,vcf,gff,gff3,bam,bed,gff,gff3,vcf",Intersect intervals,
70,calculate the distribution of relative distances between two files,,By default  bedtools jaccard reports the length of the intersection  the length of the union  minus the intersection   the final Jaccard statistic reflecting the similarity of the two sets  as well as the number of intersections  Whereas the bedtools intersect tool enumerates each an every intersection between two sets of genomic intervals  one often needs a single statistic reflecting the similarity of the two sets based on the intersections between them  The Jaccard statistic is used in set theory to represent the ratio of the intersection of two sets to the union of the two sets  Similarly  Favorov et al  1  reported the use of the Jaccard statistic for genome intervals  specifically  it measures the ratio of the number of intersecting base pairs between two sets to the number of base pairs in the union of the two sets  The bedtools jaccard tool implements this statistic  yet modifies the statistic such that the length of the intersection is subtracted from the length of the union  As a result  the final statistic ranges from 0 0 to 1 0  where 0 0 represents no overlap and 1 0 represent complete overlap ,bedtools_jaccard,"bed,vcf,gff,gff3",JaccardBed,
71,create a HTML page of links to UCSC locations,,Creates an HTML file with links to an instance of the UCSC Genome Browser for all features   intervals in a file  This is useful for cases when one wants to manually inspect through a large set of annotations or features ,bedtools_links,"bed,vcf,gff,gff3",LinksBed,html
72,make interval windows across a genome,,Makes adjacent or sliding windows across a genome or BED file ,bedtools_makewindowsbed,"bed,vcf,gff,gff3",MakeWindowsBed,bed
73,apply a function to a column for each overlapping interval,,bedtools map allows one to map overlapping features in a B file onto features in an A file and apply statistics and or summary operations on those features ,bedtools_map,"bam,bed,vcf,gff,gff3,bam,bed,gff,vcf,gff3",MapBed,
74,use intervals to mask sequences from a FASTA file,,bedtools maskfasta masks sequences in a FASTA file based on intervals defined in a feature file  The headers in the input FASTA file must exactly match the chromosome column in the feature file  This may be useful fro creating your own masked genome file based on custom annotations or for masking all but your target regions when aligning sequence data from a targeted capture experiment ,bedtools_maskfastabed,"bed,vcf,gff,gff3,fasta",MaskFastaBed,fasta
75,combine overlapping/nearby intervals into a single interval,,bedtools merge combines overlapping or  book ended  features in an interval file into a single feature which spans all of the combined features ,bedtools_mergebed,"bam,bed,gff,vcf",MergeBED,bed
76,counts coverage from multiple BAMs at specific intervals,,bedtools multicov  reports the count of alignments from multiple position sorted and indexed BAM files that overlap intervals in a BED file  Specifically  for each BED interval provided  it reports a separate count of overlapping alignments from each BAM file ,bedtools_multicovtbed,"bed,bam",MultiCovBed,
77,identifies common intervals among multiple interval files,,This tool identifies common intervals among multiple  sorted BED files  Intervals can be common among 0 to N of the N input BED files ,bedtools_multiintersectbed,bed,Multiple Intersect,bed
78,profile the nucleotide content of intervals in a FASTA file,,Profiles the nucleotide content of intervals in a fasta file ,bedtools_nucbed,"bed,vcf,gff,gff3,fasta",NucBed,tabular
79,computes the amount of overlap from two intervals,,overlap computes the amount of overlap  in the case of positive values  or distance  in the case of negative values  between feature coordinates occurring on the same input line and reports the result at the end of the same line  In this way  it is a useful method for computing custom overlap scores from the output of other BEDTools ,bedtools_overlapbed,"bed,vcf,gff,gff3",OverlapBed,
80,generate random intervals in a genome,,bedtools random will generate a random set of intervals in BED6 format  One can specify both the number   n  and the size   l  of the intervals that should be generated ,bedtools_randombed,,RandomBed,bed
81,calculate the distribution of relative distances,,Traditional approaches to summarizing the similarity between two sets of genomic intervals are based upon the number or proportion of intersecting intervals  However  such measures are largely blind to spatial correlations between the two sets where  dpesite consistent spacing or proximity  intersections are rare  for example  enhancers and transcription start sites rarely overlap  yet they are much closer to one another than two sets of random intervals   Favorov et al proposed a relative distance metric that describes distribution of relative distances between each interval in one set nd the two closest intervals in another set  see figure above   If there is no spatial correlation between the two sets  one would expect the relative distances to be uniformaly distributed among the relative distances ranging from 0 to 0 5  If  however  the intervals tend to be much closer than expected by chance  the distribution of observed relative distances would be shifted towards low relative distance values  e g   the figure below  ,bedtools_reldistbed,"bed,bam,vcf,gff,gff3,bed,gff,vcf,gff3",ReldistBed,
82,randomly redistrubute intervals in a genome,,bedtools shuffle will randomly permute the genomic locations of a feature file among a genome defined in a genome file  One can also provide an  exclusions  BED GFF VCF file that lists regions where you do not want the permuted features to be placed  For example  one might want to prevent features from being placed in known genome gaps  shuffle is useful as a null basis against which to test the significance of associations of one feature with another ,bedtools_shufflebed,"bed,vcf,gff,gff3,bed",ShuffleBed,bed
83,adjust the size of intervals,,bedtools slop will increase the size of each feature in a feature file by a user defined number of bases  While something like this could be done with an awk   OFS   t  print  1  2  lt slop   3  lt slop     bedtools slop will restrict the resizing to the size of the chromosome  i e  no start  lt  0 and no end   chromosome size  ,bedtools_slopbed,"bed,vcf,gff,gff3",SlopBed,bed
84,order the intervals,,Sorts a feature file by chromosome and other criteria ,bedtools_sortbed,"bed,gff,gff3,vcf",SortBED,
85,reports the distances between features,,Report the spacing between intervals in a file ,bedtools_spacingbed,"bed,vcf,gff,gff3,bam",SpacingBed,
86,remove intervals based on overlaps,,bedtools subtract searches for features in B that overlap A  If an overlapping feature is found in B  the overlapping portion is removed from A and the remaining portion of A is reported  If a feature in B overlaps all of a feature in A  the A feature will not be reported ,bedtools_subtractbed,"bed,vcf,gff,gff3,bed,gff,vcf,gff3",SubtractBed,
87,tag BAM alignments based on overlaps with interval files,,Annotates a BAM file based on overlaps with multiple BED GFF VCF files on the intervals in an input bam file,bedtools_tagbed,"bam,bed,gff,vcf",TagBed,bam
88,combines coverage intervals from multiple BEDGRAPH files,,This tool merges multiple BedGraph files  allowing direct and fine scale coverage comparisons among many samples files  The BedGraph files need not represent the same intervals  the tool will identify both common and file specific intervals  In addition  the BedGraph values need not be numeric  one can use any text as the BedGraph value and the tool will compare the values from multiple files ,bedtools_unionbedgraph,bedgraph,Merge BedGraph files,bedgraph
89,find overlapping intervals within a window around an interval,,Similar to bedtools intersect  window searches for overlapping features in A and B  However  window adds a specified number  1000  by default  of base pairs upstream and downstream of each feature in A  In effect  this allows features in B that are  near  features in A to be detected ,bedtools_windowbed,"bed,bam,vcf,gff,gff3,bed,gff,vcf,gff3",WindowBed,
90,to a BIOM table,,  Usage  biom add metadata  OPTIONS     Add metadata to a BIOM table     Add sample and or observation metadata to BIOM formatted files  See   examples here      Example usage     Add sample metadata to a BIOM table       biom add metadata  i otu table biom  o table with sample metadata biom    m sample metadata txt  Options     i    input fp PATH             The input BIOM table   required     o    output fp PATH            The output BIOM table   required     m    sample metadata fp PATH   The sample metadata mapping file  will add                                   sample metadata to the input BIOM table  if                                   provided       observation metadata fp PATH  The observation metadata mapping file  will                                   add observation metadata to the input BIOM                                   table  if provided       sc separated TEXT             Comma separated list of the metadata fields                                   to split on semicolons  This is useful for                                   hierarchical data such as taxonomy or                                   functional categories      sc pipe separated TEXT        Comma separated list of the metadata fields                                   to split on semicolons and pipes        This                                   is useful for hierarchical data such as                                   functional categories with one to many                                   mappings  e g  x y z x y w        int fields TEXT               Comma separated list of the metadata fields                                   to cast to integers  This is useful for                                   integer data such as  DaysSinceStart       float fields TEXT             Comma separated list of the metadata fields                                   to cast to floating point numbers  This is                                   useful for real number data such as  pH       sample header TEXT            Comma separated list of the sample metadata                                   field names  This is useful if a header line                                   is not provided with the metadata  if you                                   want to rename the fields  or if you want to                                   include only the first n fields where n is                                   the number of entries provided here      observation header TEXT       Comma separated list of the observation                                   metadata field names  This is useful if a                                   header line is not provided with the                                   metadata  if you want to rename the fields                                    or if you want to include only the first n                                   fields where n is the number of entries                                   provided here      output as json                Write the output file in JSON format      help                          Show this message and exit      ,biom_add_metadata,"biom1,tabular",Add metadata,biom1
91,between BIOM table formats,,  Usage  biom convert  OPTIONS       Convert to from the BIOM table format     Convert between BIOM table formats  See examples here      Example usage     Convert a  classic  BIOM file  tab separated text  to an HDF5 BIOM formatted OTU table       biom convert  i table txt  o table biom   to hdf5   Options     i    input fp PATH             The input BIOM table   required     o    output fp PATH            The output BIOM table   required     m    sample metadata fp PATH   The sample metadata mapping file  will add sample metadata to the input BIOM table  if provided       observation metadata fp PATH  The observation metadata mapping file  will add observation metadata to the input BIOM table  if provided       to json                       Output as JSON formatted table      to hdf5                       Output as HDF5 formatted table      to tsv                        Output as TSV formatted  classic  table  table is a BIOM table with collapsed samples  this will update the sample metadata of the table to the supported HDF5 collapsed format      collapsed observations        If   to hdf5 is passed and the original table is a BIOM table with collapsed observations  this will update the  supported HDF5 collapsed format      header key TEXT               The observation metadata to include from the input BIOM table file when creating a tsv table file  By default no observation metadata will be included      output metadata id TEXT       The name to be given to the observation metadata column when creating a tsv table file if the column should be renamed      table type                    OTU table Pathway table Function table Ortholog table Gene table Metabolite table Taxon table Table The type of the table      process obs metadata          taxonomy naive sc separated Process metadata associated with observations when converting from a classic table      tsv metadata formatter        naive sc separated Method for formatting the observation      help                          Show this message and exit       ,biom_convert,"tabular,biom1",Convert,biom1
92,from a vsearch/uclust/usearch BIOM file,, Create a BIOM table from a vsearch uclust usearch BIOM file      ,biom_from_uc,"txt,fasta",Create a BIOM table,biom1
93,a BIOM table,, Normalize the values of a BIOM table through various methods  Relative abundance will take the relative abundance of each observation in terms of samples or observations   Presence absensece will convert observations to 1 s and 0 s based on presence of the observation      ,biom_normalize_table,biom1,Normalize,biom1
94,a BIOM table,, Subset a BIOM table  over either observations or samples  without fully parsing it  This command is intended to assist in working with very large tables when tight on memory  or as a lightweight way to subset a full table  Currently  it is possible to produce tables with rows or columns  observations or samples  that are fully zeroed      ,biom_subset_table,"biom1,text,tabular",Subset,biom1
95,in a BIOM table,, Provides details on the observation counts per sample  including summary statistics  as well as metadata categories associated with samples and observations      ,biom_summarize_table,biom1,Summarize sample or observation data,text
96,converter,,This tool uses Bio  SeqFeature  Tools  Unflattener and Bio  Tools  GFF to convert GenBank flatfiles to GFF3 with gene containment hierarchies mapped for optimal display in gbrowse ,bp_genbank2gff3,genbank,Genbank to GFF3,gff3
97,,,Convert BlastXML results into GFF3 format ,blastxml_to_gapped_gff3,blastxml,BlastXML to gapped GFF3,gff3
98,- map reads against reference genome,,   Bowtie2 Overview    Bowtie2  is an ultrafast and memory efficient tool for aligning sequencing reads to long reference sequences  It is particularly good at aligning reads of about 50 up to 100s or 1 000s of characters to relatively long  e g  mammalian  genomes  Bowtie 2 supports gapped  local  and paired end alignment modes  Galaxy wrapper for Bowtie 2 outputs alignments in  BAM format    enabling interoperation with a large number of other tools available at this site  Majority of information in this page is derived from an excellent  Bowtie2 manual   written by Ben Langmead       Bowtie2        Bowtie2 manual   manual shtml      BAM format              Selecting reference genomes for Bowtie2    Galaxy wrapper for Bowtie2 allows you select between precomputed and user defined indices for reference genomes using   Will you select a reference genome from your history or use a built in index    flag  This flag has two options       1    Use a built in genome index     when selected  this is default   Galaxy provides the user with   Select reference genome index   dropdown  Genomes listed in this dropdown have been pre indexed with bowtie2 build utility and are ready to be mapped against      2    Use a genome from the history and build index     when selected  Galaxy provides the user with   Select reference genome sequence   dropdown  This dropdown is populated by all FASTA formatted files listed in your current history  If your genome of interest is uploaded into history it will be shown there  Selecting a genome from this dropdown will cause Galaxy to first transparently index it using bowtie2 build command  and then run mapping with bowtie2   If your genome of interest is not listed here you have two choices       1  Contact galaxy team using   Help  Support   link at the top of the interface and let us know that an index needs to be added     2  Upload your genome of interest as a FASTA file to Galaxy history and selected   Use a genome from the history and build index   option              class   infomark    Bowtie2 options    Galaxy wrapper for Bowtie2 implements most but not all options available through the command line  Supported options are described below            Inputs    Bowtie 2 accepts files in Sanger FASTQ format  single or paired end   Paired end data can represented as two individual  forward and reverse  datasets  as well as a single interleaved dataset  see an example at the end of the help section              Input options            interleaved             Reads interleaved FASTQ files where the first two records  8 lines  represent a mate pair        s   skip  int              Skip  i e  do not align  the first   int   reads or pairs in the input        u   qupto  int              Align the first   int   reads or read pairs from the input  after the               s     skip  reads or pairs have been skipped   then stop   Default  no limit        5   trim5  int              Trim   int   bases from 5   left  end of each read before alignment  default  0         3   trim3  int              Trim   int   bases from 3   right  end of each read before alignment  default  0          phred33             Input qualities are ASCII chars equal to the Phred quality plus 33   This is             also called the  Phred 33  encoding  which is used by the very latest Illumina             pipelines         phred64             Input qualities are ASCII chars equal to the Phred quality plus 64   This is             also called the  Phred 64  encoding         solexa quals             Convert input qualities from Solexa Phred quality  which can be negative  to             Phred Phred quality  which can t    This scheme was used in older Illumina GA             Pipeline versions  prior to 1 3    Default  off         int quals             Quality values are represented in the read input file as space separated ASCII integers  e g    40 40 30 40      rather than ASCII characters  e g    II I                  Integers are treated as being on the Phred quality scale unless                solexa quals  is also specified  Default  off             Presets in    end to end  mode            very fast             Same as    D 5  R 1  N 0  L 22  i S 0 2 50         fast             Same as    D 10  R 2  N 0  L 22  i S 0 2 50         sensitive             Same as    D 15  R 2  L 22  i S 1 1 15   default in    end to end  mode         very sensitive             Same as    D 20  R 3  N 0  L 20  i S 1 0 50             Presets options in    local  mode            very fast local             Same as    D 5  R 1  N 0  L 25  i S 1 2 00         fast local             Same as    D 10  R 2  N 0  L 22  i S 1 1 75         sensitive local             Same as    D 15  R 2  N 0  L 20  i S 1 0 75   default in    local  mode         very sensitive local             Same as    D 20  R 3  N 0  L 20  i S 1 0 50             Alignment options           N  int              Sets the number of mismatches to allowed in a seed alignment during multiseed             alignment   Can be set to 0 or 1  Setting this higher makes alignment slower              often much slower  but increases sensitivity   Default  0        L  int              Sets the length of the seed substrings to align during multiseed alignment              Smaller values make alignment slower but more sensitive  Default  the                sensitive  preset is used by default  which sets   L  to 22 in                end to end  mode and to 20 in    local  mode        i  func              Sets a function governing the interval between seed substrings to use during             multiseed alignment   For instance  if the read has 30 characers  and seed             length is 10  and the seed interval is 6  the seeds extracted will be       Read       TAGCTACGCTCTACGCTATCATGCATAAAC     Seed 1 fw  TAGCTACGCT     Seed 1 rc  AGCGTAGCTA     Seed 2 fw        CGCTCTACGC     Seed 2 rc        GCGTAGAGCG     Seed 3 fw              ACGCTATCAT     Seed 3 rc              ATGATAGCGT     Seed 4 fw                    TCATGCATAA     Seed 4 rc                    TTATGCATGA      Since it s best to use longer intervals for longer reads  this parameter sets     the interval as a function of the read length  rather than a single     one size fits all number   For instance  specifying   i S 1 2 5  sets the     interval function  f  to  f x    1   2 5   sqrt x    where x is the read length      If the function returns a result less than     1  it is rounded up to 1  Default  the    sensitive  preset is used by     default  which sets   i  to  S 1 1 15  in    end to end  mode to   i S 1 0 75      in    local  mode         n ceil  func              Sets a function governing the maximum number of ambiguous characters  usually              N s and or    s  allowed in a read as a function of read length   For instance              specifying   L 0 0 15  sets the N ceiling function  f  to  f x    0   0 15   x               where x is the read length   Reads exceeding this ceiling are filtered out              Default   L 0 0 15          dpad  int               Pads  dynamic programming problems by   int   columns on either side to allow             gaps   Default  15         gbar  int              Disallow gaps within   int   positions of the beginning or end of the read              Default  4         ignore quals             When calculating a mismatch penalty  always consider the quality value at the             mismatched position to be the highest possible  regardless of the actual value              I e  input is treated as though all quality values are high   This is also the             default behavior when the input doesn t specify quality values  e g  in   f                 r   or   c  modes          nofw   norc             If    nofw  is specified   bowtie2  will not attempt to align unpaired reads to             the forward  Watson  reference strand   If    norc  is specified   bowtie2  will             not attempt to align unpaired reads against the reverse complement  Crick              reference strand  In paired end mode     nofw  and    norc  pertain to the             fragments  i e  specifying    nofw  causes  bowtie2  to explore only those             paired end configurations corresponding to fragments from the reverse complement              Crick  strand   Default  both strands enabled         no 1mm upfront             By default  Bowtie 2 will attempt to find either an exact or a 1 mismatch             end to end alignment for the read  before  trying the multiseed heuristic   Such             alignments can be found very quickly  and many short read alignments have exact or             near exact end to end alignments   However  this can lead to unexpected             alignments when the user also sets options governing the multiseed heuristic              like   L  and   N    For instance  if the user specifies   N 0  and   L  equal             to the length of the read  the user will be surprised to find 1 mismatch alignments             reported   This option prevents Bowtie 2 from searching for 1 mismatch end to end             alignments before using the multiseed heuristic  which leads to the expected             behavior when combined with options such as   L  and   N    This comes at the             expense of speed         end to end             In this mode  Bowtie 2 requires that the entire read align from one end to the             other  without any trimming  or  soft clipping   of characters from either end              The match bonus    ma  always equals 0 in this mode  so all alignment scores             are less than or equal to 0  and the greatest possible alignment score is 0              This is mutually exclusive with    local       end to end  is the default mode         local             In this mode  Bowtie 2 does not require that the entire read align from one end             to the other   Rather  some characters may be omitted   soft clipped   from the             ends in order to achieve the greatest possible alignment score   The match bonus                ma  is used in this mode  and the best possible alignment score is equal to             the match bonus     ma   times the length of the read   Specifying    local              and one of the presets  e g     local   very fast   is equivalent to specifying             the local version of the preset     very fast local     This is mutually             exclusive with    end to end       end to end  is the default mode            Scoring options            ma  int              Sets the match bonus   In    local  mode   int   is added to the alignment             score for each position where a read character aligns to a reference character             and the characters match   Not used in    end to end  mode   Default  2         mp MX MN             Sets the maximum   MX   and minimum   MN   mismatch penalties  both integers   A             number less than or equal to  MX  and greater than or equal to  MN  is             subtracted from the alignment score for each position where a read character             aligns to a reference character  the characters do not match  and neither is an              N    If    ignore quals  is specified  the number subtracted quals  MX               Otherwise  the number subtracted is  MN   floor   MX MN  MIN Q  40 0  40 0                 where Q is the Phred quality value   Default   MX    6   MN    2         np  int              Sets penalty for positions where the read  reference  or both  contain an             ambiguous character such as  N    Default  1         rdg  int1   int2              Sets the read gap open    int1    and extend    int2    penalties   A read gap of             length N gets a penalty of   int1     N     int2     Default  5  3         rfg  int1   int2              Sets the reference gap open    int1    and extend    int2    penalties   A             reference gap of length N gets a penalty of   int1     N     int2     Default              5  3         score min  func              Sets a function governing the minimum alignment score needed for an alignment to             be considered  valid   i e  good enough to report    This is a function of read             length  For instance  specifying  L 0  0 6  sets the minimum score function  f              to  f x    0    0 6   x   where  x  is the read length   The default in    end to end  mode is  L  0 6  0 6  and             the default in    local  mode is  G 20 8             Reporting options           k  int              By default   bowtie2  searches for distinct  valid alignments for each read              When it finds a valid alignment  it continues looking for alignments that are             nearly as good or better   The best alignment found is reported  randomly             selected from among best if tied    Information about the best alignments is             used to estimate mapping quality and to set SAM optional fields  such as              AS i  and  XS i        When   k  is specified  however   bowtie2  behaves differently   Instead  it     searches for at most   int   distinct  valid alignments for each read   The     search terminates when it can t find more distinct valid alignments  or when it     finds   int    whichever happens first   All alignments found are reported in     descending order by alignment score  The alignment score for a paired end     alignment equals the sum of the alignment scores of the individual mates  Each     reported read or pair alignment beyond the first has the SAM  secondary  bit      which equals 256  set in its FLAGS field   For reads that have more than       int   distinct  valid alignments   bowtie2  does not guarantee that the       int   alignments reported are the best possible in terms of alignment score        k  is mutually exclusive with   a        Note  Bowtie 2 is not designed with large values for   k  in mind  and when     aligning reads to long  repetitive genomes large   k  can be very  very slow        a             Like   k  but with no upper limit on number of alignments to search for     a              is mutually exclusive with   k        Note  Bowtie 2 is not designed with   a  mode in mind  and when     aligning reads to long  repetitive genomes this mode can be very  very slow            Effort options           D  int              Up to   int   consecutive seed extension attempts can  fail  before Bowtie 2             moves on  using the alignments found so far   A seed extension  fails  if it             does not yield a new best or a new second best alignment   This limit is             automatically adjusted up when  k or  a are specified   Default  15        R  int                int   is the maximum number of times Bowtie 2 will  re seed  reads with             repetitive seeds  When  re seeding   Bowtie 2 simply chooses a new set of reads              same length  same number of mismatches allowed  at different offsets and             searches for more alignments   A read is considered to have repetitive seeds if             the total number of seed hits divided by the number of seeds that aligned at             least once is greater than 300   Default  2            Paired end options           I   minins  int              The minimum fragment length for valid paired end alignments   E g  if   I 60  is             specified and a paired end alignment consists of two 20 bp alignments in the             appropriate orientation with a 20 bp gap between them  that alignment is             considered valid  as long as   X  is also satisfied    A 19 bp gap would not             be valid in that case   If trimming options   3  or   5  are also used  the               I  constraint is applied with respect to the untrimmed mates               The larger the difference between   I  and   X   the slower Bowtie 2 will             run   This is because larger differences bewteen   I  and   X  require that             Bowtie 2 scan a larger window to determine if a concordant alignment exists              For typical fragment length ranges  200 to 400 nucleotides   Bowtie 2 is very             efficient               Default  0  essentially imposing no minimum        X   maxins  int              The maximum fragment length for valid paired end alignments   E g  if   X 100              is specified and a paired end alignment consists of two 20 bp alignments in the             proper orientation with a 60 bp gap between them  that alignment is considered             valid  as long as   I  is also satisfied    A 61 bp gap would not be valid in             that case   If trimming options   3  or   5  are also used  the   X              constraint is applied with respect to the untrimmed mates  not the trimmed             mates               The larger the difference between   I  and   X   the slower Bowtie 2 will             run   This is because larger differences bewteen   I  and   X  require that             Bowtie 2 scan a larger window to determine if a concordant alignment exists              For typical fragment length ranges  200 to 400 nucleotides   Bowtie 2 is very             efficient               Default  500         fr   rf   ff             The upstream downstream mate orientations for a valid paired end alignment             against the forward reference strand   E g   if    fr  is specified and there is             a candidate paired end alignment where mate 1 appears upstream of the reverse             complement of mate 2 and the fragment length constraints    I  and   X   are             met  that alignment is valid   Also  if mate 2 appears upstream of the reverse             complement of mate 1 and all other constraints are met  that too is valid                 rf  likewise requires that an upstream mate1 be reverse complemented and a             downstream mate2 be forward oriented      ff  requires both an upstream mate 1             and a downstream mate 2 to be forward oriented   Default     fr   appropriate             for Illumina s Paired end Sequencing Assay          no mixed             By default  when  bowtie2  cannot find a concordant or discordant alignment for             a pair  it then tries to find alignments for the individual mates   This option             disables that behavior         no discordant             By default   bowtie2  looks for discordant alignments if it cannot find any             concordant alignments   A discordant alignment is an alignment where both mates             align uniquely  but that does not satisfy the paired end constraints                 fr     rf     ff     I     X     This option disables that behavior         dovetail             If the mates  dovetail   that is if one mate alignment extends past the             beginning of the other such that the wrong mate begins upstream  consider that             to be concordant   Default  mates cannot dovetail in a concordant alignment         no contain             If one mate alignment contains the other  consider that to be non concordant              Default  a mate can contain the other in a concordant alignment         no overlap             If one mate alignment overlaps the other at all  consider that to be             non concordant   Default  mates can overlap in a concordant alignment             SAM options            rg id  text              Set the read group ID to   text     This causes the SAM   RG  header line to be             printed  with   text   as the value associated with the  ID   tag   It also             causes the  RG Z   extra field to be attached to each SAM output record  with             value set to   text           rg  text              Add   text    usually of the form  TAG VAL   e g   SM Pool1   as a field on the               RG  header line   Note  in order for the   RG  line to appear     rg id              must also be specified   This is because the  ID  tag is required by the SAM             Specification   Specify    rg  multiple times to set multiple fields   See the             SAM Specification for details about what fields are legal         omit sec seq             When printing secondary alignments  Bowtie 2 by default will write out the  SEQ              and  QUAL  strings   Specifying this option causes Bowtie 2 to print an asterix             in those fields instead            Other options            reorder             Guarantees that output SAM records are printed in an order corresponding to the             order of the reads in the original input file  even when   p  is set greater             than 1   Specifying    reorder  and setting   p  greater than 1 causes Bowtie             2 to run somewhat slower and use somewhat more memory then if    reorder  were             not specified   Has no effect if   p  is set to 1  since output order will             naturally correspond to input order in that case         seed  int              Use   int   as the seed for pseudo random number generator   Default  0         non deterministic             Normally  Bowtie 2 re initializes its pseudo random generator for each read   It             seeds the generator with a number derived from  a  the read name   b  the             nucleotide sequence   c  the quality sequence   d  the value of the    seed              option  This means that if two reads are identical  same name  same             nucleotides  same qualities  Bowtie 2 will find and report the same alignment s              for both  even if there was ambiguity   When    non deterministic  is specified              Bowtie 2 re initializes its pseudo random generator for each read using the             current time   This means that Bowtie 2 will not necessarily report the same             alignment for two identical reads   This is counter intuitive for some users              but might be more appropriate in situations where the input consists of many             identical reads             Paired end  and mate pair  data in fastq format    Paired end datasets can be represented as two individual datasets   First dataset      1 1  AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA     EGGEGGGDFGEEEAEECGDEGGFEEGEFGBEEDDECFEFDD CDD ED   2 1  AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA     HHHHHHEGFHEEFEEHEEHHGGEGGGGEFGFGGGGHHHHFBEEEEEFG  Second dataset      1 2  CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC     GHHHDFDFGFGEGFBGEGGEGEGGGHGFGHFHFHHHHHHHEF EFEFF   2 2  CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC     HHHHHHHHHHHHHGHHHHHHGHHHHHHHHHHHFHHHFHHHHHHHHHHH  Or a single  interleaved  dataset      1 1  AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA     EGGEGGGDFGEEEAEECGDEGGFEEGEFGBEEDDECFEFDD CDD ED   1 2  CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC     GHHHDFDFGFGEGFBGEGGEGEGGGHGFGHFHFHHHHHHHEF EFEFF   2 1  AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA     HHHHHHEGFHEEFEEHEEHHGGEGGGGEFGFGGGGHHHHFBEEEEEFG   2 2  CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC     HHHHHHHHHHHHHGHHHHHHGHHHHHHHHHHHFHHHFHHHHHHHHHHH     ,bowtie2,"fastqsanger,fastqsanger.gz,fastqsanger.bz2,fasta,fasta",Bowtie2,"fastqsanger,bam,sam,txt"
99,assess genome assembly and annotation completeness,,         BUSCO  assessing genome assembly and annotation completeness with Benchmarking Universal Single Copy Orthologs              BUSCO       ,busco,"fasta,augustus",Busco,"txt,tabular"
100,- map medium and long reads (> 100 bp) against reference genome,,   What is does    From   BWA MEM is an alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human  It automatically chooses between local and end to end alignments  supports paired end reads and performs chimeric alignment  The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases   This Galaxy tool wraps bwa mem module of bwa read mapping tool  The Galaxy implementation takes fastq files as input and produces output in BAM format  which can be further processed using various BAM utilities exiting in Galaxy  BAMTools  SAMTools  Picard             Indices  Selecting reference genomes for BWA    Galaxy wrapper for BWA allows you select between precomputed and user defined indices for reference genomes using   Will you select a reference genome from your history or use a built in index    flag  This flag has two options     1    Use a built in genome index     when selected  this is default   Galaxy provides the user with   Select reference genome index   dropdown  Genomes listed in this dropdown have been pre indexed with bwa index utility and are ready to be mapped against    2    Use a genome from the history and build index     when selected  Galaxy provides the user with   Select reference genome sequence   dropdown  This dropdown is populated by all FASTA formatted files listed in your current history  If your genome of interest is uploaded into history it will be shown there  Selecting a genome from this dropdown will cause Galaxy to first transparently index it using  bwa index  command  and then run mapping with  bwa mem    If your genome of interest is not listed here you have two choices     1  Contact galaxy team using   Help  Support   link at the top of the interface and let us know that an index needs to be added   2  Upload your genome of interest as a FASTA file to Galaxy history and selected   Use a genome from the history and build index   option            Galaxy specific option    Galaxy allows four levels of control over bwa mem options provided by   Select analysis mode   menu option  These are     1   Simple Illumina mode   The simplest possible bwa mem application in which it alignes single or paired end data to reference using default parameters  It is equivalent to the following command  bwa mem  reference index   fastq dataset1   fastq dataset2    2   PacBio mode   The mode adjusted specifically for mapping of long PacBio subreads  Equivalent to the following command  bwa mem  k17  W40  r10  A1  B1  O1  E1  L0   reference index   PacBio dataset in fastq format    3   Full list of options   Allows access to all options through Galaxy interface    RG    info      ,bwa_mem,"fastqsanger,fastqsanger.gz,fasta",Map with BWA-MEM,bam
101,- map short reads (< 100 bp) against reference genome,,   What is does    BWA is a software package for mapping low divergent sequences against a large reference genome  such as the human genome  The bwa aln algorithm is designed for Illumina sequence reads up to 100bp  For longer reads use the separate BWA MEM Galaxy tool   This Galaxy tool wraps bwa aln  bwa samse and  sampe modules of bwa read mapping tool       bwa aln     actual mapper placing reads onto the reference sequence     bwa samse     post processor converting suffix array coordinates into genome coordinates in SAM format for   single reads     bam sampe     post processor for paired reads   The Galaxy implementation takes fastq or BAM  unaligned BAM  datasets as input and produces output in BAM format  which can be further processed using various BAM utilities exiting in Galaxy  BAMTools  SAMTools  Picard             Indices  Selecting reference genomes for BWA    The Galaxy wrapper for BWA allows you to select between precomputed and user defined indices for reference genomes using the   Will you select a reference genome from your history or use a built in index    select box   This select box has two options     1    Use a built in genome index     when selected  this is default   Galaxy provides the user with   Select      reference genome index   dropdown  Genomes listed in this dropdown have been pre indexed with bwa index utility      and are ready to be mapped against    2    Use a genome from the history and build index     when selected  Galaxy provides the user with   Select      reference genome sequence   dropdown  This dropdown is populated by all FASTA formatted files listed in your      current history  If your genome of interest is uploaded into history it will be shown there  Selecting a genome      from this dropdown will cause Galaxy to first transparently index it using  bwa index  command  and then run      mapping with  bwa aln     If your genome of interest is not listed here you have two choices     1  Contact galaxy team using   Help  Support   link at the top of the interface and let us know that an index      needs to be added   2  Upload your genome of interest as a FASTA file to Galaxy history and selected   Use a genome from the history      and build index   option     RG    info      ,bwa,"fastqsanger,fastqsanger.gz,fasta,bam",Map with BWA,bam
102,Fast and accurate aligner of BS-Seq reads.,,BWA meth performs alignment of reads in a bisulfite sequencing experiment  e g   RRBS or WGBS  to a genome  The methodology employed for this is similar to bismark  where both the reads and the reference genome are  in silico  converted prior to alignment  Methylation extraction on the resulting BAM file can be done with the PileOMeth tool ,bwameth,"fasta,fastqsanger,fastqsanger.gz,fastqsanger.bz2",bwameth,bam
103,creates circos plots from standard bioinformatics datatypes.,, Circos         Circos is a software package for visualizing data and information  It visualizes data in a circular layout   this makes Circos ideal for exploring relationships between objects or positions  There are other reasons why a circular layout is advantageous  not the least being the fact that it is attractive   Circos is ideal for creating publication quality infographics and illustrations with a high data to ink ratio  richly layered data and pleasant symmetries  You have fine control each element in the figure to tailor its focus points and detail to your audience      image    PATH TO IMAGES circos sample panel png     alt  several example circos plots  For more information see the Circos documentation        documentation         ,circgraph,"bed6,bed12,fasta,tabular,txt,bed6,bed12,wig,gff3,bed6,bed12,gff3,txt",Circos Builder,"png,svg,tar.gz"
104,"
        Detects positive selection (paml package)
    ",,     class   infomark    Galaxy integration   Victor Mataigne and ABIMS TEAM    Contact support abims sb roscoff fr for any questions or concerns about the Galaxy implementation of this tool                 CompCodeML  from paml package     A few help is detailed below   full and detailed codeml readme can be found on the paml website       website       class   warningmark  Due to their high number  some parameters incompatibility can remain   This Galaxy implementation     handles incompatibilities between branch and sites models  the tool CANNOT be run with incompatible models     warns the user in a help section when an advanced parameter has known incompatibilities  the tool CAN be run  but the output files will be empty    We recommand to have a look at the full paml manual before looking at the advanced parameters  in order to spot parameters incompatibilities and to know what each model does  If you choose by mistake incompatible parameters  the output files will be empty  except the log file   run codeml  output  which will normally explicit the error      class   infomark  Known incompatibilities         seqtype    3   only compatible with  FSsites    0         clock    2   needs branch labels in the tree        fix alpha   1 combined with alpha   0 are not compatible with NSsites   0        aaDist    0 is the only one compatible with  NSsites  different than 0 and  seqtype    1         method    1   does not work with  clock  different than 0                 Description       class   infomark  codeML finds positive selection within branches or codons within a tree and a set of sequences                 Input files      a treefile in Newick format  with or without branch lengths     a fasta file with sequences from the species of the tree file  one header sequence per species  and run codeml  from the paml suite                  Parameters    Several models are available    branch models   model  parameter     sites models   NSsites  parameter  model is left at 0     branch sites models  when model   2 NSsites 2 3     Clade models  when model 3 NSsites 2 3   Basically  this tool write a configfile called codeml ctl with the specified parameters and then launches codeml      class   infomark  Branch models allow the omega ratio to vary among branches in the phylogeny and are useful for detecting positive selection acting on particular lineages  Sites models allow the omega ratio to vary among sites  codons or amino acids    Two pairs of models appear to be particularly useful  forming two likelihood ratio tests of positive selection   The first compares M1a   NearlyNeutral   NSsites 1  and M2a   PositiveSelection   NSsites 2   while the second compares M7   beta   NSsites 7  and M8   beta     NSsites 8      Other examples of model    How to run the branch site models  A  amp  B in Yang  amp  Nielsen 2002 MBE    The options are       Model A   model 2  NSsites 2       Model B   model 2  NSsites 3    How to run the M0  one ratio  model       model   0  NSsites    0                 Advanced Parameters       class   infomark  See paml complete manual and FAQ on paml website       website      Details of some parameters             kappa  denotes the transition transversion rate ratio         fix kappa  specifies whether kappa in K80  F84  or HKY85 is given at a fixed value or is to be estimated by iteration from the data             If fix kappa   1  fixed   the value of kappa is the given value            If fix kappa   0  estimated  the value of kappa is used as the initial estimate for iteration          alpha  refers to the shape parameter alpha of the gamma distribution for variable substitution rates across sites  Yang 1994a          fix alpha  works in a similar way that fix kappa             The model of a single rate for all sites is specified as fix alpha   1 and alpha   0  0 means infinity             The  discrete   gamma model is specified by a positive value for alpha  and  ncatG  is then the number of categories for the discrete gamma model  Values such as 5  4  8  or 10 are reasonable         fix rho and rho work in a similar way and concern independence or correlation of rates at adjacent sites  where rho is the correlation parameter of the auto discrete gamma model  Yang 1995              The model of independent rates for sites is specified as fix rho   1 and rho   0  choosing alpha   0 further means a constant rate for all sites             The auto discrete gamma model is specified by positive values for both alpha and rho             The model of a constant rate for sites is a special case of the  discrete  gamma model with alpha   0  means infinity              The model of independent rates for sites is a special case of the auto discrete gamma model with rho   0                 Output files      codeml ctl   a copy of the control file  list of all the parameters used for the codeml run     run codeml   main result file name    The 2NG dN and 2NG dS files are the Nei an Gojobori  1986  dN and dS values    lnf  rst and rst1  Supplemental results    rub   records of the iteration progress  i e  the minimization of the negative log likelihood                  How to edit manually the tree file   Branch or node labels    Some models implemented in codeml allow several groups of branches on the tree  which are assigned different parameters of interest         For example  in the local clock models  clock   2 or 3   you can have  say  3 branch rate groups  with low  medium  and high rates respectively         Also the branch specific codon models  model   2 or 3 or codonml  allow different branch groups to have different  s  leading to so called  two ratios  and  three ratios  models         All those models require branches or nodes in the tree to be labeled  Branch labels are specified in the same way as branch lengths except that the symbol     is used rather than      The branch labels are consecutive integers starting from 0  which is the default and does not have to be specified   In   Hsa Human  Hla gibbon   1    Cgu Can colobus  Pne langur   Mmu rhesus    Ssc squirrelM  Cja marmoset          The internal branch ancestral to human and gibbon has the ratio  1  while all other branches  with the default label  0  have the background ratio  0   The following trees are equivalent         rabbit  rat   1  human   goat cow  marsupial          rabbit  1  rat  1   1  human   goat cow  marsupial      is the symbol for clade labels   Rules concerning nested clade labels   The symbol   takes precedence over the symbol    and clade labels close to the tips take precedence over clade labels for ancestral nodes close to the root   In the tree     rabbit  rat   2  human  3   goat cow   1  marsupial          1 is first applied to the whole clade of placental mammals  except for the human lineage   and then  2 is applied to the rabbit rat clade      Equivalent tree with only               rabbit  2  rat  2   2  human  3   1  goat cow  1   1  marsupial         ,codeml,"fasta,nhx",codeML,txt
105,COmpare Multiple METagenomes,,    Description    COMMET  COmpare Multiple METagenomes   provides a global similarity overview between all datasets of a large metagenomic project   Directly from non assembled reads  all against all comparisons are performed through an efficient indexing strategy  Then  results are stored as bit vectors  a compressed representation of read files  that can be used to further combine read subsets by common logical operations  Finally  COMMET computes a clusterization of metagenomic datasets  which is visualized by dendrogram and heatmaps               Web site          ,commet,"fasta, fastq",Commet,"csv,png"
106,discovering polymorphism from raw unassembled RADSeq NGS reads.,,    Description    Software discoSnp is designed for discovering Single Nucleotide Polymorphism  SNP  from raw set s  of reads obtained with Next Generation Sequencers  NGS    DiscoSnpRad uses options specific to RAD Seq  branching strategy  kind of extensions  abundance threshold  and kind of bubbles to be found   Moreover  it clusters variants per locus by calling the  discoRAD finalization sh  pipeline  Cluster information is  reported in the final provided VCF file   Note that from release of DiscoSnp   2 0 6  the tool also detects close SNPs and indels    discosnp help      ,discosnp_rad,,DiscoSnpRAD,"vcf,fasta"
107,is an efficient tool for detecting SNPs without a reference genome.,,    Description    Software discoSnp is designed for discovering Single Nucleotide Polymorphism  SNP  from raw set s  of reads obtained with Next Generation Sequencers  NGS    Note that number of input read sets is not constrained  it can be one  two  or more  Note also that no other data as reference genome or annotations are needed   The software is composed by two modules  First module  kissnp2  detects SNPs from read sets  A second module  kissreads  enhance the kissnp2 results by computing per read set  and for each found SNP i  its mean read coverage and ii  the  phred  quality of reads generating the polymorphism   Note that from release of DiscoSnp   2 0 6  the tool also detects close SNPs and indels    discosnp help     ,discosnp_pp,"fasta,fastq",DiscoSnp++,"vcf,fasta"
108,"is a local transcriptome assembler for SNPs, indels and AS events",,    Description    KisSplice is a piece of software that enables the   analysis of RNA seq data with or without a reference genome    It is an exact local transcriptome assembler that allows one to identify   SNPs  indels and alternative splicing events    It can deal with an arbitrary number of biological conditions  and will quantify each variant in each condition  It has been tested on Illumina datasets of up to 1G reads  Its memory consumption is around 5Gb for 100M reads   KisSplice is not a full length transcriptome assembler  This means that it will output the variable regions of the transcripts  not reconstruct them entirely  However  KisSplice results can be further aligned to a reference transcriptome  if available   or to the output of a full length transcriptome assembler like Trinity or Oases             Website    References  documentation and FAQ here        here         ,kissplice,"fasta,fastq",KisSplice,fasta
109,is a set a programs for correcting sequencing errors in PacBio reads,,    Lordec Correct    Program for correcting sequencing errors in PacBio reads using highly accurate short reads  e g  Illumina    LoRDEC outputs the corrected reads to the given file in FASTA format  The regions that remain weak after the correction are outputted in lower case characters and the solid regions are outputted in upper case characters              Lordec Trim    Program for trimming the weak regions from the beginning and end of the corrected reads              Lordec Statistics    Program to generate statistics on solid and weak k mers              Web site           ,lordec,"fasta,fastq.gz,fastq",Lordec,"fasta,tabular"
110,is a targeted assembly software,,    Description    Mapsembler2 is a targeted assembly software  It takes as input a set of NGS raw reads  fasta or fastq  gzipped or not  and a set of input sequences  starters   It first determines if each starter is read coherent  e g  whether reads confirm the presence of each starter in the original sequence  Then for each read coherent starter  Mapsembler2 outputs its sequence neighborhood as a linear sequence or as a graph  depending on the user choice  Mapsembler2 may be used for  not limited to      Validate an assembled sequence  input as starter   e g  from a de Bruijn graph assembly where read coherence was not enforced     Checks if a gene  input as starter  has an homolog in a set of reads     Checks if a known enzyme is present in a metagenomic NGS read set     Enrich unmappable reads by extending them  possibly making them mappable     Checks what happens at the extremities of a contig     Remove contaminants or symbiont reads from a read set             Web site           ,mapsembler2,"fasta,fasta,fastq",Mapsembler2,fasta
111,is a tool that can detect inversion breakpoints directly from raw NGS reads,,    Description    TakeABreak is a tool that can detect inversion breakpoints directly from raw NGS reads  without the need of any reference genome and without de novo assembling the genomes  Its implementation has a very limited memory impact allowing its usage on common desktop computers and acceptable runtime  Illumina reads simulated at 2x40x coverage from human chromosome 22 can be treated in less than two hours  with less than 1GB of memory               Web site           ,takeabreak,"fasta,fastq",TakeABreak,fasta
112,on Collections,,          Joins lists of tabular datasets together on a field            Example    To join three files  with headers  based on the first column     First file  in 1 tabular            KEY    c2  c3  c4     one     1 1 1 2 1 3     two     1 4 1 5 1 6     three   1 7 1 8 1 9     Second File  in 2 tabular            KEY    c2  c3  c4     one     2 1 2 2 2 3     two     2 4 2 5 2 6     three   2 7 2 8 2 9    Third file  in 3 tabular            KEY    c2  c3  c4     one     3 3 3 2 3 3     two     3 4 3 5 3 6     three   3 7 3 8 3 9     Joining   the files  using   identifier column of 1   and a   header lines of 1    will return         KEY    in 1 tabular c2 in 1 tabular c3 in 1 tabular c4 in 2 tabular c2 in 2 tabular c3 in 2 tabular c4 in 3 tabular c2 in 3 tabular c3 in 3 tabular c4     one     1 1              1 2            1 3             2 1              2 2             2 3             3 3             3 2             3 3     three   1 7              1 8            1 9             2 7              2 8             2 9             3 7             3 8             3 9     two     1 4              1 5            1 6             2 4              2 5             2 6             3 4             3 5             3 6               ,collection_column_join,tabular,Column Join,"tabular,txt"
113,"
        by heading
    ",,                  Reorders a file s columns by sorted value of header fields          Specify the optional Identifier column parameter to make a column left most  generally used for a Key column that should not be sorted within the other columns               ,column_order_header_sort,tabular,Sort Column Order,tabular
114,"
        by heading
    ",,                  Removes or keeps columns based upon user provided values               ,column_remove_by_header,tabular,Remove columns,tabular
115,Provide mapping statistics,,This tool creates a coverage report for QC purposes  By default  average coverage statistics are provided  taken from samtools flagstats  If specified  it can also create overviews per gene in the BED file  and sub exon plots for failed exons  ,CoverageReport2,"bam,bed",Panel Coverage Report,pdf
116,Convert genome coordinates or annotation files between genome assemblies,,  HELP GENERAL   BAM            CrossMap updates chromosomes  genome coordinates  header sections  and all BAM flags accordingly  The program version  of CrossMap  is inserted into the header section  along with the names of the original BAM file and the chain file  For pair end sequencing  insert size is also recalculated      Optional tags    Q     QC  QC failed   N     Unmapped  Originally unmapped or originally mapped but failed to liftover to new assembly   M     Multiple mapped  Alignment can be liftover to multiple places   U     Unique mapped  Alignment can be liftover to only 1 place     Tags for pair end sequencing include     QF     QC failed NN     both read1 and read2 unmapped NU     read1 unmapped  read2 unique mapped NM     read1 unmapped  multiple mapped UN     read1 uniquely mapped  read2 unmap UU     both read1 and read2 uniquely mapped UM     read1 uniquely mapped  read2 multiple mapped MN     read1 multiple mapped  read2 unmapped MU     read1 multiple mapped  read2 unique mapped MM     both read1 and read2 multiple mapped    Tags for single end sequencing include    QF     QC failed SN     unmaped SM     multiple mapped SU     uniquely mapped      ,crossmap_bam,bam,CrossMap BAM,bam
117,Convert genome coordinates or annotation files between genome assemblies,,  HELP GENERAL   BED      BED format file must have at least 3 columns  chrom  start  end  and no more than 12 columns  BED format   format1  A BED  Browser Extensible Data  file is a tab delimited text file describing genome regions or gene annotations  It is the standard file format used by UCSC  It consists of one line per feature  each containing 3 12 columns  CrossMap converts BED files with less than 12 columns to a different assembly by updating the chromosome and genome coordinates only  all other columns remain unchanged  Regions from old assembly mapping to multiple locations to the new assembly will be split  For 12 columns BED files  all columns will be updated accordingly except the 4th column  name of bed line   5th column  score value  and 9th column  RGB value describing the display color   12 column BED files usually define multiple blocks  eg  exon   if any of the exons fails to map to a new assembly  the whole BED line is skipped   Notes   1  For BED like formats mentioned above  CrossMap only updates  chrom  1st    column     start  2nd column      end  3rd column    and  strand   if    any   All other columns will keep AS IS  2  Lines starting with       browser    track  will be skipped  3  Lines will less than 3 columns will be skipped  4  2nd column and 3 column must be integer  otherwise skipped  5      strand is assumed if no strand information was found  6  For standard BED format  12 columns   If any of the defined exon blocks    cannot be uniquely mapped to target assembly  the whole entry will be    skipped  7  If input region cannot be consecutively mapped target assembly  it will be split  8     unmap file contains regions that cannot be unambiguously converted       ,crossmap_bed,bed,CrossMap BED,bed
118,Convert genome coordinates or annotation files between genome assemblies,,  HELP GENERAL   BigWig         Input wiggle data can be in variableStep  for data with irregular intervals  or fixedStep  for data with regular intervals   Regardless of the input  the output will always in bedGraph format  bedGraph format is similar to wiggle format and can be converted into BigWig format using UCSC wigToBigWig tool  We export files in bedGraph because it is usually much smaller than file in wiggle format  and more importantly  CrossMap internally transforms wiggle into bedGraph to increase running speed       ,crossmap_bw,bigwig,CrossMap BigWig,bigwig
119,Convert genome coordinates or annotation files between genome assemblies,,  HELP GENERAL   GFF   GTF           Your input data should be either GTF GFF2 5 or GFF3 format   GFF  General Feature Format  is another plain text file used to describe gene structure  GTF  Gene Transfer Format  is a refined version of GTF  The first eight fields are the same as GFF  Only chromosome and genome coordinates are updated  The format of output is determined from the input   Notes     Each feature  exon  intron  UTR  etc  is processed separately and   independently  and we do NOT check if features originally belonging to   the same gene were converted into the same gene    If user want to liftover gene annotation files  use BED12 format       ,crossmap_gff,"gtf,gff,gff3",CrossMap GFF,gff
120,Convert genome coordinates or annotation files between genome assemblies,,  HELP GENERAL   VCF      VCF  variant call format  is a flexible and extendable line oriented text format developed by the 1000 Genome Project  It is useful for representing single nucleotide variants  indels  copy number variants  and structural variants  Chromosomes  coordinates  and reference alleles are updated to a new assembly  and all the other fields are not changed   Notes     Genome coordinates and reference allele will be updated to target assembly    Reference genome is genome sequence of target assembly    If the reference genome sequence file     database genome hg18 fa  was   not indexed  CrossMap will automatically indexed it  only the first time   you run CrossMap     In the output VCF file  whether the chromosome IDs contain  chr  or not   depends on the format of the input VCF file       ,crossmap_vcf,"vcf,fasta",CrossMap VCF,vcf
121,Convert genome coordinates or annotation files between genome assemblies,,  HELP GENERAL   Wig      Input wiggle data can be in variableStep  for data with irregular intervals  or fixedStep  for data with regular intervals   Regardless of the input  the output will always in bedGraph format  bedGraph format is similar to wiggle format and can be converted into BigWig format using UCSC wigToBigWig tool  We export files in bedGraph because it is usually much smaller than file in wiggle format  and more importantly  CrossMap internally transforms wiggle into bedGraph to increase running speed       ,crossmap_wig,wig,CrossMap Wig,"wig,bedgraph"
122,find matched pairs and unmatched orphans,,CWPair accepts one or more gff files as input and takes the peak location to be the midpoint between the exclusion zone start and end coordinate  columns D and E    CWPair starts with the highest peak  primary peak  in the dataset  and then looks on the opposite strand for another peak located within the distance defined by a combination of the tool s   Distance upstream from a peak to allow a pair    the distance upstream or 5  to the primary peak  and   Distance downstream from a peak to allow a pair    the distance downstream or 3  to the primary peak  parameters   So  upstream  value 30  downstream  value 20 makes the tool look 30 bp upstream and 20 bp downstream  inclusive    Consequently  the search space would be 51 bp  since it includes the primary peak coordinate   The use of a negative number changes the direction of the search limits   So   upstream   30 and  downstream  20 produces an 11 bp downstream search window  20 30 bp downstream  inclusive  ,cwpair2,gff,CWPair2,tabular
123,server,,,data_source_iris_tcga,,IRIS-TCGA,auto
124,(operations on tabular data),,   HELP HEADER     Syntax    This tools performs common operations  such as summing  counting  mean  standard deviation  on input file  based on tabular data  The tool can also optionaly group the input based on a given field            Example 1      Find the average score in statistics course of college students  grouped by their college major  The input file has three fields  Name Major Score  and a header line        Name        Major            Score     Bryan       Arts             68     Isaiah      Arts             80     Gabriel     Health Medicine  100     Tysza       Business         92     Zackery     Engineering      54                    Grouping the input by the second column   Major    and performing operations   mean   and   sample standard deviation   on the third column   Score    gives        GroupBy Major      mean Score    sstdev Score      Arts               68 9474       10 4215     Business           87 3636       5 18214     Engineering        66 5385       19 8814     Health Medicine    90 6154       9 22441     Life Sciences      55 3333       20 606     Social Sciences    60 2667       17 2273  This sample file is available at       Example 2      Using the UCSC RefSeq Human Gene Track  available at      List the number and identifiers of isoforms per gene  The gene identifier is in column 13  the isoform transcript identifier is in column 2  Grouping by column 13 and performing   count   and   Combine all values   on column 2  gives        GroupBy field 13      count field 2      collapse field 2      A1BG                  1                  NM 130786     A1BG AS1              1                  NR 015380     A1CF                  6                  NM 001198818 NM 001198819 NM 001198820 NM 014576 NM 138932 NM 138933     A2M                   1                  NM 000014     A2M AS1               1                  NR 026971     A2ML1                 2                  NM 001282424 NM 144670            Count how many transcripts are listed for each chromosome and strand  Chromosome is on column 3  Strand is in column 4  Transcript identifiers are in column 2  Grouping by columns   3 4   and performing operation   count   on column 2  gives        GroupBy field 3      GroupBy field 4      count field 2      chr1                                      2456     chr1                                      2431     chr2                                      1599     chr2                                      1419     chr3                                      1287     chr3                                      1249           HELP FOOTER       ,datamash_ops,,Datamash,
125,columns in a tabular file,,   HELP HEADER            Syntax    This tools reverses the order of columns in a tabular input file            Example    Input file        Genes  Sample  Counts     NOX1   A1      514     DcP    A2      542     HH     B3      490  Output file        Counts  Sample  Genes     514     A1      NOX1     542     A2      DcP     490     B3      HH   HELP FOOTER       ,datamash_reverse,,Reverse,
126,rows/columns in a tabular file,,   HELP HEADER     Syntax    This tools transposes  swaps  rows columns in a tabular input file            Example    Input file        Genes   NOX1  DcP  HH     Sample  A1    A2   B3     Counts  514   542  490  Output file        Genes  Sample  Counts     NOX1   A1      514     DcP    A2      542     HH     B3      490   HELP FOOTER       ,datamash_transpose,,Transpose,
127,Determines differentially expressed features from count tables,,Estimate variance mean dependence in count data from high throughput sequencing assays and test for differential expression based on a model using the negative binomial distribution,deseq2,"tabular,gtf,gff3",DESeq2,"tabular,pdf"
128,Determines differential exon usage from count tables,,Inference of differential exon usage in RNA Seq ,dexseq,"gtf,gff,tabular",DEXSeq,"tabular,html"
129,Prepare and count exon abundancies from RNA-seq data,,The main goal of this tool is to count the number of reads fragments per exon of each gene in RNA seq samples  In addition  it also prepares your annotation GTF file  making it compatible for counting ,dexseq_count,"gff,bam",DEXSeq-Count,"tabular,gtf"
130, differential binding analysis of ChIP-Seq peak data,,DiffBind  is a  Bioconductor package   that provides functions for processing ChIP Seq data enriched for genomic loci where specific protein DNA binding occurs  including peak sets identified by ChIP Seq peak callers and aligned sequence read datasets  It is designed to work with multiple peak sets simultaneously  representing different ChIP experiments  antibodies  transcription factor and or histone marks  experimental conditions  replicates  as well as managing the results of multiple peak callers ,diffbind,"bam,bed",DiffBind,"bed,pdf,tabular"
131,to assemble metagenomics data using an overlap-layout-consensus (OLC) approach,, DISCO is a multi threaded and multiprocess distributed memory overlap layout consensus  OLC  metagenome assembler  Disco was developed as a scalable assembler to assemble large metagenomes from billions of Illumina sequencing reads of complex microbial communities  Disco was parallelized for computer clusters in a hybrid architecture that integrated shared memory multi threading  point to point message passing  and remote direct memory access  The assembly and scaffolding were performed using an iterative overlap graph approach   The detailed user manual of the assembler and how to use it to acheive best results is provided here   This is a quick start guide generally for developers and testers  Users with limited experience with genome assembly are advised to use the user manual      ,disco,"fastq,fasta",DISCO,"txt,fasta"
132,from EBI Metagenomics database,,The European Bioinformatics Institute  EMBL EBI  maintains the world s most comprehensive range of freely available and up to date molecular databases,ebi_metagenomics_run_downloader,,Download run data,"fasta,tsv,csv,newick"
133,to obtain search results on resources and services hosted at the EBI,,The European Bioinformatics Institute  EMBL EBI  maintains the world s most comprehensive range of freely available and up to date molecular databases ,ebi_search_rest_results,,EBI Search,tabular
134,"
        Perform differential expression of count data
    ",,Given a counts matrix  or a set of counts files  for example from   featureCounts    and optional information about the genes  this tool produces plots and tables useful in the analysis of differential gene expression ,edger,tabular,edgeR,html
135, easy and efficient ensemble gene set testing,,EGSEA   an acronym for  Ensemble of Gene Set Enrichment Analyses   is a  Bioconductor package   that utilizes the analysis results of eleven prominent GSE algorithms from the literature to calculate collective significance scores for gene sets  These methods are currently    ora  globaltest  plage  safe  zscore  gage  ssgsea  roast  fry  padog  camera  gsva    The ora  gage  camera and gsva methods depend on a competitive null hypothesis while the remaining seven methods are based on a self contained hypothesis  EGSEA s gene set database  the   EGSEAdata   Bioconductor package  contains around 25 000 gene sets from 16 collections from MSigDB   KEGG  and GeneSetDB   Supported organisms are human  mouse and rat  however MSigDB is only available for human and mouse  An example  EGSEA workflow   is available at the Bioconductor workflows website ,egsea,tabular,EGSEA,"html,txt,rdata"
136,"Predicts potentially antigenic regions of a protein sequence, using the method of Kolaskar and Tongaonkar.",,     You can view the original documentation here            here     ,EMBOSS: antigenic1,data,antigenic,antigenic
137,Back translate a protein sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: backtranseq2,fasta,backtranseq,txt
138,Bending and curvature plot in B-DNA,,     You can view the original documentation here            here     ,EMBOSS: banana3,data,banana,txt
139,Replace or delete sequence sections,,    class   warningmark   The input dataset needs to be sequences                You can view the original documentation here            here     ,EMBOSS: biosed4,fasta,biosed,txt
140,Calculates the twisting in a B-DNA sequence,,     You can view the original documentation here            here     ,EMBOSS: btwisted5,data,btwisted,btwisted
141,CAI codon adaptation index,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: cai6,fasta,cai,cai
142,CAI codon adaptation index using custom codon usage file,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: cai_custom6,"fasta,txt",cai custom,txt
143,Create a chaos game representation plot for a sequence,,     You can view the original documentation here            here     ,EMBOSS: chaos7,data,chaos,png
144,Protein charge plot,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: charge8,fasta,charge,charge
145,Reports STOP codons and ORF statistics of a protein,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: checktrans9,fasta,checktrans,"checktrans,fasta,gff"
146,Codon usage statistics,,     You can view the original documentation here            here     ,EMBOSS: chips10,data,chips,chips
147,Draws circular maps of DNA constructs,,     You can view the original documentation here            here     ,EMBOSS: cirdna11,data,cirdna,png
148,Codon usage table comparison,,     You can view the original documentation here            here     ,EMBOSS: codcmp12,,codcmp,codcmp
149,"Extract CDS, mRNA and translations from feature tables",,     You can view the original documentation here            here     ,EMBOSS: coderet13,data,coderet,coderet
150,Count composition of dimer/trimer/etc words in a sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: compseq14,fasta,compseq,compseq
151,Plot CpG rich areas,,     You can view the original documentation here            here     ,EMBOSS: cpgplot15,data,cpgplot,"cpgplot,png,gff"
152,Reports all CpG rich regions,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: cpgreport16,fasta,cpgreport,"cpgreport,gff"
153,Create a codon usage table,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: cusp17,fasta,cusp,cusp
154,Removes a specified section from a sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: cutseq18,fasta,cutseq,fasta
155,Calculates DNA RNA/DNA melting temperature,,     You can view the original documentation here            here     ,EMBOSS: dan19,data,dan,dan
156,Removes gap characters from sequences,,     You can view the original documentation here            here     ,EMBOSS: degapseq20,data,degapseq,fasta
157,Alter the name or description of a sequence,,     You can view the original documentation here            here     ,EMBOSS: descseq21,data,descseq,fasta
158,Find differences between nearly identical sequences,,     You can view the original documentation here            here     ,EMBOSS: diffseq22,data,diffseq,"diffseq,gff"
159,Protein proteolytic enzyme or reagent cleavage digest,,     You can view the original documentation here            here     ,EMBOSS: digest23,data,digest,digest
160,Displays a thresholded dotplot of two sequences,,     You can view the original documentation here            here     ,EMBOSS: dotmatcher24,data,dotmatcher,png
161,Non-overlapping wordmatch dotplot of two sequences,,     You can view the original documentation here            here     ,EMBOSS: dotpath25,data,dotpath,png
162,Displays a wordmatch dotplot of two sequences,,     You can view the original documentation here            here     ,EMBOSS: dottup26,data,dottup,png
163,Regular expression search of a nucleotide sequence,,     You can view the original documentation here            here     ,EMBOSS: dreg27,data,dreg,dreg
164,Finds DNA inverted repeats,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: einverted28,fasta,einverted,einverted
165,Finds PEST motifs as potential proteolytic cleavage sites,,     You can view the original documentation here            here     ,EMBOSS: epestfind29,data,epestfind,"png,epestfind"
166,Finds tandem repeats,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: equicktandem31,fasta,equicktandem,"table,equicktandem"
167,Align EST and genomic DNA sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: est2genome32,"fasta,data",est2genome,est2genome
168,Looks for tandem repeats in a nucleotide sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: etandem33,fasta,etandem,"etandem,table"
169,Extract features from a sequence,,     You can view the original documentation here            here     ,EMBOSS: extractfeat34,data,extractfeat,fasta
170,Extract regions from a sequence,,     You can view the original documentation here            here     ,EMBOSS: extractseq35,data,extractseq,fasta
171,Residue/base frequency table or plot,,     You can view the original documentation here            here     ,EMBOSS: freak36,data,freak,freak
172,Nucleic acid pattern search,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: fuzznuc37,fasta,fuzznuc,fuzznuc
173,Protein pattern search,,     You can view the original documentation here            here     ,EMBOSS: fuzzpro38,data,fuzzpro,fuzzpro
174,Protein pattern search after translation,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: fuzztran39,fasta,fuzztran,fuzztran
175,Predicts protein secondary structure,,     You can view the original documentation here            here     ,EMBOSS: garnier40,data,garnier,garnier
176,Calculates fractional GC content of nucleic acid sequences,,     You can view the original documentation here            here     ,EMBOSS: geecee41,data,geecee,geecee
177,Finds and extracts open reading frames (ORFs),,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: getorf42,fasta,getorf,fasta
178,Report nucleic acid binding motifs,,     You can view the original documentation here            here     ,EMBOSS: helixturnhelix43,data,helixturnhelix,motif
179,Hydrophobic moment calculation,,     You can view the original documentation here            here     ,EMBOSS: hmoment44,data,hmoment,hmoment
180,Calculates the isoelectric point of a protein,,     You can view the original documentation here            here     ,EMBOSS: iep45,data,iep,iep
181,Displays some simple information about sequences,,     You can view the original documentation here            here     ,EMBOSS: infoseq46,data,infoseq,txt
182,Plots isochores in large DNA sequences,,    class   warningmark  The input dataset needs to be sequences            Syntax    This application plots GC content over a sequence  It is intended for large sequences such as complete chromosomes or large genomic contigs  although interesting results can also be obtained from shorter sequences  You can view the original documentation here            here      Both   Window size   and   Shift increment   are intergers            Example      Input sequences         hg18 dna range chrX 151073054 151073376 5 pad 0 3 pad 0 revComp FALSE strand   repeatMasking none     TTTATGTCTATAATCCTTACCAAAAGTTACCTTGGAATAAGAAGAAGTCA     GTAAAAAGAAGGCTGTTGTTCCGTGAAATACTGTCTTTATGCCTCAGATT     TGGAGTGCTCAGAGCCTCTGCAGCAAAGATTTGGCATGTGTCCTAGGCCT     GCTCAGAGCAGCAAATCCCACCCTCTTGGAGAATGAGACTCATAGAGGGA     CAGCTCCCTCCTCAGAGGCTTCTCTAATGGGACTCCAAAGAGCAAACACT     CAGCCCCATGAGGACTGGCCAGGCCAAGTGGTGTGTGGGAACAGGGAGCA     GCGGTTTCCAAGAGGATACAGTA    Output data file        Position Percent G C 1    323     80 0 422     112 0 460     144 0 509     176 0 534     208 0 553     240 0 553    Output graphics file      image     static emboss icons isochore png   ,EMBOSS: isochore47,fasta,isochore,"png,isochore"
183,Draws linear maps of DNA constructs,,     You can view the original documentation here            here     ,EMBOSS: lindna48,data,lindna,png
184,Finds MAR/SAR sites in nucleic sequences,,     You can view the original documentation here            here     ,EMBOSS: marscan49,data,marscan,gff
185,Mask off features of a sequence,,     You can view the original documentation here            here     ,EMBOSS: maskfeat50,data,maskfeat,fasta
186,Mask off regions of a sequence,,     You can view the original documentation here            here     ,EMBOSS: maskseq51,data,maskseq,fasta
187,Finds the best local alignments between two sequences,,     You can view the original documentation here            here     ,EMBOSS: matcher52,data,matcher,markx0
188,Merge two large overlapping nucleic acid sequences,,     You can view the original documentation here            here     ,EMBOSS: megamerger53,data,megamerger,"fasta,txt"
189,Merge two overlapping nucleic acid sequences,,     You can view the original documentation here            here     ,EMBOSS: merger54,data,merger,"fasta,simple"
190,Mutate sequence beyond all recognition,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: msbar55,fasta,msbar,fasta
191,Needleman-Wunsch global alignment,,    class   warningmark  needle reads any two sequences of the same type  DNA or protein             Syntax    This tool uses the Needleman Wunsch global alignment algorithm to find the optimum alignment  including gaps  of two sequences when considering their entire length       Optimal alignment    Dynamic programming methods ensure the optimal global alignment by exploring all possible alignments and choosing the best       The Needleman Wunsch algorithm   is a member of the class of algorithms that can calculate the best score and alignment in the order of mn steps   where  n  and  m  are the lengths of the two sequences        Gap open penalty     10 0 for any sequence  The gap open penalty is the score taken away when a gap is created  The best value depends on the choice of comparison matrix  The default value assumes you are using the EBLOSUM62 matrix for protein sequences  and the EDNAFULL matrix for nucleotide sequences   Floating point number from 1 0 to 100 0       Gap extension penalty     0 5 for any sequence  The gap extension  penalty is added to the standard gap penalty for each base or residue in the gap  This is how long gaps are penalized  Usually you will expect a few long gaps rather than many short gaps  so the gap extension penalty should be lower than the gap penalty  An exception is where one or both sequences are single reads with possible sequencing errors in which case you would expect many single base gaps  You can get this result by setting the gap open penalty to zero  or very low  and using the gap extension penalty to control gap scoring   Floating point number from 0 0 to 10 0   You can view the original documentation here            here             Example      Input File         hg18 dna range chrX 151073054 151073136 5 pad 0 3 pad 0 revComp FALSE strand   repeatMasking none     TTTATGTCTATAATCCTTACCAAAAGTTACCTTGGAATAAGAAGAAGTCA     GTAAAAAGAAGGCTGTTGTTCCGTGAAATACTG    If both Sequence1 and Sequence2 take the above file as input  Gap open penalty equals 10 0  Gap extension penalty equals 0 5  Brief identity and similarity is set to Yes  Output alignment file format is set to SRS pairs  the output file is                                                       Program  needle       Rundate  Mon Apr 02 2007 14 23 16       Align format  srspair       Report file    database files dataset 7 dat                                                                                                        Aligned sequences  2       1  hg18 dna       2  hg18 dna       Matrix  EDNAFULL       Gap penalty  10 0       Extend penalty  0 5             Length  83       Identity       83 83  100 0         Similarity     83 83  100 0         Gaps            0 83   0 0         Score  415 0                                                         hg18 dna           1 TTTATGTCTATAATCCTTACCAAAAGTTACCTTGGAATAAGAAGAAGTCA     50                                                                               hg18 dna           1 TTTATGTCTATAATCCTTACCAAAAGTTACCTTGGAATAAGAAGAAGTCA     50      hg18 dna          51 GTAAAAAGAAGGCTGTTGTTCCGTGAAATACTG     83                                                              hg18 dna          51 GTAAAAAGAAGGCTGTTGTTCCGTGAAATACTG     83                                                                                              ,EMBOSS: needle56,fasta,needle,needle
192,Report CpG rich areas,,     You can view the original documentation here            here     ,EMBOSS: newcpgreport57,data,newcpgreport,newcpgreport
193,Reports CpG rich region,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: newcpgseek58,fasta,newcpgseek,newcpgseek
194,Type in a short new sequence,,     You can view the original documentation here            here     ,EMBOSS: newseq59,,newseq,fasta
195,Removes carriage return from ASCII files,,     You can view the original documentation here            here     ,EMBOSS: noreturn60,data,noreturn,noreturn
196,Exclude a set of sequences and write out the remaining ones,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: notseq61,fasta,notseq,fasta
197,Writes one sequence from a multiple set of sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: nthseq62,fasta,nthseq,fasta
198,Displays protein hydropathy,,     You can view the original documentation here            here     ,EMBOSS: octanol63,data,octanol,png
199,Find protein sequence regions with a biased composition,,     You can view the original documentation here            here     ,EMBOSS: oddcomp64,data,oddcomp,oddcomp
200,Looks for inverted repeats in a nucleotide sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: palindrome65,fasta,palindrome,palindrome
201,Insert one sequence into another,,    class   warningmark  The input datasets need to be sequences              You can view the original documentation here            here     ,EMBOSS: pasteseq66,fasta,pasteseq,fasta
202,Search a protein sequence with a motif,,     You can view the original documentation here            here     ,EMBOSS: patmatdb67,data,patmatdb,dbmotif
203,Predicts coiled coil regions,,     You can view the original documentation here            here     ,EMBOSS: pepcoil68,data,pepcoil,pepcoil
204,Plots simple amino acid properties in parallel,,     You can view the original documentation here            here     ,EMBOSS: pepinfo69,data,pepinfo,"pepinfo,png"
205,Displays proteins as a helical net,,     You can view the original documentation here            here     ,EMBOSS: pepnet70,data,pepnet,png
206,Protein statistics,,     You can view the original documentation here            here     ,EMBOSS: pepstats71,data,pepstats,pepstats
207,Shows protein sequences as helices,,     You can view the original documentation here            here     ,EMBOSS: pepwheel72,data,pepwheel,png
208,Displays protein hydropathy,,     You can view the original documentation here            here     ,EMBOSS: pepwindow73,data,pepwindow,png
209,Displays protein hydropathy of a set of sequences,,     You can view the original documentation here            here     ,EMBOSS: pepwindowall74,data,pepwindowall,png
210,Plot quality of conservation of a sequence alignment,,     You can view the original documentation here            here     ,EMBOSS: plotcon75,data,plotcon,png
211,Plot potential open reading frames,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: plotorf76,fasta,plotorf,png
212,Displays all-against-all dotplots of a set of sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: polydot77,fasta,polydot,"polydot,png"
213,Regular expression search of a protein sequence,,     You can view the original documentation here            here     ,EMBOSS: preg78,data,preg,preg
214,"Displays aligned sequences, with colouring and boxing",,     You can view the original documentation here            here     ,EMBOSS: prettyplot79,data,prettyplot,png
215,Output sequence with translated ranges,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: prettyseq80,fasta,prettyseq,prettyseq
216,Searches DNA sequences for matches with primer pairs,,     You can view the original documentation here            here     ,EMBOSS: primersearch81,"fasta,data",primersearch,primersearch
217,Reverse and complement a sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: revseq82,fasta,revseq,fasta
218,All-against-all comparison of a set of sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: seqmatchall83,fasta,seqmatchall,seqmatchall
219,Reads and writes sequences,,     You can view the original documentation here            here     ,EMBOSS: seqret84,data,seqret,fasta
220,Show features of a sequence,,     You can view the original documentation here            here     ,EMBOSS: showfeat85,data,showfeat,showfeat
221,Shuffles a set of sequences maintaining composition,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: shuffleseq87,fasta,shuffleseq,fasta
222,Reports protein signal cleavage sites,,     You can view the original documentation here            here     ,EMBOSS: sigcleave88,data,sigcleave,motif
223,Finds siRNA duplexes in mRNA,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: sirna89,fasta,sirna,"table,fasta"
224,Display a DNA sequence with 6-frame translation and ORFs,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: sixpack90,fasta,sixpack,"sixpack,fasta"
225,"Reads and writes sequences, skipping first few",,     You can view the original documentation here            here     ,EMBOSS: skipseq91,data,skipseq,fasta
226,Split a sequence into (overlapping) smaller sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: splitter92,fasta,splitter,fasta
227,Match large sequences against one or more other sequences,,     You can view the original documentation here            here     ,EMBOSS: supermatcher95,"fasta,data",supermatcher,"simple,supermatcher"
228,Synonymous codon usage Gribskov statistic plot,,     You can view the original documentation here            here     ,EMBOSS: syco96,fasta,syco,"png,syco"
229,Fickett TESTCODE statistic to identify protein-coding DNA,,     You can view the original documentation here            here     ,EMBOSS: tcode97,data,tcode,table
230,"Search sequence documentation. Slow, use SRS and Entrez!",,     You can view the original documentation here            here     ,EMBOSS: textsearch98,data,textsearch,textsearch
231,Displays membrane spanning regions,,     You can view the original documentation here            here     ,EMBOSS: tmap99,data,tmap,"seqtable,png"
232,Align nucleic coding regions given the aligned proteins,,     You can view the original documentation here            here     ,EMBOSS: tranalign100,"fasta,data",tranalign,fasta
233,Translate nucleic acid sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: transeq101,fasta,transeq,fasta
234,Trim poly-A tails off EST sequences,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: trimest102,fasta,trimest,fasta
235,Trim ambiguous bits off the ends of sequences,,    class   warningmark   The input dataset needs to be sequences                You can view the original documentation here            here     ,EMBOSS: trimseq103,fasta,trimseq,fasta
236,Finds neighbouring pairs of features in sequences,,     You can view the original documentation here            here     ,EMBOSS: twofeat104,data,twofeat,table
237,Reads sequence fragments and builds one sequence,,    class   warningmark   The input dataset needs to be sequences                You can view the original documentation here            here     ,EMBOSS: union105,fasta,union,fasta
238,Strips out DNA between a pair of vector sequences,,     You can view the original documentation here            here     ,EMBOSS: vectorstrip106,"fasta,data",vectorstrip,"fasta,vectorstrip"
239,Smith-Waterman local alignment,,    class   warningmark  The input datasets need to be sequences              You can view the original documentation here            here     ,EMBOSS: water107,fasta,water,srs
240,Wobble base plot,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: wobble108,fasta,wobble,"png,wobble"
241,Counts words of a specified size in a DNA sequence,,    class   warningmark  The input dataset needs to be sequences              You can view the original documentation here            here     ,EMBOSS: wordcount109,fasta,wordcount,wordcount
242,Finds all exact matches of a given size between 2 sequences,,    class   warningmark  The input datasets need to be sequences              You can view the original documentation here            here     ,EMBOSS: wordmatch110,fasta,wordmatch,"match,gff"
243,,,This tool retrieve an analysis report for an accession id     ,enasearch_retrieve_analysis_report,,Retrieve an analysis report,tabular
244,(other than taxon and project),,This tool retrieve ENA data  other than taxon and project      ,enasearch_retrieve_data,,Retrieve ENA data,tabular
245,,,This tool retrieve a run report for an accession id     ,enasearch_retrieve_run_report,,Retrieve a run report,tabular
246,,,This tool retrieve ENA taxon data,enasearch_retrieve_taxons,,Retrieve ENA taxon data,tabular
247,given a query,,This tool retrieve ENA taxon data     ,enasearch_search_data,,Search ENA data,tabular
248,,,export2graphlan is a conversion software tool to produce both annotation and tree file for GraPhlAn  It can convert MetaPhlAn  LEfSe  and or HUMAnN output to GraPhlAn input format,export2graphlan,"tabular,txt,tsv,tabular",Export to GraPhlAn,txt
249,using coordinates from assembled/unassembled genomes,,This tool uses coordinate  strand  and build information to fetch genomic DNAs in FASTA or interval format ,Extract genomic DNA 1,"gff,interval,fasta",Extract Genomic DNA,
250,,,Produces a graphical representation of FASTA data with each nucleotide represented by a selected color ,fasta_nucleotide_color_plot,fasta,Fasta nucleotide color plot,png
251,Read Quality reports,,    class   infomark    Purpose    FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines  It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis   The main functions of FastQC are     Import of data from BAM  SAM or FastQ FastQ gz files  any variant     Providing a quick overview to tell you in which areas there may be problems   Summary graphs and tables to quickly assess your data   Export of results to an HTML based permanent report   Offline operation to allow automated generation of reports without running the interactive application            class   infomark    FastQC    This is a Galaxy wrapper  It merely exposes the external package FastQC  which is documented at FastQC  Kindly acknowledge it as well as this tool if you use it  FastQC incorporates the Picard tools  libraries for SAM BAM processing   The contaminants file parameter was borrowed from the independently developed fastqcwrapper contributed to the Galaxy Community Tool Shed by J  Johnson  Adaption to version 0 11 2 by T  McGowan             class   infomark    Inputs and outputs    FastQC  is the best place to look for documentation   it s very good  A summary follows below for those in a tearing hurry   This wrapper will accept a Galaxy fastq  fastq gz  sam or bam as the input read file to check  It will also take an optional file containing a list of contaminants information  in the form of a tab delimited file with 2 columns  name and sequence  As another option the tool takes a custom limits txt file that allows setting the warning thresholds for the different modules and also specifies which modules to include in the output   The tool produces a basic text and a HTML output file that contain all of the results  including the following     Basic Statistics   Per base sequence quality   Per sequence quality scores   Per base sequence content   Per base GC content   Per sequence GC content   Per base N content   Sequence Length Distribution   Sequence Duplication Levels   Overrepresented sequences   Kmer Content  All except Basic Statistics and Overrepresented sequences are plots       FastQC        Picard tools       ,fastqc,"fastq,fastq.gz,fastq.bz2,bam,sam,tabular,txt",FastQC,"html,txt"
252,Measure gene expression in RNA-Seq experiments from SAM or BAM files.,, featureCounts                Overview          FeatureCounts is a light weight read counting program written entirely in the C programming language  It can be used to count both gDNA seq and RNA seq reads for genomic features in in SAM BAM files  FeatureCounts is part of the Subread  package   Input formats               Alignments should be provided in either      SAM format   5    BAM format  Annotations for gene regions should be provided in the GFF GTF format       format3      Alternatively  the featureCounts built in annotations for genomes hg38  hg19  mm10 and mm9 can be used through selecting the built in option above  These annotations were downloaded from NCBI RefSeq database and then adapted by merging overlapping exons from the same gene to form a set of disjoint exons for each gene  Genes with the same Entrez gene identifiers were also merged into one gene  See the Subread  User s Guide for more information   Output format               FeatureCounts produces a table containing counted reads  per gene  per row  Optionally the last column can be set to be the effective gene length  These tables are compatible with the DESeq2 Galaxy wrapper by IUC  Column names are added as metadata object       Subread       ,featurecounts,"bam,sam,gff,gtf,gff3,fasta",featureCounts,tabular
253,assembles Illumina reads into unitigs,, fermi2 can assemble reads into unitigs  Unitig output can be further analysed by alignment to a reference genome using bwa mem  and based on the alignment variants can be called using the fermi variants tool         Usage    fermi2 pl unitig  options   in fq     Options   p STR    output prefix  fmdef              s STR    approximate genome size  100m              2        2 pass error correction             l INT    primary read length  101              T INT    use INT mer for post trimming filtering  61              k INT    min overlap length during unitig construction  based on  l              o INT    min overlap length during graph cleaning  based on  l              m INT    min overlap length for unambiguous merging  based on  l              t INT    number of threads  4              E        don t apply error correction      ,fermi2,"fastqsanger,fastqsanger.gz",fermi2,fastqsanger.gz
254,call variants from genome-aligned contigs,,  FermiKit is a de novo assembly based variant calling pipeline for deep Illumina resequencing data  This galaxy wrapper can be used to call variants from contigs generated by fermi2 that have subsequently been aligned to a reference genome using bwa  options  B9  O16  L5 or  x intractg    ,fermikit_variants,"bam,fasta",fermikit-variants,vcf
255,adjust length of short reads,,  FLASH  Fast Length Adjustment of SHort reads  is an accurate and fast tool to merge paired end reads that were generated from DNA fragments whose lengths are shorter than twice the length of reads   Merged read pairs result in unpaired longer reads  which are generally more desired in genome assembly and genome analysis processes   Briefly  the FLASH algorithm considers all possible overlaps at or above a minimum length between the reads in a pair and chooses the overlap that results in the lowest mismatch density  proportion of mismatched bases in the overlapped region    Ties between multiple overlaps are broken by considering quality scores at mismatch sites   When building the merged sequence  FLASH computes a consensus sequence in the overlapped region       ,flash,"fastqsanger,fastqsolexa,fastqillumina",FLASH,"tabular,txt"
256,for finding (fragmented) genes in short reads,,FragGeneScan is an application for finding  fragmented  genes in short reads  It can also be applied to predict prokaryotic genes in incomplete assemblies or complete genomes  ,fraggenescan,fasta,FragGeneScan,"tabular,fasta,gff"
257,bayesian genetic variant detector,,FreeBayes is a Bayesian genetic variant detector designed to find small polymorphisms  specifically SNPs  single nucleotide polymorphisms   indels  insertions and deletions   MNPs  multi nucleotide polymorphisms   and complex events  composite insertion and substitution events  smaller than the length of a short read sequencing alignment ,freebayes,"fasta,bed,txt,vcf_bgzip,vcf,tabular",FreeBayes,"vcf,bed,txt"
258, indels in BAM datasets,,  When calling indels  it is important to homogenize the positional distribution of insertions and deletions in the input by using left realignment  Left realignment will place all indels in homopolymer and microsatellite repeats at the same position  provided that doing so does not introduce mismatches between the read and reference other than the indel  This method is computationally inexpensive and handles the most common classes of alignment inconsistency   This is leftalign utility from FreeBayes package      ,bamleftalign,"bam,fasta",BamLeftAlign,bam
259,"an intuitive interface to filter, extract, and convert Genomic Data Commons experiments",,,data_source_gdcwebapp,,GDCWebApp,auto
260,Retrieve genes with actionable somatic mutations via COSMIC and DGIdb,,Retrieve genes with actionable somatic mutations via COSMIC and DGIdb  It checks for variants that have the somatic flag set  which can be done with GEMINI set somatic  with high or medium impact severity  The results are then compared to entries in COSMIC and DGIdb,gemini_@BINARY@,,GEMINI @BINARY@,tabular
261,Amend an already loaded GEMINI database.,,Gemini amend adds information about the samples via PED file ,gemini_@BINARY@,tabular,GEMINI @BINARY@,gemini.sqlite
262,adding your own custom annotations,,It is inevitable that researchers will want to enhance the GEMINI framework with their own  custom annotations  GEMINI provides a sub command called annotate for exactly this purpose ,gemini_@BINARY@,"vcf,bed",GEMINI @BINARY@,tabular
263,Find variants meeting an autosomal recessive/dominant model,,Assuming you have defined the familial relationships between samples when loading your VCF into GEMINI  one can leverage a built in tool for identifying variants that meet an autosomal recessive or dominant inheritance pattern  The reported variants will be restricted to those variants having the potential to impact the function of affecting protein coding transcripts ,gemini_recessive_and_dominant,,GEMINI autosomal recessive/dominant,tabular
264,perform sample-wise gene-level burden calculations,,Burden performs sample wise gene level burden calculations ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
265,Identifying potential compound heterozygotes,,Many recessive disorders are caused by compound heterozygotes  Unlike canonical recessive sites where the same recessive allele is inherited from both parents at the  same  site in the gene  compound heterozygotes occur when the individual s phenotype is caused by two heterozygous recessive alleles at  different  sites in a particular gene ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
266,List the gemini database tables and columns,,Because of the sheer number of annotations that are stored in gemini  there are admittedly too many columns to remember by rote  If you can t recall the name of particular column  just use the db info tool  It will report all of the tables and all of the columns   types in each table  ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
267,Identifying potential de novo mutations,,Assuming you have defined the familial relationships between samples when loading your VCF into GEMINI  you can use this tool for identifying de novo  a k a spontaneous  mutations that arise in offspring ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
268,Extract data from the Gemini DB,,Reports information in a Gemini database ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
269,Identify somatic fusion genes from a GEMINI database,,Identifies somatic fusion genes from a GEMINI database ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
270,Custom genotype filtering by gene,,The gemini query tool allows querying by variant and the inheritance tools described above enable querying by gene for fixed inheritance patterns  The gene wise tool allows querying by gene with custom genotype filters to bridge the gap between these tools ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
271,Find genes among variants that are interacting partners,,Integrating the knowledge of the known protein protein interactions would be useful in explaining variation data  Meaning to say that a damaging variant in an interacting partner of a potential protein may be equally interesting as the protein itself  We have used the HPRD  binary interaction data to build a p p network graph which can be explored by GEMINI ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
272,Loading a VCF file into GEMINI,,Before we can use GEMINI to explore genetic variation  we must first load our VCF file into the GEMINI database framework  We expect you to have first annotated the functional consequence of each variant in your VCF using either VEP or snpEff ,gemini_@BINARY@,"vcf,tabular",GEMINI @BINARY@,gemini.sqlite
273,Filter LoF variants by transcript position and type,, Filter LoF variants by transcript position and type ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
274,Identify candidate violations of Mendelian inheritance,,Assuming you have defined the familial relationships between samples when loading your VCF into GEMINI  you can use this tool for identifying mutations that violate the Mendelian inheritance scheme ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
275,Map genes and variants to KEGG pathways,,Mapping genes to biological pathways is useful in understanding the function role played by a gene  Likewise  genes involved in common pathways is helpful in understanding heterogeneous diseases  We have integrated the KEGG pathway mapping for gene variants  to explain annotate variation ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
276,Quality control tool,,Checks whether the given sex of the samples are probable  It issues the query  ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
277,Querying the GEMINI database,,The real power in the GEMINI framework lies in the fact that all of your genetic variants have been stored in a convenient database in the context of a wealth of genome annotations that facilitate variant interpretation  The expressive power of SQL allows one to pose intricate questions of one s variation data  This tool offers you an easy way to query your variants ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
278,Extracting variants from specific regions or genes,,One often is concerned with variants found solely in a particular gene or genomic region ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
279,Identifying runs of homozygosity,,                                                                              ROH    Identifying runs of homozygosity                                                                             Runs of homozygosity are long stretches of homozygous genotypes that reflect segments shared identically by descent and are a result of consanguinity or natural selection  Consanguinity elevates the occurrence of rare recessive diseases  e g  cystic fibrosis  that represent homozygotes for strongly deleterious mutations  Hence  the identification of these runs holds medical value ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
280,Tag somatic mutations in a GEMINI database,,Gemini set somatic sets the flag  is somatic  by comparing tumor normal pairs in an already loaded Gemini database  ,gemini_@BINARY@,,GEMINI @BINARY@,gemini.sqlite
281,Compute useful variant statistics,,The stats tool computes some useful variant statistics for a GEMINI database  Like computing the transition and transversion ratios for the snps ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
282,"Conducting analyses on genome ""windows""",,It computs variation metrics across genomic windows  both fixed and sliding  ,gemini_@BINARY@,,GEMINI @BINARY@,tabular
283,Linkage and Haplotypes analysis,,    Genehunter MODscore   calculates a  maximized LOD   MOD  score over a set of genotypes for use in linkage and haplotype analysis   Haplotypes are generated using either this maximum probability approach  or via slower more conventional Viterbi crawling   Untyped founders can be simulated by reconstructing their haplotypes from offspring  and points of recombination can still be accurately determined in lieu of this   Due to the stochastic nature of the analysis  a random seed can be set by the user to produce reproducible results   Many more configurable options are outlined in the the official manual        manual         ,genehunter_modscore,"linkage_pedin,linkage_datain,linkage_map,txt",Genehunter-Modscore,"allegro_ihaplo,allegro_fparam"
284,peak predictor,,GeneTrack separately identifies peaks on the forward      W  and reverse      C  strand   The way that GeneTrack works is to replace each tag with a probabilistic distribution of occurrences for that tag at and around its mapped genomic coordinate   The distance decay of the probabilistic distribution is set by adjusting the value of the tool s   Sigma to use when smoothing reads   parameter   GeneTrack then sums the distribution over all mapped tags   This results in a smooth continuous trace that can be globally broadened or tightened by adjusting the sigma value   GeneTrack starts with the highest smoothed peak first  treating each strand separately if indicated by the data  then sets up an exclusion zone  centered over the peak  defined by the value of the   Peak exclusion zone   parameter  see figure    The exclusion zone prevents any secondary peaks from being called on the same strand within that exclusion zone   In rare cases  it may be desirable to set different exclusion zones upstream  more 5   versus downstream  more 3   of the peak ,genetrack,"scidx,gff",GeneTrack,
285,against parent features,,Often the genomic data processing analysis process requires a workflow like the following ,gff3.rebase,gff3,Rebase GFF3 features,gff3
286,compare assembled transcripts to a reference annotation,,    GffCompare Overview       GffCompare   compare and evaluate the accuracy of RNA Seq transcript assemblers  Cufflinks  Stringtie     collapse  merge  duplicate transcripts from multiple GTF GFF3 files  e g  resulted from assembly of different samples    classify transcripts from one or multiple GTF GFF3 files as they relate to reference transcripts provided in a annotation file  also in GTF GFF3 format   The original form of this program is also distributed as part of the Cufflinks suite  under the name  CuffCompare   see manual   Most of the options and parameters of CuffCompare are supported by GffCompare  while new features will likely be added to GffCompare in the future   A notable difference from GffCompare is that when a single query GTF GFF file is given as input  along with a reference annotation   r option   gffcompare switches into  annotation mode  and it generates a  annotated gtf file instead of the  merged gtf produced by CuffCompare with the same parameters  This file has the same general format as CuffCompare s  merged gtf file  with  class codes  assigned to transcripts as per their relationship with the matching overlapping reference transcript    but the original transcript IDs are preserved  so gffcompare can thus be used as a simple way of annotating a set of transcripts   Another important difference is that the input transcripts are no longer discarded when they are found to be  intron redundant   i e  contained within other  longer isoforms  CuffCompare had the  G option to prevent collapsing of such intron redundant isoforms into their longer  containers   but GffCompare has made this the default mode of operation  hence the  G option is no longer needed and is simply ignored when given            ,gffcompare,"gtf,gff3,gtf,fasta",GffCompare,"txt,tabular,gtf"
287,,,  This tool will generate a histogram representing the distrinutions of each numerical column  Each column should have a descriptive header with no spaces  which will be used in the plot legend to represent the corresponding column  group    Input data example  ID  Cond A Cond B gene A  10  15 gene B  8   12 gene C 10   15 gene D  6   9 gene E  9   13 5 gene F  8   12      ,ggplot2_histogram,tabular,Histogram w ggplot2,pdf
288,,,         This tool will generate a scatterplot representing data from two groups conditions            The input data should be in tabular format and the user can determine which groups  columns  to plot           Multiple groups can be plotted on the same or multiple plots by providing a column with a group identifier under  Advanced   plotting multiple groups            Feel free to explore the  many  advanced options to customize your plot  Galaxy makes this type optimization easy for the user             The ouput is a pdf file with your scatterplot  The dimensions of this file can be modified under  Advanced   output dimensions       ,ggplot2_point,tabular,Scatterplot w ggplot2,pdf
289,,,         Supply this tool with a text file with headers indicating the various groups to be plotted  This tool will sniff out each column with values that can be plotted and display the distribution of that data group  Note that columns may be excluded from this plot if they contain questionable characters        ,ggplot2_violin,tabular,Violin plot w ggplot2,pdf
290,,, This tool will generate a clustered heatmap of your data  More customization options will be added  for now the heatmap uses a red coloring scheme and clustering is performed using the  maximum  similarity measure and the  complete  hierarchical clustering measure    Input data should have row labels in the first column and column labels  For example  the row labels  the first column  should represent gene IDs and the column labels should represent sample IDs    This wrapper employs the heatmap 2 function of R      ,ggplot2_heatmap2,tabular,heatmap2,pdf
291,of windows in each sequence,,This tool calculates the ACGT Content from a given Sequence  given a sliding window ,glimmer_acgt_content,fasta,ACGT Content,tabular
292,,,This program constructs an interpolated context model  ICM  from an input set of sequences ,glimmer_build_icm,fasta,Glimmer ICM builder,data
293,from a genome,, This program reads a genome sequence and a list of coordinates for it and outputs a multi   fasta file of the regions specified by the coordinates ,glimmer_extract,"fasta,tabular",Extract sequence regions,fasta
294,from a GenBank file,,     ,glimmer_gbk_to_orf,genbank,Extract ORF,fasta
295,,,Converts a Glimmer3 output File to an GFF Annotation File  ,glimmer_glimmer_to_gff,tabular,Convert Glimmer to GFF,gff
296,"identify long, non-overlapping ORFs",,    This program identifies long  non overlapping open reading frames  orfs  in a DNA sequence file      These orfs are very likely to contain genes  and can be used as a set of training sequences     More specifically  among all orfs longer than a minimum length   those that do not overlap any others are output  The start codon used for     each orf is the first possible one  The program  by default  automatically determines the     value that maximizes the number of orfs that are output  With the  t option  the initial     set of candidate orfs also can be filtered using entropy distance  which generally produces     a larger  more accurate training set  particularly for high GC content genomes ,glimmer_long_orfs,fasta,Glimmer long ORFs,tabular
297,Predict ORFs in prokaryotic genomes (knowlegde-based),,This is the main program that makes gene predictions based on an interpolated context model  ICM  ,glimmer_knowledge_based,"fasta,tar",Glimmer3,"fasta,txt"
298,Predict ORFs in prokaryotic genomes (not knowlegde-based),,This tool predicts open reading frames  ORFs  from a given DNA Sequence  That tool is not knowlegde based ,glimmer_not_knowledge_based,fasta,Glimmer3,"fasta,txt"
299,tests for overrepresented gene categories,, Gene Ontology    GO  analysis is widely used to reduce complexity and highlight biological processes in genome wide expression studies  but standard methods give biased results on RNA seq data due to over detection of differential expression for long and highly expressed transcripts  This tool provides methods for performing GO analysis of RNA seq data  taking length bias into account  The methods and software used by goseq are equally applicable to other category based tests of RNA seq data  such as KEGG  pathway analysis ,goseq,tabular,goseq,"tabular,pdf,rdata"
300,to produce graphical output of an input tree,,GraPhlAn is a software tool for producing high quality circular representations of taxonomic and phylogenetic trees  GraPhlAn focuses on concise  integrative  informative  and publication ready representations of phylogenetically  and taxonomically driven investigation ,graphlan,"txt,nhx,phyloxml",GraPhlAn,"png,pdf,ps,eps,svg"
301,for GraPhlAn,,GraPhlAn is a software tool for producing high quality circular representations of taxonomic and phylogenetic trees  GraPhlAn focuses on concise  integrative  informative  and publication ready representations of phylogenetically  and taxonomically driven investigation ,graphlan_annotate,"txt,nhx,nex,phyloxml,txt","Generation, personalization and annotation of tree",phyloxml
302,Recombination detection in Bacteria,,   Gubbins    Since the introduction of high throughput  second generation DNA sequencing technologies  there has been an enormous increase in the size of datasets being used for estimating bacterial population phylodynamics  Although many phylogenetic techniques are scalable to hundreds of bacterial genomes  methods which have been used for mitigating the effect of mechanisms of horizontal sequence transfer on phylogenetic reconstructions cannot cope with these new datasets  Gubbins  Genealogies Unbiased By recomBinations In Nucleotide Sequences  is an algorithm that iteratively identifies loci containing elevated densities of base substitutions while concurrently constructing a phylogeny based on the putative point mutations outside of these regions  Simulations demonstrate the algorithm generates highly accurate reconstructions under realistic models of short term bacterial evolution  and can be run in only a few hours on alignments of hundreds of bacterial genome sequences     Running Gubbins    To run Gubbins with default settings   Supply a  fasta  genome alignment file and press execute     Other options       Advanced     Iterations     i    The maximum number of iterations to perform  the algorithm will stop earlier than this if it converges on the same tree in two successive iterations  Default is 5    Converge method    z   Criteria to use to know when to halt iterations  weighted robinson foulds robinson foulds recombination   Default is weighted robinson foulds    Outgroup     o    The name of a sequence in the alignment on which to root the tree    Really Advanced    These options are here for completeness and you shouldn t need to change them from their defaults  You really need to know what you are doing before you use these    Tree builder     t   The algorithm to use in the construction of phylogenies in the analysis  can be  raxml   to use RAxML   fasttree   to use Fasttree  or  hybrid   to use Fasttree for the first iteration and RAxML in all subsequent iterations  Default is raxml  Filter Percentage    f    Filter out taxa with more than this percentage of missing data  Default is 25    Minimum snps     m    The minimum number of base substitutions required to identify a recombination  Default is 3    And others         Output files      Recombination predictions in EMBL tab file format      Recombination predictions in GFF3 format     Base substitution reconstruction in EMBL tab format      VCF file summarising the distribution of SNPs     Per branch reporting of the base substitutions inside and outside recombinations events      FASTA format alignment of filtered polymorphic sites used to generate the phylogeny in the final iteration      Phylip format alignment of filtered polymorphic sites used to generate the phylogeny in the final iteration      Final phylogenetic tree in newick format       ,gubbins,fasta,Gubbins,"txt,gff3,embl,fasta,phylip,csv,vcf"
303,Removes all non-variant blocks from a gVCF file to produce a smaller variant-only VCF file.,,          Extract variants from a gVCF field  removing all non variant blocks to yield a smaller variant only VCF file       From the  gvcftools   toolkit           gvcftools          ,gvcftools_extract_variants,vcf,Extract Variants from gVCF files,vcf
304,,,                                                               bio hansel   Heidelberg And eNteritidis Snp ELucidation                                                              Subtype  Salmonella enterica  subsp  enterica serovar Heidelberg and Enteritidis genomes using  in silico  33 bp k mer SNP subtyping schemes developed by Genevieve Labbe et al  Subtype  Salmonella  genome assemblies  FASTA files  and or whole genome sequencing reads  FASTQ files         Usage       1  Enter your FASTA FASTQ file s  2  Select which scheme you would like to use  e g  heidelberg  enteritidis  or specify your own  3  Click Execute  For more information visit      Example Usage                Analysis of a single FASTA file                                  Contents of   results tab                                                                                                                                                                                                                                                                                                                                                                                                                       sample       scheme       subtype       all subtypes                                     tiles matching subtype                                          are subtypes consistent   inconsistent subtypes   n tiles matching all   n tiles matching all total   n tiles matching positive   n tiles matching positive total   n tiles matching subtype   n tiles matching subtype total   file path                                                                                                                                                                                                                                                                                                                                                                                                                      file fasta   heidelberg   2 2 2 2 1 4   2  2 2  2 2 2  2 2 2 2  2 2 2 2 1  2 2 2 2 1 4   1037658 2 2 2 2 1 4  2154958 2 2 2 2 1 4  3785187 2 2 2 2 1 4   True                                              202                    202                          17                          17                                3                          3                                file fasta                                                                                                                                                                                                                                                                                                                                                                                                                  Contents of   match results tab                                                                                                                                                                                                                                                                                                                                               tilename                      stitle                                  pident   length   mismatch   gapopen   qstart   qend   sstart   send     evalue   bitscore   qlen   slen     seq                                 coverage   is trunc   refposition       subtype       is pos tile   sample   file path    scheme                                                                                                                                                                                                                                                                                                                                                 775920 2 2 2 2                NODE 2 length 512016 cov 46 4737 ID 3   100      33       0          0         1        33     474875   474907   2E 11    62 1       33     512016   GTTCAGGTGCTACCGAGGATCGTTTTTGGTGCG   1          False      775920            2 2 2 2       True          out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3305400 2 1 1 1       NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     276235   276267   2E 11    62 1       33     427905   CATCGTGAAGCAGAACAGACGCGCATTCTTGCT   1          False      negative3305400   2 1 1 1       False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3200083 2 1           NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     170918   170950   2E 11    62 1       33     427905   ACCCGGTCTACCGCAAAATGGAAAGCGATATGC   1          False      negative3200083   2 1           False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3204925 2 2 3 1 5     NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     175760   175792   2E 11    62 1       33     427905   CTCGCTGGCAAGCAGTGCGGGTACTATCGGCGG   1          False      negative3204925   2 2 3 1 5     False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3230678 2 2 2 1 1 1   NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     201513   201545   2E 11    62 1       33     427905   AGCGGTGCGCCAAACCACCCGGAATGATGAGTG   1          False      negative3230678   2 2 2 1 1 1   False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3233869 2 1 1 1 1     NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     204704   204736   2E 11    62 1       33     427905   CAGCGCTGGTATGTGGCTGCACCATCGTCATTA   1          False      negative3233869   2 1 1 1 1     False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3254229 2 2 3 1 3     NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     225064   225096   2E 11    62 1       33     427905   CGCCACCACGCGGTTAGCGTCACGCTGACATTC   1          False      negative3254229   2 2 3 1 3     False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3257074 2 2 1         NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     227909   227941   2E 11    62 1       33     427905   CGGCAACCAGACCGACTACGCCGCCAAGCAGAC   1          False      negative3257074   2 2 1         False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3264474 2 2 2 1 1 1   NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     235309   235341   2E 11    62 1       33     427905   AATGGCGCCGATCGTCGCCAGATAACCGTTGCC   1          False      negative3264474   2 2 2 1 1 1   False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3267927 2 2 2 2 2 1   NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     238762   238794   2E 11    62 1       33     427905   AAAGAGAAATATGATGCCAGGCTGATACATGAC   1          False      negative3267927   2 2 2 2 2 1   False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3278067 1 1           NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     248902   248934   2E 11    62 1       33     427905   TGTGAGTAAGTTGCGCGATATTCTGCTGGATTC   1          False      negative3278067   1 1           False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3299717 2 2 3 1 4     NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     270552   270584   2E 11    62 1       33     427905   ATGCCGGACAGCAGGCGAAACTCGAACCGGATA   1          False      negative3299717   2 2 3 1 4     False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                             negative3373069 2 2 2 2 1 1   NODE 3 length 427905 cov 48 1477 ID 5   100      33       0          0         1        33     344011   344043   2E 11    62 1       33     427905   CTCTCCAGAAGATGAAGCCCGTGATGCGGCGCA   1          False      negative3373069   2 2 2 2 1 1   False         out      file fasta   heidelberg                                                                                                                                                                                                                                                                                                                                            Next 196 lines omitted     Analysis of a single FASTQ readset                                     Contents of   results tab                                                                                                                                                                                                                                                                                                                                                                                                                            sample   scheme       subtype       all subtypes                                     tiles matching subtype                     are subtypes consistent   inconsistent subtypes   n tiles matching all   n tiles matching all total   n tiles matching positive   n tiles matching positive total   n tiles matching subtype   n tiles matching subtype total   file path                                                                                                                                                                                                                                                                                                                                                                                                                                                         564      heidelberg   2 2 1 1 1 1   2  2 2  2 2 1  2 2 1 1  2 2 1 1 1  2 2 1 1 1 1   1983064 2 2 1 1 1 1  4211912 2 2 1 1 1 1   True                                              202                    202                          20                          20                                2                          2                                forward fastqsanger  reverse fastqsanger                                                                                                                                                                                                                                                                                                                                                                                                                      Contents of   match results tab                                                                                                                                                                                                            seq                                 freq   sample   file path                                  tilename           is pos tile   subtype     refposition   is kmer freq okay   scheme                                                                                                                                                                                                              ACGGTAAAAGAGGACTTGACTGGCGCGATTTGC   68     564      forward fastqsanger  reverse fastqsanger   21097 2 2 1 1 1    True          2 2 1 1 1   21097         True                heidelberg                                                                                                                                                                                                          AACCGGCGGTATTGGCTGCGGTAAAAGTACCGT   77     564      forward fastqsanger  reverse fastqsanger   157792 2 2 1 1 1   True          2 2 1 1 1   157792        True                heidelberg                                                                                                                                                                                                          CCGCTGCTTTCTGAAATCGCGCGTCGTTTCAAC   67     564      forward fastqsanger  reverse fastqsanger   293728 2 2 1 1     True          2 2 1 1     293728        True                heidelberg                                                                                                                                                                                                          GAATAACAGCAAAGTGATCATGATGCCGCTGGA   91     564      forward fastqsanger  reverse fastqsanger   607438 2 2 1       True          2 2 1       607438        True                heidelberg                                                                                                                                                                                                          CAGTTTTACATCCTGCGAAATGCGCAGCGTCAA   87     564      forward fastqsanger  reverse fastqsanger   691203 2 2 1 1     True          2 2 1 1     691203        True                heidelberg                                                                                                                                                                                                          CAGGAGAAAGGATGCCAGGGTCAACACGTAAAC   33     564      forward fastqsanger  reverse fastqsanger   944885 2 2 1 1 1   True          2 2 1 1 1   944885        True                heidelberg                                                                                                                                                                                                         Next 200 lines omitted       ,bio_hansel,"fastqsanger, fastq, fasta,fastqsanger, fastq,fasta",Salmonella Subtyping,tabular
305,creates a contact matrix,,  Creation of the contact matrix                                    hicBuildMatrix   creates a contact matrix based on Hi C read pairs  It requires two sam or bam files  corresponding to the first and second mates of the paired end H C reads  The sam and bam files should  not be sorted by position  There are two main options to create the Hi C contact matrix  either by  fixed bin size  eg  10 000 bp  or by bins of variable restriction fragment size length     hicBuildMatrix   generates a quality control output that can be used to analyze the quality of the Hi C reads   Input         hicBuildMatrix  is having the following parameters   Parameters                two input BAM SAM files   a bin size   a restriction cut file as an alternative to the bin size   restriction sequence  e g  HindIII  GATC    Output          hicBuildMatrix  creates as an output        the contact matrix       a bam file with the accepted alignments       a quality report   Example plot                                                                      image    PATH TO IMAGES SRR027956 svg     width  70   Contact matrix created with  hicPlotMatrix    Quality report                 The quality report gives you information about     how many pairs were used to build the contact matrix   dangling end pairs  These are reads that start with the restriction site and constitute reads that were digested but no ligated    same fragment pairs  These are read mates  facing inward  separated by up to 800 bp that do not have a restriction enzyme in between  These read pairs are not valid Hi C pairs    self circles  Self circles are defined as pairs within 25kb with  outward  read orientation   self ligations  These are read pairs with a restriction site in between that are within 800 bp   Contact distance                      inter chromosomal   short range   20 kb   long range  Read orientation                      inward pairs   outward pairs    left pairs   right pairs      image    PATH TO IMAGES hicQC png     width  70       For more information about HiCExplorer please consider our documentation on readthedocs io        readthedocs io     ,hicexplorer_hicbuildmatrix,"sam,bam,bed",@BINARY@,"bam,h5,html,txt"
306,Runs Dekker's iterative correction over a hic matrix.,,  Matrix correction                       hicCorrectMatrix   runs Dekker s iterative correction over a Hi C matrix   Imakaev 2012      For correcting the matrix   it is important to remove the unassembled scaffolds  e g   NT     mitochondrial DNA and Y chromosome and keep only  chromosomes  as scaffolds create problems with matrix correction  Therefore  we use the chromosome names  1 19  X  Y  here       Important    Use  chr1 chr2 chr3 etc   if your genome index uses chromosome names with the  chr  prefix   Matrix correction works in two steps  first a histogram containing the sum of contact  per bin  row sum  is produced  This plot needs to be inspected to decide the best threshold for removing bins with lower number of reads  The second steps removes the low scoring bins and does the correction   Input         Diagnostic plot                  Plots a histogram of the coverage per bin together with the modified z score based on the median absolute deviation method   See Boris Iglewicz and David Hoaglin 1993  Volume 16   How to Detect and Handle Outliers The ASQC Basic References in Quality Control  Statistical Techniques  Edward F  Mykytka  Ph D   Editor   Parameters              the contact matrix   Max value for the x axis in counts per bin   include chromosomes   Correct          Run the iterative correction    Parameters              number of iterations   inflation cutoff   trans region cutoff   sequenced count cutoff   skip diagonal counts   normalize each chromosome separately   remove bins of low coverage   remove bins of large coverage   include chromosomes  Output             Diagnostic plot          image    PATH TO IMAGES diagnostic plot png          width  70           Correct        the corrected contact matrix    For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io         Imakaev 2012    ,hicexplorer_hiccorrectmatrix,,@BINARY@,"h5,png"
307,Computes pairwise correlations between hic matrices data,,  Matrix correlation                     Computes pairwise correlations between Hi C contact matrices  The correlation is computed taking the values from each pair of matrices and discarding values that are zero in both matrices   Input        Parameters              Two contact matrices which are used for the correlation    Choice if pearson or spearman correlation should be used    log scale for the values   Correlate full matrix or only specific chromosomes   Correlate only within a given range    colormap to use   Colormap    Output         Pearson correlation                         image    PATH TO IMAGES hicCorrelate pearson png     width  45      image    PATH TO IMAGES hicCorrelate pearson scatter png   width  45     Spearman correlation                           image    PATH TO IMAGES hicCorrelate spearman png     width  45       image    PATH TO IMAGES hicCorrelate spearman scatter png     width  45    For more information about HiCExplorer please consider our documentation on readthedocs io        readthedocs io       Colormap    ,hicexplorer_hiccorrelate,,@BINARY@,png
308,find minimum cuts that correspond to boundaries,, Calculate TADs                 Topological associated domains  TADs  are regions on the DNA which tend to interact within the region a lot  but not outside their boundaries  More information    Calculation                hicFindTADs   computes the TAD regions in two steps  In a first step it computes a TAD separation score based on a z score matrix for all bins  The z score is defined as    The absolute value of z represents the distance between the raw score and the population mean in  units of the standard deviation  z is negative when the raw score is below the mean  positive when above     Source        image    PATH TO IMAGES z score svg     width  100      Source of image      In our case the distribution describes the counts per bin of a genomic distance  In a second step the local minima of the TAD separation score is evaluated with respect to the surrounding bins to assign a p value  Two multiple testing corrections can be applied to filter the results   Bonferroni     or the  false discovery rate        Input        Parameters              contact matrix to compute the TADs on   minimum window length   maximum window length   step size   multiple testing correction   minimum threshold   minimum distance   hicFindTADs tries to identify sensible parameters but those can be change to identify more stringent set of boundaries   Output           Boundary positions as a bed file   Matrix with multi scale TAD scores as a bedgraph    TAD domains as a bed file   Boundary information plus score as gff   TAD information in bm file   Z score matrix in h5  The calulated TAD regions can be plotted with   hicPlotTADs         image    PATH TO IMAGES master TADs plot png     width  80      For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io       Source   Calculation from raw score      information   ,hicexplorer_hicfindtads,,@BINARY@,"bed,bedgraph,gff,h5"
309,Merges bins from a Hi-C matrix,,  Change matrix resolution                             hicMergeMatrixBins   is used to decrease the resolution of a matrix  With this tool you can create out of a 100 kb  contact matrix a 1000 kb one   Number of bins to merge   10  100 kb   10   1000 kb   1 Mb  This functionality is useful especially for plotting  The higher the resolution of an contact matrix is  the more likely it is to run out of memory while plotting  This is caused by the circumstances that we compute internally with a sparse matrices but  to plot we need a dense one  Furthermore  the higher the resolution of a matrix the more detailed it is which can make it  difficult to interpret  especially if the read depth of the Hi C data is not high   Input        Parameters              contact matrix to change the resolution on   Number of bins to merge   running window  Output         A contact matrix with the resolution   original resolution   number of bins       For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io   ,hicexplorer_hicmergematrixbins,,@BINARY@,h5
310,computes the principal components for A / B compartment analysis,, Principal component analysis                               hicPCA  computes two eigenvector files based on the input matrix for an A   B compartment analysis   Input         the matrix to be analysed  Parameters              Output file format  bigwig or bedgraph  Output        Two files with the first and the second eigenvector     For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io   ,hicexplorer_hicpca,,@BINARY@,bigwig
311,distance vs HiC counts plot per chromosome,, Relation of genomic distance and number of contacts                                                             This program makes a distance vs  Hi C counts plots  It can use several matrix files to compare   them  If the     perchr   option is given  each chromosome is plotted independently  In the case   of more than one matrix  multiple plots are created  one per chromosome  When plotting multiple   matrices denser matrices are scaled down to match the sum of the smaller matrix      For more information about HiCExplorer please consider our documentation on readthedocs io    Input        Parameters              contact matrix   skip diagonal   per chromosome   max depth   plot size   chromosome s  to exclude  Output         Output if all data in the contact matrix is considered      image    PATH TO IMAGES hicPlotDistVsCounts result1 png     width  70   Output if the distance vs  Hi C contact counts is computed and plotted per chromosome      image    PATH TO IMAGES hicPlotDistVsCounts result2 png     width  80        readthedocs io   ,hicexplorer_hicplotdistvscounts,"h5,cool",@BINARY@,png
312,Plots a HiC matrix heatmap,, Contact matrix plot                            hicPlotMatrix   is a visualization tool for a contact matrix  It supports to plot the whole contact matrix  one or more chromosomes  a region or two regions against each other   Additional it can plot the result of a principal component analysis to have a better understanding of A   B compartments   Input        Parameters              the contact matrix  h5 or cool file format    A title for the plot   Score name   per chromosome   The chromosomes to include in the plot     What to show     The region s  to plot  This parameter overrides  chromosome   If either  chromosomes  or  region  is given the full contact matrix is used    log   log1p of the values  It is recommended to use log1p    Colormaps  for the heatmap     vMin   vMax   principal component  a bedgraph or bigwig file containing eigenvector information  Output         The contact matrix plotted for chromosome 1      image   SRR027956 svg     width  60    The contact matrix used with     perChr   and the first eigenvector from the tool   hicPCA    For this plot a pearson correlated matrix was used which is computed by creating first an observed   expected matrix and second a pearson correlation matrix  These matricies can be computed with   hicChangeMatrixType    The used Hi C data were published by  Lieberman Aiden     in 2009   GSE18199          image    PATH TO IMAGES SRR0279XX perChr eigenvector1 png     width  70      For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io       Colormaps   ,hicexplorer_hicplotmatrix,"bedgraph,bigwig",@BINARY@,png
313,"Plots the diagonal, and some values close to the diagonal of a HiC matrix",,  Plot TADs              hicPlotTADs   is a visualization tool to plot the topologically associating domains  TADs  in a given region  Additional tracks can be added to enable the comparisons with other data like gene tracks   Input         the region to plot  chr1 1000 2000   the tracks        the contact matrix       Boundaries file  The result of   hicFindTADs      different tracks for comparison        Chromatine states         TAD score       gene tracks       Generic bigwig  bedgraph or bedgraph matrix files       Vlines  vertical lines as a visual support where regions start   end over all tracks       Spacer  Add some space between the different tracks  For each track parameters for the color  the width or the font size can be defined   Output        An output looks like this       image    PATH TO IMAGES master TADs plot png     width  80      For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io   ,hicexplorer_hicplottads,bed,@BINARY@,png
314,computes the principal components for A / B compartment analysis,, Principal component analysis                               hicPCA  computes two eigenvector files based on the input matrix for an A   B compartment analysis   Input         the matrix to be analysed  Parameters              Output file format  bigwig or bedgraph  Output        Two files with the first and the second eigenvector     For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io   ,hicexplorer_hicplotviewpoint,,@BINARY@,"png,bedgraph"
315,combines Hi-C matrices of the same size,, Summation of matrices                          hicSumMatrix   is combining two  or more  contact matrices of the same size to one   This is useful if replicates of an Hi C experiment should be merged into one contact matrix to  increase the power of the data  It is the nature of Hi C that real contact cannot be distinguished  from noise  especially with a low contact count  The more contacts are given  the more likely it is  that a high number of contacts are real contact or contain at least a high amount  Therefore it is  a common way to merge replicates of Hi C experiments to increase the validity of the experiment   Input        Parameters              two or matrices of the same shape   Output        The summed matrix     For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io   ,hicexplorer_hicsummatrices,,@BINARY@,h5
316,"transforms a matrix to a obs_exp, pearson and covariance matrix",, Transformation of matrix for plotting                                        hicTransform  computes three matrices  an observed expected matrix based on it a pearson correlation matrix and based on it a covariance matrix  These three matrices can be used with  hicPlotMatrix  for an A   B compartment analysis   Input         the matrix to be transformed  Parameters              Output file format  h5 or cool  Output          observed expected matrix   pearson correlation matrix    covariance matrix     For more information about HiCExplorer please consider our documentation on readthedocs io       readthedocs io   ,hicexplorer_hictransform,,@BINARY@,h5
317,A fast and sensitive alignment program,, Introduction               What is HISAT                   HISAT      is a fast and sensitive spliced alignment program  As part of HISAT  we have developed a new indexing scheme based on the Burrows Wheeler transform   BWT       and the  FM index       called hierarchical indexing  that employs two types of indexes   1  one global FM index representing the whole genome  and  2  many separate local FM indexes for small regions collectively covering the genome  Our hierarchical index for the human genome  about 3 billion bp  includes  48 000 local FM indexes  each representing a genomic region of  64 000bp  As the basis for non gapped alignment  the FM index is extremely fast with a low memory footprint  as demonstrated by  Bowtie       In addition  HISAT provides several alignment strategies specifically designed for mapping different types of RNA seq reads  All these together  HISAT enables extremely fast and sensitive alignment of reads  in particular those spanning two exons or more  As a result  HISAT is much faster  50 times than  TopHat2      with better alignment quality  Although it uses a large number of indexes  the memory requirement of HISAT is still modest  approximately 4 3 GB for human  HISAT uses the  Bowtie2      implementation to handle most of the operations on the FM index  In addition to spliced alignment  HISAT handles reads involving indels and supports a paired end alignment mode  Multiple processors can be used simultaneously to achieve greater alignment speed  HISAT outputs alignments in  SAM      format  enabling interoperation with a large number of other tools  e g   SAMtools        GATK       that use SAM  HISAT is distributed under the  GPLv3 license       and it runs on the command line under Linux  Mac OS X and Windows   Running HISAT                Reporting            The reporting mode governs how many alignments HISAT looks for  and how to report them   In general  when we say that a read has an alignment  we mean that it has a  valid alignment   valid alignments meet or exceed the minimum score threshold      When we say that a read has multiple alignments  we mean that it has multiple alignments that are valid and distinct from one another   Distinct alignments map a read to different places                                                     Two alignments for the same individual read are  distinct  if they map the same read to different places  Specifically  we say that two alignments are distinct if there are no alignment positions where a particular read offset is aligned opposite a particular reference offset in both alignments with the same orientation  E g  if the first alignment is in the forward orientation and aligns the read character at read offset 10 to the reference character at chromosome 3  offset 3 445 245  and the second alignment is also in the forward orientation and also aligns the read character at read offset 10 to the reference character at chromosome 3  offset 3 445 245  they are not distinct alignments   Two alignments for the same pair are distinct if either the mate 1s in the two paired end alignments are distinct or the mate 2s in the two alignments are distinct or both   Default mode  search for one or more alignments  report each                                                               HISAT searches for up to N distinct  primary alignments for each read  where N equals the integer specified with the    k   parameter  Primary alignments mean alignments whose alignment score is equal or higher than any other alignments  It is possible that multiple distinct alignments whave the same score  That is  if    k 2   is specified  HISAT will search for at most 2 distinct alignments  The alignment score for a paired end alignment equals the sum of the alignment scores of the individual mates  Each reported read or pair alignment beyond the first has the SAM  secondary  bit  which equals 256  set in its FLAGS field  See the  SAM specification      for details   HISAT does not  find  alignments in any specific order  so for reads that have more than N distinct  valid alignments  HISAT does not gaurantee that the N alignments reported are the best possible in terms of alignment score  Still  this mode can be effective and fast in situations where the user cares more about whether a read aligns  or aligns a certain number of times  than where exactly it originated   Alignment summmary                     When HISAT finishes running  it prints messages summarizing what happened  These messages are printed to the  standard error    stderr   filehandle and can be optionally printed to a file  Choose    new summary  under   Summary Options   for compatibility with  MultiQC   hisat2     For datasets consisting of unpaired reads  the summary might look like this           20000 reads  of these        20000  100 00   were unpaired  of these          1247  6 24   aligned 0 times         18739  93 69   aligned exactly 1 time         14  0 07   aligned  1 times     93 77  overall alignment rate  For datasets consisting of pairs  the summary might look like this           10000 reads  of these        10000  100 00   were paired  of these          650  6 50   aligned concordantly 0 times         8823  88 23   aligned concordantly exactly 1 time         527  5 27   aligned concordantly  1 times                      650 pairs aligned concordantly 0 times  of these            34  5 23   aligned discordantly 1 time                      616 pairs aligned 0 times concordantly or discordantly  of these            1232 mates make up the pairs  of these              660  53 57   aligned 0 times             571  46 35   aligned exactly 1 time             1  0 08   aligned  1 times     96 70  overall alignment rate  The indentation indicates how subtotals relate to totals       class   infomark    HISAT2 options    Galaxy wrapper for HISAT2 implements most  but not all  options available through the command line  Supported options are described below            Inputs    HISAT2 accepts files in FASTQ or FASTA format  single end or paired end    Note that if your reads are from a stranded library  you need to choose the appropriate setting under   Specify strand information   above  For single end reads  use F or R   F  means a read corresponds to a transcript   R  means a read corresponds to the reverse complemented counterpart of a transcript  For paired end reads  use either FR or RF  With this option being used  every read alignment will have an XS attribute tag      means a read belongs to a transcript on     strand of genome      means a read belongs to a transcript on     strand of genome   TopHat has a similar option    library type option  where fr firststrand corresponds to R and RF  fr secondstrand corresponds to F and FR              Input options           s   skip  int              Skip  i e  do not align  the first   int   reads or pairs in the input        u   qupto  int              Align the first   int   reads or read pairs from the input  after the               s     skip  reads or pairs have been skipped   then stop   Default  no limit        5   trim5  int              Trim   int   bases from 5   left  end of each read before alignment  default  0         3   trim3  int              Trim   int   bases from 3   right  end of each read before alignment  default  0          phred33             Input qualities are ASCII chars equal to the Phred quality plus 33   This is             also called the  Phred 33  encoding  which is used by the very latest Illumina             pipelines         phred64             Input qualities are ASCII chars equal to the Phred quality plus 64   This is             also called the  Phred 64  encoding         solexa quals             Convert input qualities from Solexa Phred quality  which can be negative  to             Phred Phred quality  which can t    This scheme was used in older Illumina GA             Pipeline versions  prior to 1 3    Default  off         int quals             Quality values are represented in the read input file as space separated ASCII integers  e g    40 40 30 40      rather than ASCII characters  e g    II I                  Integers are treated as being on the Phred quality scale unless                solexa quals  is also specified  Default  off             Alignment options            n ceil  func              Sets a function governing the maximum number of ambiguous characters  usually              N s and or    s  allowed in a read as a function of read length   For instance              specifying   L 0 0 15  sets the N ceiling function  f  to  f x    0   0 15   x               where x is the read length   Reads exceeding this ceiling are filtered out              Default   L 0 0 15          ignore quals             When calculating a mismatch penalty  always consider the quality value at the             mismatched position to be the highest possible  regardless of the actual value              I e  input is treated as though all quality values are high   This is also the             default behavior when the input doesn t specify quality values  e g  in   f                 r   or   c  modes          nofw   norc             If    nofw  is specified   hisat2  will not attempt to align unpaired reads to             the forward  Watson  reference strand   If    norc  is specified   hisat2  will not attempt to align unpaired reads against the reverse complement  Crick              reference strand  In paired end mode     nofw  and    norc  pertain to the             fragments  i e  specifying    nofw  causes  hisat2  to explore only those             paired end configurations corresponding to fragments from the reverse complement              Crick  strand   Default  both strands enabled            Scoring options            mp MX MN             Sets the maximum   MX   and minimum   MN   mismatch penalties  both integers  A number less than or equal to  MX  and greater than or equal to  MN  is             subtracted from the alignment score for each position where a read character             aligns to a reference character  the characters do not match  and neither is an              N    If    ignore quals  is specified  the number subtracted quals  MX               Otherwise  the number subtracted is  MN   floor   MX MN  MIN Q  40 0  40 0                 where Q is the Phred quality value   Default   MX    6   MN    2         sp MX MN             Sets the maximum   MX   and minimum   MN   penalties for soft clipping per base  both integers  A number less than or equal to  MX  and greater than or equal to  MN  is subtracted from the alignment score for each position  The number subtracted is  MN   floor   MX MN  MIN Q  40 0  40 0     where Q is the Phred quality value  Default   MX    2   MN    1         no softclip             Disallow soft clipping         np  int              Sets penalty for positions where the read  reference  or both  contain an             ambiguous character such as  N    Default  1         rdg  int1   int2              Sets the read gap open    int1    and extend    int2    penalties   A read gap of             length N gets a penalty of   int1     N     int2     Default  5  3         rfg  int1   int2              Sets the reference gap open    int1    and extend    int2    penalties   A             reference gap of length N gets a penalty of   int1     N     int2     Default              5  3         score min  func              Sets a function governing the minimum alignment score needed for an alignment to             be considered  valid   i e  good enough to report    This is a function of read             length  For instance  specifying  L 0  0 6  sets the minimum score function  f              to  f x    0    0 6   x   where  x  is the read length  The default is  L 0  0 2             Spliced alignment options            pen cansplice  int              Sets the penalty for each pair of canonical splice sites  e g  GT AG   Default  0         pen noncansplice  int              Sets the penalty for each pair of non canonical splice sites  e g  non GT AG   Default  12         pen canintronlen  func              Sets the penalty for long introns with canonical splice sites so that alignments with shorter introns are preferred to those with longer ones  Default  G  8 1        pen noncanintronlen  func              Sets the penalty for long introns with noncanonical splice sites so that alignments with shorter introns are preferred to those with longer ones  Default  G  8 1        min intronlen  int              Sets minimum intron length  Default  20        max intronlen  int              Sets maximum intron length  Default  500000        no spliced alignment             Disable spliced alignment        I   minins  int              The minimum fragment length for valid paired end alignments This option is valid only with    no spliced alignment   E g  if   I 60  is specified and a paired end alignment consists of two 20 bp alignments in the appropriate orientation with a 20 bp gap between them  that alignment is considered valid  as long as   X  is also satisfied   A 19 bp gap would not be valid in that case  If trimming options   3  or   5  are also used  the   I  constraint is applied with respect to the untrimmed mates               The larger the difference between   I  and   X   the slower HISAT2 will run  This is because larger differences between   I  and   X  require that HISAT2 scan a larger window to determine if a concordant alignment exists  For typical fragment length ranges  200 to 400 nucleotides   HISAT2 is very efficient               Default  0  essentially imposing no minimum        X   maxins  int              The maximum fragment length for valid paired end alignments  This option is valid only with    no spliced alignment   E g  if   X 100  is specified and a paired end alignment consists of two 20 bp alignments in the proper orientation with a 60 bp gap between them  that alignment is considered valid  as long as   I  is also satisfied   A 61 bp gap would not be valid in that case  If trimming options   3  or   5  are also used  the  X constraint is applied with respect to the untrimmed mates  not the trimmed mates               The larger the difference between   I  and   X   the slower HISAT2 will run  This is because larger differences between   I  and   X  require that HISAT2 scan a larger window to determine if a concordant alignment exists  For typical fragment length ranges  200 to 400 nucleotides   HISAT2 is very efficient               Default  500         known splicesite infile  path              With this mode  you can provide a list of known splice sites  which HISAT2 makes use of to align reads with small anchors  You can create such a list using python hisat2 extract splice sites py genes gtf   splicesites txt  where hisat2 extract splice sites py is included in the HISAT2 package  genes gtf is a gene annotation file  and splicesites txt is a list of splice sites with which you provide HISAT2 in this mode  Note that it is better to use indexes built using annotated transcripts  such as genome tran or genome snp tran   which works better than using this option  It has no effect to provide splice sites that are already included in the indexes         tmo   transcriptome mapping only             Report only those alignments within known transcripts         dta   downstream transcriptome assembly             Report alignments tailored for transcript assemblers including StringTie  With this option  HISAT2 requires longer anchor lengths for de novo discovery of splice sites  This leads to fewer alignments with short anchors  which helps transcript assemblers improve significantly in computation and memory usage         dta cufflinks             Report alignments tailored specifically for Cufflinks  In addition to what HISAT2 does with the above option    dta   With this option  HISAT2 looks for novel splice sites with three signals  GT AG  GC AG  AT AC   but all user provided splice sites are used irrespective of their signals  HISAT2 produces an optional field  XS A       for every spliced alignment         no templatelen adjustment             Disables template length adjustment for RNA seq reads            Reporting options           k  int              It searches for at most   int   distinct  primary alignments for each read  Primary alignments mean alignments whose alignment score is equal or higher than any other alignments  The search terminates when it can t find more distinct valid alignments  or when it finds   int    whichever happens first  The alignment score for a paired end alignment equals the sum of the alignment scores of the individual mates  Each reported read or pair alignment beyond the first has the SAM  secondary  bit  which equals 256  set in its FLAGS field  For reads that have more than   int   distinct  valid alignments  hisat2 does not guarantee that the   int   alignments reported are the best possible in terms of alignment score  Default  5  HFM  or 10  HGFM               Note  HISAT2 is not designed with large values for   k  in mind  and when aligning reads to long  repetitive genomes large   k  can be very  very slow        max seeds             HISAT2  like other aligners  uses seed and extend approaches  HISAT2 tries to extend seeds to full length alignments  In HISAT2     max seeds  is used to control the maximum number of seeds that will be extended  HISAT2 extends up to these many seeds and skips the rest of the seeds  Large values for    max seeds  may improve alignment sensitivity  but HISAT2 is not designed with large values for    max seeds  in mind  and when aligning reads to long  repetitive genomes large    max seeds  can be very  very slow  The default value is the maximum of 5 and the value that comes with   k          secondary             Report secondary alignments            Paired end options            fr   rf   ff             The upstream downstream mate orientations for a valid paired end alignment             against the forward reference strand   E g   if    fr  is specified and there is             a candidate paired end alignment where mate 1 appears upstream of the reverse             complement of mate 2 and the fragment length constraints    I  and   X   are             met  that alignment is valid   Also  if mate 2 appears upstream of the reverse             complement of mate 1 and all other constraints are met  that too is valid                 rf  likewise requires that an upstream mate1 be reverse complemented and a             downstream mate2 be forward oriented      ff  requires both an upstream mate 1             and a downstream mate 2 to be forward oriented   Default     fr   appropriate             for Illumina s Paired end Sequencing Assay          no mixed             By default  when  hisat2  cannot find a concordant or discordant alignment for             a pair  it then tries to find alignments for the individual mates   This option             disables that behavior         no discordant             By default   hisat2  looks for discordant alignments if it cannot find any             concordant alignments   A discordant alignment is an alignment where both mates             align uniquely  but that does not satisfy the paired end constraints                 fr     rf     ff     I     X     This option disables that behavior      Output options            un   un gz   un bz2             Write unpaired reads that fail to align to file at   path    These reads correspond to the SAM records with the FLAGS  0x4  bit set and neither the  0x40  nor  0x80  bits set  If    un gz  is specified  output will be gzip compressed  If    un bz2  is specified  output will be bzip2 compressed  Reads written in this way will appear exactly as they did in the input file  without any modification  same sequence  same name  same quality string  same quality encoding   Reads will not necessarily appear in the same order as they did in the input         al   al gz   al bz2             Write unpaired reads that align at least once to file at   path    These reads correspond to the SAM records with the FLAGS  0x4    0x40   and  0x80  bits unset  If    al gz  is specified  output will be gzip compressed  If    al bz2  is specified  output will be bzip2 compressed  Reads written in this way will appear exactly as they did in the input file  without any modification  same sequence  same name  same quality string  same quality encoding   Reads will not necessarily appear in the same order as they did in the input         un conc   un conc gz   un conc bz2             Write paired end reads that fail to align concordantly to file s  at   path    These reads correspond to the SAM records with the FLAGS  0x4  bit set and either the  0x40  or  0x80  bit set  depending on whether it s mate  1 or  2    1 and  2 strings are added to the filename to distinguish which file contains mate  1 and mate  2  If a percent symbol     is used in  path   the percent symbol is replaced with 1 or 2 to make the per mate filenames  Otherwise   1 or  2 are added before the final dot in  path  to make the per mate filenames  Reads written in this way will appear exactly as they did in the input files  without any modification  same sequence  same name  same quality string  same quality encoding   Reads will not necessarily appear in the same order as they did in the inputs         al conc   al conc gz   al conc bz2             Write paired end reads that align concordantly at least once to file s  at   path    These reads correspond to the SAM records with the FLAGS  0x4  bit unset and either the  0x40  or  0x80  bit set  depending on whether it s mate  1 or  2    1 and  2 strings are added to the filename to distinguish which file contains mate  1 and mate  2  If a percent symbol     is used in  path   the percent symbol is replaced with 1 or 2 to make the per mate filenames  Otherwise   1 or  2 are added before the final dot in   path   to make the per mate filenames  Reads written in this way will appear exactly as they did in the input files  without any modification  same sequence  same name  same quality string  same quality encoding   Reads will not necessarily appear in the same order as they did in the inputs      Other options            seed  int              Use   int   as the seed for pseudo random number generator   Default  0         non deterministic             Normally  HISAT2 re initializes its pseudo random generator for each read  It seeds the generator with a number derived from  a  the read name   b  the nucleotide sequence   c  the quality sequence   d  the value of the    seed  option  This means that if two reads are identical  same name  same nucleotides  same qualities  HISAT2 will find and report the same alignment s  for both  even if there was ambiguity  When    non deterministic  is specified  HISAT2 re initializes its pseudo random generator for each read using the current time  This means that HISAT2 will not necessarily report the same alignment for two identical reads  This is counter intuitive for some users  but might be more appropriate in situations where the input consists of many identical reads       ,hisat2,"fasta,fastqsanger,fastqsanger.gz,fastqsanger.bz2,fasta,gtf",HISAT2,"bam,fastqsanger,txt"
318,append modelmask line to a multiple sequence alignments,,  HELP PRE   alimask is used to apply a mask line to a multiple sequence alignment  based on provided alignment or model coordinates  When hmmbuild receives a masked alignment as input  it produces a profile model in which the emission probabilities at masked positions are set to match the background frequency  rather than being set based on observed frequencies in the alignment  Position specific insertion and deletion rates are not altered  even in masked regions  alimask autodetects input format  and produces masked alignments in Stockholm format   msafile  may contain only one sequence alignment   A common motivation for masking a region in an alignment is that the region contains a simple tandem repeat that is observed to cause an unacceptably high rate of false positive hits   In the simplest case  a mask range is given in coordinates relative to the input alignment  using   alirange  s   However it is more often the case that the region to be masked has been identified in coordinates relative to the profile model  e g  based on recognizing a simple repeat pattern in false hit alignments or in the HMM logo   Not all alignment columns are converted to match state positions in the profile  see the   symfrac flag for hmmbuild for discussion   so model positions do not necessarily match up to alignment column positions  To remove the burden of converting model positions to alignment positions  alimask accepts the mask range input in model coordinates as well  using   modelrange  s   When using this flag  alimask determines which alignment positions would be identified by hmmbuild as match states  a process that requires that all hmmbuild flags impacting that decision be supplied to alimask  It is for this reason that many of the hmmbuild flags are also used by alimask    HELP PRE OTH     Ranges    Ranges are expressed as a hyphenated pair of integers  e g  12 40  Ranges can be expressed in terms of model coordinates or alignment coordinates    FORMAT SELECTOR HELP   MCSS HELP   ARSWS HELP   SEED HELP    ATTRIBUTION  ,hmmer_alimask,,alimask,stockholm
319,align sequences to a profile HMM,,  HELP PRE   Perform a multiple sequence alignment of all the sequences in  seqfile  by aligning them individually to the profile HMM in  hmmfile   The new alignment is output to stdout in Stockholm format   The  hmmfile  should contain only a single profile  If it contains more  only the first profile in the file will be used   Either  hmmfile  or  seqfile   but not both  may be      dash   which means reading this input from stdin rather than a file   The sequences in  seqfile  are aligned in unihit local alignment mode  Therefore they should already be known to contain only a single domain  or a fragment of one   The optimal alignment may assign some residues as nonhomologous  N and C states   in which case these residues are still included in the resulting alignment  but shoved to the outer edges  To trim these unaligned nonhomologous residues from the result  see the   trim option     HELP PRE OTH    FORMAT SELECTOR HELP    ATTRIBUTION  ,hmmer_hmmalign,fasta,hmmalign,stockholm
320,Build a profile HMM from an input multiple alignment,,  HELP PRE   For each multiple sequence alignment in  msafile  build a profile HMM and save it to a new file  hmmfile out     HELP PRE OTH    FORMAT SELECTOR HELP   MCSS HELP   ARSWS HELP   AEEWS HELP   PRIOR HELP   HSSI HELP   EVAL CALIB HELP   SEED HELP   LENGTHS HELP    ATTRIBUTION  ,hmmer_hmmbuild,,hmmbuild,hmm3
321,convert profile file to a HMMER format,,  HELP PRE   The hmmconvert utility converts an input profile file to different HMMER formats   By default  the input profile can be in any HMMER format  including old obsolete formats from HMMER2  ASCII or binary  the output profile is a current HMMER3 ASCII format    ATTRIBUTION  ,hmmer_hmmconvert,,hmmconvert,hmm3
322,sample sequence(s) from a profile HMM,,  HELP PRE   The hmmemit program samples  emits  sequences from the profile HMM s  in hmmfile  and writes them to output  Sampling sequences may be useful for a variety of purposes  including creating synthetic true positives for benchmarks or tests   The default is to sample one unaligned sequence from the core probability model  which means that each sequence consists of one full length domain  Alternatively  with the  c option  you can emit a simple majority rule consensus sequence  or with the  a option  you can emit an alignment  in which case  you probably also want to set  N to something other than its default of 1 sequence per model    As another option  with the  p option you can sample a sequence from a fully configured HMMER search profile  This means sampling a  homologous sequence  by HMMER s definition  including nonhomologous flanking sequences  local alignments  and multiple domains per sequence  depending on the length model and alignment mode chosen for the profile   The hmmfile may contain a library of HMMs  in which case each HMM will be used in turn    HELP PRE OTH   Output Formats                 Several output formats are available  each with different options     Fasta    Fasta option is the easiest to understand  given an input model  it will produce N sequences in fasta format from that model     Alignment    Produces a stockholm alignment  of what the Fasta output would have produced     Majority Rule Concensus Sequence    Emit a plurality rule consensus sequence  instead of sampling a sequence from the profile HMM s probability distribution  The consensus sequence is formed by selecting the maximum probability residue at each match state     Fancier Concensus Sequence    Emit a fancier plurality rule consensus sequence than the  c option  If the maximum probability residue has p   minl show it as a lower case  any  residue  n or x   if p    minl and   minu show it as a lower case residue  and if p    minu show it as an upper case residue  The default settings of minu and minl are both 0 0  which means  C gives the same output as  c unless you also set minu and minl to what you want     Sample    Sample unaligned sequences from the implicit search profile  not from the core model  The core model consists only of the homologous states  between the begin and end states of a HMMER Plan7 model   The profile includes the nonhomologous N  C  and J states  local glocal and uni multihit algorithm configuration  and the target length model  Therefore sequences sampled from a profile may in  clude nonhomologous as well as homologous sequences  and may contain more than one homologous sequence segment  By default  the profile is in multihit local mode  and the target sequence length is configured for L 400    ATTRIBUTION  ,hmmer_hmmemit,,hmmemit,fasta
323,retrieve profile HMM(s) from a file,,  HELP PRE   Quickly retrieves one or more profile HMMs from an  hmmfile   a large Pfam database  for example   The profile names should be listed in a text file  separated by newlines  By default  fetched HMMs are printed to standard output in HMMER3 format    ATTRIBUTION  ,hmmer_hmmfetch,"tabular,txt",hmmfetch,hmm3
324,search sequence(s) against a profile database,,  HELP PRE   hmmscan is used to search protein sequences against collections of protein profiles  For each sequence in  seqfile   use that query sequence to search the target database of profiles in  hmmfile   and output ranked lists of the profiles with the most significant matches to the sequence    HELP PRE OTH    OFORMAT WITH OPTS HELP   THRESHOLDS HELP   CUT HELP   ACCEL HEUR HELP   ADV OPTS HELP   SEED HELP    ATTRIBUTION  ,hmmer_hmmscan,fasta,hmmscan,txt
325,search profile(s) against a sequence database,,  HELP PRE   hmmsearch is used to search one or more profiles against a sequence database  For each profile in  hmmfile   use that query profile to search the target database of sequences in  seqdb   and output ranked lists of the sequences with the most significant matches to the profile  To build profiles from multiple alignments  see hmmbuild    HELP PRE OTH    OFORMAT WITH OPTS HELP   THRESHOLDS HELP   CUT HELP   ACCEL HEUR HELP   ADV OPTS HELP   SEED HELP    ATTRIBUTION  ,hmmer_hmmsearch,fasta,hmmsearch,txt
326,iteratively search a protein sequence against a protein database (PSIBLAST-like),,  HELP PRE   jackhmmer iteratively searches each query sequence in  seqfile  against the target sequence s  in  seqdb   The first iteration is identical to a phmmer search  For the next iteration  a multiple alignment of the query together with all target sequences satisfying inclusion thresholds is assembled  a profile is constructed from this alignment  identical to using hmmbuild on the alignment   and profile search of the  seqdb  is done  identical to an hmmsearch with the profile      HELP PRE OTH    OFORMAT WITH OPTS HELP NOPFAM   HSSI HELP   THRESHOLDS HELP   ACCEL HEUR HELP   MCSS HELP   ARSWS HELP   AEEWS HELP   PRIOR HELP   EVAL CALIB HELP   ADV OPTS HELP   SEED HELP    ATTRIBUTION  ,hmmer_jackhmmer,fasta,jackhmmer,txt
327,search a DNA model or alignment against a DNA database (BLASTN-like),,  HELP PRE   nhmmer is used to search one or more nucleotide queries against a nucleotide sequence database  For each query in  queryfile   use that query to search the target database of sequences in  seqdb   and output a ranked list of the hits with the most significant matches to the query  A query may be either a profile model built using hmmbuild  a sequence alignment  or a single sequence  Sequence based queries can be in a number of formats  see   qformat   and can typically be autodetected  Note that only Stockholm format supports the use of multiple sequence based queries    HELP PRE OTH    OFORMAT WITH OPTS N HELP   HSSI HELP   THRESHOLDS NODOM HELP   CUT HELP   ACCEL HEUR HELP   FORMAT SELECTOR HELP   ADV OPTS HELP   LENGTHS HELP   SEED HELP    ATTRIBUTION  ,hmmer_nhmmer,fasta,nhmmer,txt
328,search DNA sequence(s) against a DNA profile database,,  HELP PRE   nhmmscan is used to search nucleotide sequences against collections of nucleotide profiles  For each sequence in  seqfile   use that query sequence to search the target database of profiles in  hmmfile   and output ranked lists of the profiles with the most significant matches to the sequence   The  seqfile  may contain more than one query sequence  It can be in FASTA format  or several other common sequence file formats  genbank  embl  and uniprot  among others   or in alignment file formats  stockholm  aligned fasta  and others   See the   qformat option for a complete list    HELP PRE OTH    OFORMAT WITH OPTS N HELP   THRESHOLDS NODOM HELP   CUT HELP   ACCEL HEUR HELP   BIAS COMP HELP   ADV OPTS HELP   LENGTHS HELP   SEED HELP     ATTRIBUTION  ,hmmer_nhmmscan,fasta,nhmmscan,txt
329,search a protein sequence against a protein database (BLASTP-like),,  HELP PRE   phmmer is used to search one or more query protein sequences against a protein sequence database   For each query sequence in  seqfile   use that sequence to search the target database of sequences in  seqdb   and output ranked lists of the sequences with the most significant matches to the query     HELP PRE OTH    OFORMAT WITH OPTS HELP   HSSI HELP   THRESHOLDS HELP   ACCEL HEUR HELP   EVAL CALIB HELP   ADV OPTS HELP   SEED HELP    ATTRIBUTION  ,hmmer_phmmer,fasta,phmmer,txt
330, - Count aligned reads in a BAM file that overlap features in a GFF file,,  Overview           This tool takes an alignment file in SAM or BAM format and feature file in GFF format and calculates the number of reads mapping to each feature  It uses the  htseq count  script that is part of the HTSeq python module  See  for details   A feature is an interval  i e   a range of positions  on a chromosome or a union of such intervals   In the case of RNA Seq  the features are typically genes  where each gene is considered here as the union of all its exons  One may also consider each exon as a feature  e g   in order to check for alternative splicing  For comparative ChIP Seq  the features might be binding regions from a pre determined list    Overlap Modes                Special care must be taken to decide how to deal with reads that align to or overlap with more than one feature  The   htseq count   script allows to choose between three modes  See also the FAQ   if the following explanation seems too technical   The three overlap resolution modes of  htseq count  work as follows  For each position  i  in the read  a set  S i   is defined as the set of all features overlapping position  i   Then  consider the set  S   which is  with  i  running through all position within the read or a read pair     the union of all the sets  S i   for mode   union    This mode is   recommended for most use cases    the intersection of all the sets  S i   for mode   intersection strict      the intersection of all non empty sets  S i   for mode     intersection nonempty     If  S  contains precisely one feature  the read  or read pair  is counted for this feature  If  S  is empty  the read  or read pair  is counted as   no feature    If  S  contains more than one feature    htseq count   behaves differently based on the     nonunique   option         nonunique none    default   the read  or read pair  is counted as     ambiguous   and not counted for any features  Also  if the read  or read   pair  aligns to more than one location in the reference  it is scored as     alignment not unique          nonunique all    the read  or read pair  is counted as   ambiguous   and   is also counted in all features to which it was assigned  Also  if the read    or read pair  aligns to more than one location in the reference  it is   scored as   alignment not unique   and also separately for each location   Notice that when using     nonunique all   the sum of all counts will not be equal to the number of reads  or read pairs   because those with multiple alignments or overlaps get scored multiple times   The following figure illustrates the effect of these three modes and the     nonunique   option      image   count modes png   Strandedness                 Important  The default for strandedness is yes  Be sure to choose the correct value     To check which value is correct  select forward and reverse independently  If the overall counts drop at one condition then the opposite condition is correct  otherwise your data is not stranded   Output         The script outputs a table with counts for each feature  followed by the special counters  which count reads that were not counted for any feature for various reasons  namely     no feature   reads which could not be assigned to any feature  set S as described above was empty       ambiguous   reads which could have been assigned to more than one feature and hence were not counted for any of these  set S had mroe than one element       too low aQual   reads which were not counted due to the  a option  see below     not aligned   reads in the SAM file without alignment     alignment not unique   reads with more than one reported alignment  These reads are recognized from the NH optional SAM field tag   If the aligner does not set this field  multiply aligned reads will be counted multiple times     Options Summary                  Usage  htseq count  options  sam file gff file  This script takes an alignment file in SAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it  See  for details   Options     f  format     format  format         Format of the input data  Possible values are sam  for text SAM files  and bam  for binary BAM files   Default is sam      r  order     order  order         For paired end data  the alignment have to be sorted either by read name or by alignment position  If your data is not sorted  use the samtools sort function of samtools to sort it  Use this option  with name or pos for  order  to indicate how the input data has been sorted  The default is name         If name is indicated  htseq count expects all the alignments for the reads of a given read pair to appear in adjacent records in the input data  For pos  this is not expected  rather  read alignments whose mate alignment have not yet been seen are kept in a buffer in memory until the mate is found  While  strictly speaking  the latter will also work with unsorted data  sorting ensures that most alignment mates appear close to each other in the data and hence the buffer is much less likely to overflow       max reads in buffer  number         When  alignment file  is paired end sorted by position  allow only so many reads to stay in memory until the mates are found  raising this number will use more memory   Has no effect for single end or paired end sorted by name   default  30000000      s  yes no reverse     stranded  yes no reverse         whether the data is from a strand specific assay  default  yes         For stranded no  a read is considered overlapping with a feature regardless of whether it is mapped to the same or the opposite strand as the feature  For stranded yes and single end reads  the read has to be mapped to the same strand as the feature  For paired end reads  the first read has to be on the same strand and the second read on the opposite strand  For stranded reverse  these rules are reversed      a  minaqual     a  minaqual         skip all reads with alignment quality lower than the given minimum value  default  10   Note  the default used to be 0 until version 0 5 4       t  feature type     type  feature type         feature type  3rd column in GFF file  to be used  all features of other type are ignored  default  suitable for RNA Seq analysis using an Ensembl GTF file  exon      i  id attribute     idattr  id attribute         GFF attribute to be used as feature ID  Several GFF lines with the same feature ID will be considered as parts of the same feature  The feature ID is used to identity the counts in the output table  The default  suitable for RNA Seq analysis using an Ensembl GTF file  is gene id       additional attr  id attributes         Additional feature attributes  which will be printed as an additional column after the primary attribute column but before the counts column s   The default is none  a suitable value to get gene names using an Ensembl GTF file is gene name      m  mode     mode  mode         Mode to handle reads overlapping more than one feature  Possible values for  mode  are union  intersection strict and intersection nonempty  default  union       nonunique  nonunique mode         Mode to handle reads that align to or are assigned to more than one feature in the overlap  mode  of choice  see  m option    nonunique mode  are none and all  default  none       secondary alignments  mode         Mode to handle secondary alignments  SAM flag 0x100    mode  can be score and ignore  default  score       supplementary alignments  mode         Mode to handle supplementary chimeric alignments  SAM flag 0x800    mode  can be score and ignore  default  score      o  samout     samout  samout         write out all SAM alignment records into an output SAM file called  samout   annotating each line with its assignment to a feature or a special counter  as an optional field with tag  XF       q    quiet        suppress progress report and warnings     h    help        Show a usage summary and exit      FAQ   frequenctly asked questions       ,htseq_count,"sam,bam,gff,fasta",htseq-count,"tabular,bam"
331,to profile presence/absence and abundance of microbial pathways and gene families,,  HELP HEADER   This tool corresponds to the main tool in HUMAnN2 pipeline     Inputs    The input is a single file corresponding either to filtered shotgun sequencing metagenome file  fastq  fastq gz  fasta  or fasta gz format   alignment file  sam  bam or blastm8 format  or gene table file  tsv or biom format    A file with a taxonomic profile  obtained with MetaPhlan2  can also be provided to avoid first step of taxonomic profiling needed to select pangenomes in protein database  Otherwise  default MetaPhlAn2 or custom databases can be used for taxonomic profiling  For custom databases  a fasta file with marker gene sequences is required and also a json file containing metadata                taxonomy                  taxonomy of genome1   genome1 length               taxonomy of genome2   genome2 length                                 markers                  marker1 name                      clade   the clade that the marker belongs to                   ext    list of external genomes where the marker appears                    len   length of the marker                   score   score of the marker                   taxon   the taxon of the marker                                              For functional profiling  HUMAnN2 uses multiple databases  Locally cached nucleotide or protein databases have to be downloaded database before using them  using the dedicated tool   Custom databases can also be used after upload  Nucleotide database have to be provided as a dataset     Outputs    HUMAnN creates three output files      A file with gene families and their abundance    A file with pathways and their abundance    A file with pathways and their coverage      ,humann2,"fastq,fasta,sam,bam,biom1,tabular,txt,fasta,json,tsv",HUMAnN2,"tsv,biom1"
332,HUMAnN2 functions with metadata,,  HELP HEADER   When associating metadata with HUMAnN2 features  it is often beneficial to associate with community totals and avoid testing each individual feature stratification  to improve statistical power   This is the approach used by the HUMAnN2 utility script humann2 associate  which can compare feature totals across samples with 1  a single continuous metadatum  via the Spearman Correlation  or 2  a single categorical metadatum  via the Kruskal Wallis H test   Notably  this is a naive approach to association  but it is useful for tutorial purposes      ,humann2_associate,"tsv,tabular",Associate,tabular
333,stratified HUMAnN2 features,,  HELP HEADER   humann2 barplot produces plots of stratified HUMAnN2 features and includes many options for sorting and scaling data  Here is an example of a HUMAnN2 barplot for a pathway  denitrification  that was preferentially enriched in Human Microbiome Project oral samples relative to other body sites  This figure uses many options from humann2 barplot  including regrouping by genus  pseudolog scaling  and sorting samples by similarity and metadata      image    PATH TO IMAGES 731303924 page DENITRIFICATION PWY png     width  800     ,humann2_barplot,"tsv,tabular",Barplot,"png,pdf,svg"
334,,,  HELP HEADER   By default  the gene families and pathways output files from HUMAnN2 are species level  This tool generates genus level gene families     ,humann2_genefamilies_genus_level,"tsv,tabular",Create a genus level gene families file,tsv
335,HUMAnN2 generated tables,,  HELP HEADER   Join HUMAnN2 tables is a tool to join gene or pathway tables of multiple samples into a single table      ,humann2_join_tables,"tsv,tabular",Join,tsv
336,a HUMAnN2 generated table,,  HELP HEADER   Reduce HUMAnN2 table is a tool to reduce the table given a function  max  sum  mean or min       ,humann2_reduce_table,"tsv,tabular",Reduce,tsv
337,a HUMAnN2 generated table by features,,  HELP HEADER   Regroup HUMAnN2 table features is a tool for regrouping table features  abundances or coverage  given a table of feature values and a mapping of groups to component features  It produces a new table with group values in place of feature values      ,humann2_regroup_table,"tsv,tabular,tsv",Regroup,tsv
338,features of a HUMAnN2 generated table,,  HELP HEADER   Rename HUMAnN2 table features is a tool for renaming table features given a custom mapping  The mapping file must be tabular format file with two tab separated columns  The first column must contain the value you want to modify and the second contain the new valu     ,humann2_rename_table,"tsv,tabular,tsv",Rename,tsv
339,a HUMAnN2 generated table,,  HELP HEADER   Renorm HUMAnN2 table is a tool to renormalize a table  either in copies per million or in relative abundance  Each level of a stratified table will be normalized using the desired scheme       ,humann2_renorm_table,"tsv,tabular",Renormalize,tsv
340, combined meta'omic sequencing data,,  HELP HEADER   Given a DNA table and a RNA table  produce smoothed RNA and DNA values as well as relative expression values   Smoothing  means substituting a small value in place of a zero or missing value  The default method used is  Laplace   pseudocount  scaling  where the pseudocount is the sample specific minimum non zero value   Witten Bell smoothing is also implemented       ,humann2_rna_dna_norm,"tsv,tabular,biom1",Normalize,tsv
341,,,  HELP HEADER   This utility will split a table into two files  one stratified and one unstratified       ,humann2_split_stratified_table,"tsv,tabular,biom1",Split stratified table,tsv
342, a HUMAnN2 generated table,,  HELP HEADER   Split HUMAnN2 table is a tool to split a gene table with multiple columns  This file can have been generated with the join table tool      ,humann2_split_table,"tsv,tabular,biom1",Split,
343,,,  HELP HEADER   This script is currently at an experimental stage  Please use with caution   The HUMAnN2 script humann2 strain profiler can help explore strain level variation in your data  This approach assumes you have run HUMAnN2 on a series of samples and then merged the resulting genefamilies tsv tables with humann2 merge tables  Cases will arise in which the same species was detected in two or more samples  but gene families within that species were not consistently present across samples  For example  four samples may contain the species Dialister invisus  but only two samples contain the gene family UniRef50 Q5WII6 within Dialister invisus  This is a form of strain level variation in the Dialister invisus species  one which we can connect directly to function based on annotations of the UniRef50 Q5WII6 gene family   humann2 strain profiler first looks for  species  sample  pairs where  i  a large number of gene families within the species were identified  default  500  and  ii  the mean abundance of detected genes was high  default  mean   10 RPK   For species that meet these criteria  we can infer that absent gene families are likely to be truly absent  as opposed to undersampled  Simulations suggest that the cutoff of 10 RPK results in a false negative rate below 0 001  i e  for every 1000 genes identified as absent  at most one would be present but missed due to undersampling   For a given species  if at least two samples pass these criteria  the species and passing samples are sliced from the merged table and saved as a strain profile   Strain profiles can be additionally restricted to a subset of species  e g  those from a particular genus  or to gene families with a high level of variability in the population  e g  present in fewer than 80  of samples but more than 20  of samples   Additional thresholds  e g  the minimum non zero mean  can be configured with command line parameters      ,humann2_strain_profiler,"tsv,tabular,biom1",Make strain profiles,
344,,,  HELP HEADER   This utility will unpack the pathways to show the genes for each  It adds another level of stratification to the pathway abundance table by including the gene families  or EC  abundances      ,humann2_unpack_pathways,"tsv,tabular",Unpack pathway abundances to show genes included,tsv
345,compare ranked list of identifications,,  The  IDR       Irreproducible Discovery Rate  framework is a uni ed approach to measure the reproducibility of  ndings identi ed from replicate experiments and provide highly stable thresholds based on reproducibility  Unlike the usual scalar measures of reproducibility  the IDR approach creates a curve  which quantitatively assesses when the  ndings are no longer consistent across replicates       ,idr,"bed,gff",IDR,"bed,png"
346,Phylogenomic / evolutionary tree construction from multiple sequences,, IQ TREE          The full documentation can be found here        here     General Tutorial                      Input data             IQ TREE takes as input a  multiple sequence alignment  and will reconstruct an evolutionary tree that is best explained by the input data  The input alignment can be in various common formats  For example the PHYLIP  format which may look like       PHYLIP            7 28     Frog       AAATTTGGTCCTGTGATTCAGCAGTGAT     Turtle     CTTCCACACCCCAGGACTCAGCAGTGAT     Bird       CTACCACACCCCAGGACTCAGCAGTAAT     Human      CTACCACACCCCAGGAAACAGCAGTGAT     Cow        CTACCACACCCCAGGAAACAGCAGTGAC     Whale      CTACCACGCCCCAGGACACAGCAGTGAT     Mouse      CTACCACACCCCAGGACTCAGCAGTGAT  This tiny alignment contains 7 DNA sequences from several animals with the sequence length of 28 nucleotides  IQ TREE also supports other file formats such as FASTA  NEXUS  CLUSTALW  The FASTA file for the above example may look like this            Frog     AAATTTGGTCCTGTGATTCAGCAGTGAT      Turtle     CTTCCACACCCCAGGACTCAGCAGTGAT      Bird     CTACCACACCCCAGGACTCAGCAGTAAT      Human     CTACCACACCCCAGGAAACAGCAGTGAT      Cow     CTACCACACCCCAGGAAACAGCAGTGAC      Whale     CTACCACGCCCCAGGACACAGCAGTGAT      Mouse     CTACCACACCCCAGGACTCAGCAGTGAT    NOTE    If you have raw sequences  you need to first apply alignment programs like MAFFT  or ClustalW  to align the sequences  before feeding them into IQ TREE       MAFFT       ClustalW     Running example                        From the download  there is an example alignment called  example phy  in PHYLIP format  This example contains parts of the mitochondrial DNA sequences of several animals  Source   Phylogenetic Handbook          Phylogenetic Handbook         download   download  You can now start to reconstruct a maximum likelihood tree from this alignment by entering  assuming that you are now in the same folder with  example phy       iqtree  s example phy  st AA  seed 9999  m TESTNEW  msub nuclear  madd LG4M LG4x  merit AICc  bb 2000       s   is the option to specify the name of the alignment file       st   specifies the sequence type as amino acid       seed   ensures that the output files remain the same for subsequent runs       m   sets the modelling parameter for standard model selection       msub   determines the type sub modelling       madd   provides an additional selection mixed models       merit   asserts the type of optimality criterion       bb   defines the number of replicates   Each of these parameters are available under the relevant sub sections in the main tool interface   At the end of the run IQ TREE will write several output files including       example phy iqtree    the main report file that is self readable  You should look at this file to see the computational results  It also contains a textual representation of the final tree  see below        example phy treefile    the ML tree in NEWICK format  which can be visualized by any supported tree viewer programs like FigTree or  iTOL     NOTE    Starting with version 1 5 4  with this simple command IQ TREE will by default perform ModelFinder to find the best fit substitution model and then infer a phylogenetic tree using the selected model   For this example data the resulting maximum likelihood tree may look like this  extracted from    iqtree   file      NOTE    Tree is UNROOTED although outgroup taxon  LngfishAu  is drawn at root                         LngfishAu                                   LngfishSA                                            LngfishAf                                      Frog                                                    Turtle                                                                          Sphenodon                                                                                    Lizard                                                                                Crocodile                                                                                    Bird                                                         Human                                                             Seal                                                                   Cow                                                                         Whale                                                            Mouse                                                                        Rat                                           Platypus                             Opossum   This makes sense as the mammals    Human   to   Opossum    form a clade  whereas the reptiles   Turtle   to   Crocodile    and   Bird   form a separate sister clade  Here the tree is drawn at the  outgroup  Lungfish which is more accient than other species in this example  However  please note that IQ TREE always produces an   unrooted tree   as it knows nothing about this biological background  IQ TREE simply draws the tree this way as   LngfishAu   is the first sequence occuring in the alignment   Choosing the right substitution model                                        IQ TREE will choose the best model for you automatically if specify any of the TEST models  but valid custom models can also be specified that conform to those found in Models  page       Models  Substitution Models binary and morphological models                                   Advanced Parameter Selection                               Using codon models                     IQ TREE supports a number of codon models  You need to input a protein coding DNA alignment and specify codon data by option    st CODON    Otherwise  IQ TREE applies DNA model because it detects that your alignment has DNA sequences          iqtree  s coding gene phy  st CODON  If your alignment length is not divisible by 3  IQ TREE will stop with an error message  IQ TREE will group sites 1 2 3 into codon site 1  sites 4 5 6 to codon site 2  etc  Moreover  any codon  which has at least one gap unknown ambiguous nucleotide  will be treated as unknown codon character   Note that the above command assumes the standard genetic code  If your sequences follow  The Invertebrate Mitochondrial Code   then run          iqtree  s coding gene phy  st CODON5  Note that ModelFinder works for codon alignments  IQ TREE version    1 5 4 will automatically invokes ModelFinder to find the best fit codon model    Assessing branch supports with ultrafast bootstrap approximation                                                                   To overcome the computational burden required by the nonparametric bootstrap  IQ TREE introduces an ultrafast bootstrap approximation  UFBoot    Minh et al   2013   that is  orders of magnitude faster than the standard procedure and provides relatively unbiased branch support values  Citation for UFBoot      B Q  Minh  M A T  Nguyen  and A  von Haeseler  2013  Ultrafast approximation for phylogenetic bootstrap   Mol  Biol  Evol   30 1188 1195          iqtree  s example phy  m TIM2 I G  bb 1000     bb   specifies the number of bootstrap replicates where 1000 is the minimum number recommended  The section    MAXIMUM LIKELIHOOD TREE   in    example phy iqtree   shows a textual representation of the maximum likelihood tree with branch support values in percentage  The NEWICK format of the tree is printed to the file    example phy treefile    In addition  IQ TREE writes the following files       example phy contree    the consensus tree with assigned branch supports where branch lengths are optimized  on the original alignment       example phy splits    support values in percentage for all splits  bipartitions   computed as the occurence frequencies in the bootstrap trees  This file is in  star dot  format       example phy splits nex    has the same information as   example phy splits   but in NEXUS format  which can be viewed with the program SplitsTree  to explore the conflicting signals in the data  So it is more informative than consensus tree  e g  you can see how highly supported the second best conflicting split is  which had no chance to enter the consensus tree       SplitsTree     Reducing impact of severe model violations with UFBoot                                                         Starting with IQ TREE version 1 6 we provide a new option    bnni   to reduce the risk of overestimating branch supports with UFBoot due to severe model violations  With this option UFBoot will further optimize each bootstrap tree using a hill climbing nearest neighbor interchange  NNI  search based directly on the corresponding bootstrap alignment   Thus  if severe model violations are present in the data set at hand  users are advised to append    bnni   to the regular UFBoot command   iqtree  s example phy  m TIM2 I G  bb 1000  bnni  For more details see     D T  Hoang  O  Chernomor  A  von Haeseler  B Q  Minh  L S  Vinh  2017  UFBoot2  Improving the ultrafast bootstrap approximation    Assessing branch supports with  standard nonparametric bootstrap                                                                   The standard nonparametric bootstrap is invoked by  the     b   option   iqtree  s example phy  m TIM2 I G  b 100     b   specifies the number of bootstrap replicates where 100 is the minimum recommended number  The output files are similar to those produced by the UFBoot procedure     Assessing branch supports with single branch tests                                                     IQ TREE provides an implementation of the SH like approximate likelihood ratio test   Guindon et al   2010    To perform this test   run         iqtree  s example phy  m TIM2 I G  alrt 1000     alrt   specifies the number of bootstrap replicates for SH aLRT where 1000 is the minimum number recommended   IQ TREE also supports other tests such as the aBayes test  Anisimova et al   2011  and the local bootstrap test  Adachi and Hasegawa  1996    You can also perform both SH aLRT and the ultrafast bootstrap within one single run         iqtree  s example phy  m TIM2 I G  alrt 1000  bb 1000  The branches of the resulting    treefile   will be assigned with both SH aLRT and UFBoot support values  which are readable by any tree viewer program like FigTree  Dendroscope or ETE  You can also look at the textual tree figure in    iqtree   file     NOTE    Tree is UNROOTED although outgroup taxon  LngfishAu  is drawn at root Numbers in parentheses are SH aLRT support       ultrafast bootstrap support                            LngfishAu                                  LngfishSA                100 100                           LngfishAf                                       Frog               99 8 100                                              Turtle                              85 72                                                          Crocodile                                   96 5 97                                                    Bird                           39 51                                                     Sphenodon                        98 2 99                                                      Lizard                  100 100                                         Human                            92 3 93                                    Seal                               68 3 75                                      Cow                                  99 7 100                                        Whale                         99 1 100                                     Mouse                                   100 100                                        Rat                    100 100                        Platypus           93 98                  Opossum   From this figure  the branching patterns within reptiles are poorly supported  e g    Sphenodon   with SH aLRT  39   UFBoot  51  and   Turtle   with SH aLRT  85   UFBoot  72   as well as the phylogenetic position of   Seal   within mammals  SH aLRT  68 3   UFBoot  75    Other branches appear to be well supported      ,iqtree,"txt,nhx",IQ-TREE,"nhx,mldist,nex,iqtree"
347,Smooth and Plot,, This tool imports a collection of genomic region datasets  and associates to each region multiple genomic feature measurements  It allows to align the regions in multiple ways  center  left  right or scale alignment   to smooth the feature curves  possibly filling gaps in the measurements  and to create a graphical representation of the feature measurements in each region datasets  aligned curves or pointwise quantile curves             Region datasets    Each region dataset can be provided as a BED or Tabular file with tab delimited columns chr start end  extra columns present in the input file are ignored   Regions can be of different length        chr2  49960150  50060150     chr2  55912445  56012445                   Feature measurements    Feature measurements corresponding to all the regions can be provided as a BED or Tabular file with tab delimited columns chr start end value        chr2  49960150  49962150  0 9426     chr2  49962150  49964150  0 7816          Each feature must be measured in windows of a fixed size inside all the regions  missing values must be indicated as NA   Another way to import feature measurements is from a Tabular file with the first three columns chr start end corresponding to the different genomic regions  followed on the same row by all the measurements in fixed size windows        chr2  49960150  50060150  0 9426  0 7816  0 8921            1 2063     chr2  55912445  56012445  0 8719  0 9975  1 1619            0 9601                   Output    The tool returns   1  RData with the IWTomicsData object  that stores the aligned genomic region datasets  and their associated feature measurements  2  Region dataset identifiers  3  Feature identifiers  4  PDF file with the plotted data   1 3 can be used as input of the tool  IWTomics Test and Plot             class   infomark    Notes    This Galaxy tool has been developed by Fabio Cumbo  Third University of Rome  Italy   fabio cumbo iasi cnr it  and Marzia A  Cremona  The Pennsylvania State University  USA   mac78 psu edu    It implements a simplified version of the methods  smooth  and  plot  for  IWTomicsData  objects  The complete version can be found in the  R Bioconductor  package  IWTomics   see vignette         vignette    Example data can be found at   1  Simulated data  2  ETn data       Simulated data       ETn data     ,iwtomics_loadandplot,tabular,IWTomics Load,"rdata,tabular,pdf"
348,on Test Scale,, This tool allows to select the scale for the Interval Wise Testing results  In particular  it returns the p value curves for the different tests performed at the selected scale  and it creates a graphical representation of the Interval Wise Testing results and a summary plot  optional  at the selected scale            Input files    RData file with the IWTomicsData object with test results  tabular files with test IDs and feature IDs  These files are created by the tool  IWTomics Test and Plot             Output    The tool returns   1  TXT file with an adjusted p value curve for every test performed at the selected scale  2  PDF file with the plotted test results  3  PDF file with the summary plot             class   infomark    Notes    This Galaxy tool has been developed by Fabio Cumbo  Third University of Rome  Italy  and Marzia A  Cremona  The Pennsylvania State University  USA    It implements a simplified version of the function  IWTomicsTest    plotTest  and  plotSummary  for  IWTomicsData  objects  The complete version can be found in the  R Bioconductor  package  IWTomics   see vignette         vignette     ,iwtomics_plotwithscale,"rdata,tabular",IWTomics Plot with Threshold,"txt,pdf"
349,and Plot,, This tool statistically evaluates differences in genomic features between groups of regions along the genome  In particular  it implements the Interval Wise Testing for omics data  an extended version of the Interval Wise Testing for functional data presented in Pini and Vantini  2017   It allows to perform multiple two sample permutation tests between pairs of region datasets  on several features  It returns the adjusted p value curves for every test and all possible scales  Moreover  it creates a graphical representation of the Interval Wise Testing results and a summary plot  optional  with p values at the maximum scale  The tool  IWTomics Plot with Threshold on Test Scale  permits to select the scale to be used in the plots            Input files    RData file with the IWTomicsData object  tabular files with region dataset IDs and feature IDs  These files are created by the tool  IWTomics Load Smooth and Plot             Output    The tool returns   1  TXT file with an adjusted p value matrix for every test performed  Each matrix contains a p value curve  row  for every scale considered in the test  2  PDF file with the plotted test results  3  PDF file with the summary plot  4  RData with the IWTomicsData object with the test results  5  Test identifiers  6  Feature identifiers   4 6 can be used as input of the tool  IWTomics Plot with Threshold on Test Scale             class   infomark    Notes    This Galaxy tool has been developed by Fabio Cumbo  Third University of Rome  Italy  and Marzia A  Cremona  The Pennsylvania State University  USA    It implements a simplified version of the function  IWTomicsTest    plotTest  and  plotSummary  for  IWTomicsData  objects  The complete version can be found in the  R Bioconductor  package  IWTomics   see vignette         vignette     ,iwtomics_testandplot,"rdata,tabular",IWTomics Test,"txt,pdf,rdata,tabular"
350,upgrades the bare data directory to a full JBrowse instance,, Upgrades an existing bare JBrowse  data  directory into a full fledged JBrowse instance    ATTRIBUTION  ,jbrowse_to_standalone,html,JBrowse - Data Directory to Standalone,html
351,genome browser,, JBrowse in Galaxy                    JBrowse in Galaxy offers a highly configurable  workflow compatible alternative to Trackster   Overview           JBrowse is a fast  embeddable genome browser built completely with JavaScript and HTML5   The JBrowse in Galaxy  JiG  tool was written to help build complex JBrowse installations straight from Galaxy  taking advantage of the latest Galaxy features such as dataset collections  sections  and colour pickers  It allows you to build up a JBrowse instance without worrying about how to run the command line tools to format your data  and which options need to be supplied and where  Additionally it comes with many javascript functions to handle colouring of features which would be nearly impossible to write without the assistance of this tool   The JBrowse in Galaxy tool is maintained by  Eric Rasche  mailto esr jig tamu edu      who you can contact if you encounter missing features or bugs   Options          The first option you encounter is the   Fasta Sequence s     This option now accepts multiple fasta files  allowing you to build JBrowse instances that contain data for multiple genomes or chrosomomes  generally known as  landmark features  in gff3 terminology   Up to 30 will be shown from the dropdown selector within JBrowse  this is a known issue     Standalone Instances   are a somewhat in development feature  Currently Galaxy copies the entire JBrowse directory in order to have a complete  downloadable file that contains a ready to go JBrowse instance  This is obviously an anti feature because users don t want a complete copy of JBrowse  6 20Mb  that s duplicated for every JBrowse dataset in their history  and admins don t want useless copies of JBrowse on disk  Unfortunately we have not come up with the perfect solution just yet  but we re working on it  In the meantime  users have been given the option to produce just the   data    directory  For those unfamiliar with JBrowse  the   data    directory contains processed data files  but no way to view them  This feature is additionally implemented for upcoming  Apollo      integration     Genetic Code   is a new feature in v0 4 of JiG   v1 12 0 of JBrowse  which allows users to specify a non standard genetic code  and have JBrowse highlight the correct start and stop codons  If you would like to use a coding table not provided by this list  please let  me  mailto esr jig tamu edu     know so that I may add support for this     Track Groups   represent a set of tracks in a single category  These can be used to let your users understand relationships between large groups of tracks      image   sections png  Annotation Tracks                    Within Track Groups  you have one or more   Annotation Tracks    Each Annotation Track is a groups of datasets which have similar styling  This allows you to rapidly build up JBrowse instances without having to configure tracks individually  A massive improvement over previous versions  For example  if you have five different GFF3 files from various gene callers that you wish to display  you can take advantage of this feature to style all of them similarly   There are a few different types of tracks supported  each with their own set of options   GFF3 BED GBK               These are your standard feature tracks  They usually highlight genes  mRNAs and other features of interest along a genomic region  The underlying tool and this help documentation focus primarily on GFF3 data  and have not been tested extensively with other formats  Automatic min max detection will likely fail under BED and GBK datasets   The data may be of a subclass we call   match match part   data  This consists of top level   match   features  with a child   match part   feature  and is often used in displaying alignments   See  Alignments  section on the  GFF3 specification      for more information   If the data is match match part  you will need to specify the top level match feature name  as it can be one of a few different SO terms  and JiG does not yet have the ability to understand SO terms   Next up is the   Styling Options   section  which lets you control a few properties on how the track is styled  Most of these you will not need to configure and can safely leave on defaults  Occasionally you will want to change what information is shown in the end product      image   styling png  In the above image you can see some black text  and some blue text  The source of the black text is configured with the   style label   option  and the source of the blue text is configured with the   style description   option   Feature Score Scaling   Colouring Options                                            First  you need to choose between ignoring the score attribute of GFF3 files  or using it  If you choose to ignore it  all features will be coloured with a solid colour  If you choose to use it  features will have slightly different colours based on their scores      image   opacity png  If you choose   Ignore score    you may choose between automatically choosing a colour  or manually specifying one  The automatically chosen colours vary along a brewer palette and generally look quite nice with no human intervention required  The manual colour choice is somewhat self explanatory  Clicking on the small coloured square will bring up a colour palette   If you choose   Base on score    you re faced with a dizzying array of options  First is the function to map the colour choices to colour values  JiG comes with a few functions built in such as linear scaling  logarithmic scaling  and blast scaling   The   linear scaling   method says  take these values  and they map directly to a range of output values     Logarithmic scaling   says  please take the log of the score before mapping   and   Blast scaling   is further specialised to handle blast data more nicely  These are convenience functions to help transform the wide array of possible values in the GFF3 score attribute to more meaningful numbers  If you need more comprehensive score scaling  it is recommended that you pre process your GFF3 files somehow   Once you ve selected a scaling method  you can choose to manually specify the minimum and maximum expected values  or you can let JiG determine them for you automatically   Finally  opacity is the only mapping we currently provide  Future iterations will attempt to improve upon this and provide more colour scales  The Opacity option maps the highest scoring features to full opacity  and everything else to lower ones   BAM Pileups              We support BAM files and can automatically generate SNP tracks based on that bam data      image   bam png  This is  strongly discouraged  for high coverage density datasets  Unfortunately there are no other configuration options exposed for bam files  If you find JBrowse options you wish to see exposed  please let  me  mailto esr jig tamu edu     know   BlastXML              image   blast png  JiG now supports both blastn and blastp datasets  JiG internally uses a blastXML to gapped GFF3 tool to convert your blastxml datasets into a format amenable to visualization in JBrowse  This tool is also available separately from the IUC on the toolshed     Minimum Gap Size   reflects how long a gap must be before it becomes a real gap in the processed gff3 file  In the picture above  various sizes of gaps can be seen  If the minimum gap size was set much higher  say 100nt  many of the smaller gaps would disappear  and the features on both sides would be merged into one  longer feature  This setting is inversely proportional to runtime and output file size   Do not set this to a low value for large datasets   By setting this number lower  you will have extremely large outputs and extremely long runtimes  The default was configured based off of the author s experience  but the author only works on small viruses  It is  strongly  recommended that you filter your blast results before display  e g  picking out the top 10 hits or so     Protein blast search   option merely informs underlying tools that they should adjust feature locations by 3x   Styling Options                  Please see the styling options for GFF3 datasets  they are identical   Feature Score Scaling   Coloring Options                                           Please see the score scaling and colouring options for GFF3 datasets  they are identical  Remember to set your score scaling to  blast  method if you do use it   Bigwig XY               image   bigwig png    XYPlot    BigWig tracks can be displayed as a  density  plot which is continuous line which varies in colour  or as an  XYplot   XYplots are preferable for users to visually identify specific features in a bigwig track  however density tracks are more visually compact     Variance Band   is an option available to XYPlots  and can be seen in the third and fourth tracks in the above picture  This overlays a mean line  and 1 and 2 standard deviation areas     Track Scaling   is different from colour scaling  instead it configures how the track behaves inside of JBrowse    Autoscaling globally   means that JBrowse will determine the minimum and maximum for the track  and fix the bounds of the viewport to that  E g  if your track ranges from 1 1000  and the region you re currently zoomed to only goes from 0 50  then the viewport range will still show 1 1000  This is good for global genomic context  However you may wish to consider   autoscaling locally   instead  In the example of a region which varies from 0 50  autoscaling locally would cause the individual track s viewport to re adjust and show just the 0 50 region  If neither of these options are palatable  you may manually hardcode the minimum and maximums for the track to scale to   Colour Options                 BigWig tracks have two colours in JBrowse  a positive and a negative colour   As always you may manually choose a colour  or let JiG choose for you   One of the more interesting options is the   Bicolor pivot    This option allows you to control the point at which JBrowse switches from the positive colour to the negative  In the above graphic  you can see this has been configured to  mean  for the first two  orange and blue  tracks   VCFs SNPs            These tracks do not support any special configuration   Known Issues                  More than 30 landmark features cannot be listed in the manual    selector     Non GFF3 likely has issue with automatically determined min max    scores  Manually specify minimum and maximum score attributes  or do    not use varied colours based on scores to avoid this issue     ATTRIBUTION  ,jbrowse,"fasta,html,gff3",JBrowse,html
352,,,Joins datasets by identifier column,join_files_by_id,tabular,Join datasets by identifier column,tabular
353,process JSON,, JQ         jq is a lightweight and flexible JSON processor   Brief Examples                 See  the manual      for a much more detailed guide on using JQ   Select an Attribute                      Given an input like the following            foo   42   bar    less interesting data    To select just the value of   foo    supply the filter    foo    Loop over an Array                     Given an input like the following             foo   1123     foo   6536     foo   5321    To select the values of   foo    supply the filter       foo   or          foo    This will produce a file with one number per line   If you wish to select multiple things              foo   1123   bar    a      foo   6536   bar    b      foo   5321   bar    c     To select the values of   foo   AND   bar    supply the filter           foo   bar     This will produce and output array like                      1123   a            6536   b            5321   c          A common next step is to turn this into a tabular output which more Galaxy tools can work with  This can be done by checking the box for tabular  This will invoke the JQ filter of    tsv   at the end of the processing chain  and produce a tabular file       ,jq,json,JQ,json
354,- run pseudoalignment on RNA-Seq transcripts,,     kallisto      is a program for quantifying abundances of transcripts from RNA Seq data  or more generally of target sequences using high throughput sequencing reads  It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets  without the need for alignment         ,kallisto_pseudo,"fastq,tabular",Kallisto pseudo,"tabular,bam"
355,- quantify abundances of RNA-Seq transcripts,,    kallisto is a program for quantifying abundances of transcripts from RNA Seq data  or more generally of target sequences using high throughput sequencing reads  It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets  without the need for alignment  On benchmarks with standard RNA Seq data  kallisto can quantify 30 million human reads in less than 3 minutes on a Mac desktop computer using only the read sequences and a transcriptome index that itself takes less than 10 minutes to build  Pseudoalignment of reads preserves the key information needed for quantification  and kallisto is therefore not only fast  but also as accurate as existing quantification tools  In fact  because the pseudoalignment procedure is robust to errors in the reads  in many benchmarks kallisto significantly outperforms existing tools         ,kallisto_quant,"fastq,fastq.gz",Kallisto quant,"h5,tabular,bam"
356,"
        Calculate abundance distribution of k-mers
    ",, Calculate the abundance distribution of k mers from a single sequence file   Note that with   b  this script is constant memory  in exchange  k mer counts will stop at 255  The memory usage of this script with   b  will be about 1 15x the product of the   x  and   N  numbers     HELP FOOTER       ,khmer_abundance_distribution_single,,Abundance Distribution (all-in-one),oxlicg
357,"
        Calculate abundance distribution of k-mers using pre-made k-mer countgraphs
    ",, Calculate abundance distribution of the k mers in the sequence file using a pre made k mer countgraph    HELP FOOTER       ,khmer_abundance_distribution,,Abundance Distribution,
358,Count the median/avg k-mer abundance for each sequence,, Count the median avg k mer abundance for each sequence in the input file  based on the k mer counts in the given k mer countgraph  Can be used to estimate expression levels  mRNAseq  or coverage  genomic metagenomic   The output file contains sequence id  median  average  stddev  and seq length  fields are separated by spaces  For khmer 1 x count median py will split sequence names at the first space which means that some sequence formats  e g  paired FASTQ in Casava 1 8 format  will yield uninformative names  Use    csv  to fix this behavior    HELP FOOTER       ,khmer_count_median,,Count Median,txt
359,"Load, partition, and annotate FAST[AQ] sequences",,  Load in a set of sequences  partition them  merge the partitions  and annotate the original sequences files with the partition information   This script combines the functionality of  load graph py    partition graph py    merge partitions py   and  annotate partitions py  into one script  This is convenient but should probably not be used for large data sets  because  do partition py  doesn t provide save resume functionality        ,khmer_partition,,Sequence partition all-in-one,txt
360,Separate sequences that are annotated with partitions into grouped files,, Separate sequences that are annotated with partitions into grouped files    HELP FOOTER       ,khmer_extract_partitions,,Extract partitions,txt
361,"
        by minimal k-mer abundance
    ",, Trims fastq fasta sequences at k mers of a given abundance based on a provided k mer countgraph  If the input sequences are from RNAseq or metagenome sequencing then    variable coverage  should be used    HELP FOOTER       ,khmer_filter_abundance,,Filter reads,
362,"
        below k-mer abundance of 50
    ",, Trims fastq fasta sequences at k mers with abundance below 50 based on a provided k mer countgraph    HELP FOOTER  ,khmer_filter_below_abundance_cutoff,,Filter reads,
363,Filter reads using digital normalization via k-mer abundances,, Do digital normalization  remove mostly redundant sequences   Discard sequences based on whether or not their median k mer abundance lies above a specified cutoff  Kept sequences will be placed in  fileN  keep   By default  Paired end reads will be considered together  if either read will be kept  then both will be kept   This keeps both reads from a fragment  and helps with retention of repeats   Unpaired reads are treated individually   If    paired  is set then proper pairing is required and the tool will exit on unpaired reads  although    unpaired reads  can be used to supply a file of orphan reads to be read after the paired reads      force single  will ignore all pairing information and treat reads individually   With   s     savegraph   the k mer countgraph will be saved to the specified file after all sequences have been processed     loadgraph  will load the specified k mer countgraph before processing the specified files   Note that the countgraph is in same format as those produced by  load into counting py  and consumed by  abundance dist py     HELP FOOTER           ,khmer_normalize_by_median,"fasta,fastq,fastqsanger,fastqsolexa,fastqillumina,oxlicg",Normalize By Median,"oxlicg,txt"
364,KEGG Orthology Based Annotation System,,  HELP KOBAS INFO     KOBAS Annotate    Annotates an input set of genes with putative pathways and disease relationships based on mapping to genes with known annotations  It allows for both ID mapping and cross species sequence similarity mapping    HELP KOBAS URL      ,kobas_annotate,"fasta,tabular,txt,sqlite",KOBAS Annotate,tabular
365,KEGG Orthology Based Annotation System,,  HELP KOBAS INFO     KOBAS Identify    Performs statistical tests to identify significantly enriched pathways and diseases    HELP KOBAS URL      ,kobas_identify,"tabular,txt",KOBAS Identify,tabular
366,view report of classification for multiple samples,,    class   warningmark    Note    the database used must be the same as the one used in the original Kraken run           What is Does    Summarizes read counts across taxonomic ranks for multiple samples  This is convenient for comparing results across multiple experiments  conditions  locations  etc            Output    The output is tab delimited  with one line per taxon   Will optionally output a newick tree built from the kraken database taxonomy using the specified options  Tree branch lengths will be set to  1 00000       ,kraken_taxonomy_report,tabular,Kraken taxonomic report,"tabular,txt"
367,from GTF and FASTA file,,   class   infomark,length_and_gc_content,"gtf,fasta",Gene length and GC content,tabular
368,"
        Perform differential expression with limma-voom or limma-trend
    ",,Given a matrix of counts  e g  from featureCounts  and optional information about the genes  performs differential expression  DE  using the limma  Bioconductor package and produces plots and tables useful in DE analysis ,limma_voom,tabular,limma,html
369,Call broad peaks from bedGraph output,,This is   bdgbroadcall   utility from the MACS2  Package  It is designed to call broad peaks  e g   histone  from bedGraph datasets generated with MACS2 ,macs2_bdgbroadcall,bedgraph,MACS2 bdgbroadcall,interval
370,Deduct noise by comparing two signal tracks in bedGraph,,This is   bdgcmp   utility from the MACS2  Package  It is designed to deduct noise by comparing two signal tracks in bedGraph ,macs2_bdgcmp,bedgraph,MACS2 bdgcmp,bedgraph
371,Differential peak detection based on paired four bedgraph files,,This is   bdgdiff   utility from the MACS2  Package  It performs differential peak detection based on paired four bedgraph files ,macs2_bdgdiff,bedgraph,MACS2 bdgdiff,bed
372,Call peaks from bedGraph output,,This is   bdgpeakcall   utility from the MACS2  Package  It calls peaks from bedGraph output ,macs2_bdgpeakcall,bedgraph,MACS2 bdgpeakcall,bedgraph
373,Call peaks from alignment results,,  callpeak   is the main function of the MACS2  package  MACS identifies enriched binding sites in ChIP seq experiments  It captures the influence of genome complexity to evaluate the significance of enriched ChIP regions  and improves the spatial resolution of binding sites through combining the information of both sequencing tag position and orientation ,macs2_callpeak,"bam,sam,bed",MACS2 callpeak,"tabular,bed,pdf,bedgraph,html"
374,Remove duplicate reads at the same position,,This is   filterdup   utility from the MACS2  Package  It removes duplicate reads and converts results to BED format ,macs2_filterdup,"sam,bam,bed",MACS2 filterdup,bed
375,Predict 'd' or fragment size from alignment results,,This is   predictd   utility from the MACS2  Package  It predicts the  d  value or fragment size from alignment results ,macs2_predictd,"bam,sam,bed",MACS2 predictd,"txt,pdf"
376,Randomly sample number or percentage of total reads,,This is   randsample   utility from the MACS2  Package  It randomly samples reads by number or percentage from an input file ,macs2_randsample,"sam,bam,bed",MACS2 randsample,bed
377,Refine peak summits and give scores measuring balance of forward- backward tags (Experimental),,This is   refinepeak   utility from the MACS2  Package  It is an experimental utility that takes raw read alignments  refines peak summits and gives scores measuring balance of forward  backward tags  Inspired by the SPP  pipeline ,macs2_refinepeak,"sam,bam,bed,bed",MACS2 refinepeak,bed
378,genome annotation pipeline,,         MAKER is a portable and easily configurable genome annotation pipeline  Its purpose is to allow smaller eukaryotic and prokaryotic genome projects to independently annotate their genomes and to create genome databases  MAKER identifies repeats  aligns ESTs and proteins to a genome  produces ab initio gene predictions and automatically synthesizes these data into gene annotations having evidence based quality values  MAKER is also easily trainable  outputs of preliminary runs can be used to automatically retrain its gene prediction algorithm  producing higher quality gene models on seusequent runs  MAKER s inputs are minimal and its ouputs can be directly loaded into a GMOD database  They can also be viewed in the Apollo genome browser  this feature of MAKER provides an easy means to annotate  view and edit individual contigs and BACs without the overhead of a database  MAKER should prove especially useful for emerging model organism projects with minimal bioinformatics expertise and computer resources               Maker       ,maker,"fasta,gff,snaphmm,augustus",Maker,gff3
379,on a Maker annotation,,         MAKER is a portable and easily configurable genome annotation pipeline  Its purpose is to allow smaller eukaryotic and prokaryotic genome projects to independently annotate their genomes and to create genome databases  MAKER identifies repeats  aligns ESTs and proteins to a genome  produces ab initio gene predictions and automatically synthesizes these data into gene annotations having evidence based quality values  MAKER is also easily trainable  outputs of preliminary runs can be used to automatically retrain its gene prediction algorithm  producing higher quality gene models on seusequent runs  MAKER s inputs are minimal and its ouputs can be directly loaded into a GMOD database  They can also be viewed in the Apollo genome browser  this feature of MAKER provides an easy means to annotate  view and edit individual contigs and BACs without the overhead of a database  MAKER should prove especially useful for emerging model organism projects with minimal bioinformatics expertise and computer resources           This tool will automatically assign new ids to a Maker annotation respecting a specified pattern               Maker       ,maker_map_ids,gff,Map annotation ids,"gff,tabular"
380,Significant Gene Expression Profile Differences in Time Course Gene Expression Data,,maSigPro  is a regression based approach to find genes for which there are significant gene expression profile differences between experimental groups in time course microarray and RNA Seq experiments ,masigpro,"tabular,txt,tabular",maSigPro,"txt,pdf,tabular"
381,for metagenomics assembly,,MEGAHIT is a single node assembler for large and complex metagenomics NGS reads  such as soil  It makes use of succinct de Bruijn graph  SdBG  to achieve low memory assembly  MEGAHIT can optionally utilize a CUDA enabled GPU to accelerate its SdBG contstruction  The GPU accelerated version of MEGAHIT has been tested on NVIDIA GTX680  4G memory  and Tesla K40c  12G memory  with CUDA 5 5  6 0 and 6 5 ,megahit,"fastq,fastqsanger,fasta,fastq.gz,fastqsanger.gz",MEGAHIT,fasta
382,- Scan a set of sequences for motifs.,,     class   warningmark    WARNING  This tool is only available for non commercial use  Use for educational  research and non profit purposes is permitted  Before using  be sure to review  agree  and comply with the license     FIMO scans a sequence database for individual matches to each of the motifs you provide  sample output for motifs and sequences   The name FIMO stands for  Find Individual Motif Occurrences    The program searches a database of sequences for occurrences of known motifs  treating each motif independently   Motifs must be in MEME Motif Format   You can define the statistical threshold  p value  for motifs and whether FIMO scans just the given sequences or their reverse complements  where applicable       class   infomark  For detailed information on FIMO  click here   or view the license        here       license        ,meme_fimo,"memexml,fasta,txt",FIMO,"html,tabular,cisml,interval"
383,- Multiple Em for Motif Elicitation,,     class   warningmark    WARNING  This tool is only available for non commercial use  Use for educational  research and non profit purposes is permitted  Before using  be sure to review  agree  and comply with the license     If you want to specify sequence weights  you must include them at the top of your input FASTA file   MEME discovers novel  ungapped motifs  recurring  fixed length patterns  in your sequences  sample output from sequences   MEME splits variable length patterns into two or more separate motifs   A motif is a sequence pattern that occurs repeatedly in a group of related sequences   MEME represents motifs as position dependent letter probability matrices which describe the probability of each possible letter at each position in the pattern   Individual MEME motifs do not contain gaps   Patterns with variable length gaps are split by MEME into two or more separate motifs   MEME takes as input a group of sequences and outputs as many motifs as requested   MEME uses statistical modeling techniques to automatically choose the best width  number of occurrences  and description for each motif      class   infomark  For detailed information on MEME  click here   or view the license        here       license        ,meme_meme,"fasta,txt",MEME,"html,txt,memexml"
384,- perform discriminative motif discovery,,     class   warningmark    WARNING  This tool is only available for non commercial use  Use for educational  research and non profit purposes is permitted  Before using  be sure to review  agree  and comply with the license     psp gen is used to allow MEME to perform discriminative motif discovery to find motifs overrepresented in one set of sequences compared to in another set  It takes two files as input the sequence file to be input to MEME   the  primary  file  and a  control  sequence file of sequences believed not to contain the same motifs as in the  primary  file  psp gen creates a file for use by MEME that encapsulates information about probable discriminative motifs  psp gen records its chosen motif width in the file  and MEME is able to adjust the data when it tries different motif widths      class   infomark  For detailed information on psp gen  click here   or view the license        here       license             Required options        Primary sequence file     a file containing FASTA formatted sequences which are to be used as the primary set in PSP calculation      Control sequence file     a file containing FASTA formatted sequences which are to be used as the control set in PSP calculation     Additional options        Minimum width to use for position specific priors     the minimum width to use with selecting the  best  width for PSPs      Maximum width to use for position specific priors     the maximum width to use with selecting the  best  width for PSPs      Alphabet     The alphabet to be used  one of DNA  protein or RNA      Use spaced triples instead of whole word matches     use spaced triples instead of whole word matches  recommended when using the protein alphabet           Allow triples to start anywhere within a site     when using the  triples option  select  Yes  to only consider triples starting at the start of the site or  No  to allow triples to start anywhere in a width  w  site       Match as equal sequences of letters that appear together     select  Yes  to match as equal any sequence of letter that appears together  Separate letter groups using      e g   equiv  IVL HKR   means treat all occurrences of I  V or L as the same  and all occurrences of H  K or R as the same      Consider both strands when calculating position specific priors for alphabets     select  Yes  to consider both strands when calculating PSPs for complementable alphabets or  No to consider only the given strand      Set the lowest score value after scaling     select  Yes  to set the lowest score to 0 1 unless the the following  highest score  option is selected  in which case the lowest score is highest score   1      Set the highest score value after scaling     select  Yes  to set the highest score to 0 9 unless the previous  lowest score  option is selected  in which case the highest score is lowest score   1      Choose the width with the biggest difference between minimum and maximum scores before scaling     select  Yes  to choose the width with the biggest difference between minimum and maximum scores before scaling  or  No  to choose the width with the biggest maximum score before scaling      Output scores instead of priors     select  Yes  to output scores instead of position specific priors      Output primary and control file names  scores and widths     select  Yes  to produce an additional tabular output consisting of control file names  lowest and highest scores and lowest and highest widths          Report frequency of each score     select  Yes  to include the frequency of each score in the output       ,meme_psp_gen,fasta,MEME psp-gen,"memepsp,tabular"
385,Cumulative sum scaling,, metagenomeSeq Cumulative sum scaling                                       Info               Cumulative sum scaling based upon percentile selection  You can manually specificy the percentile or calculate it using cumNormStat or cumNormStatFast   Inputs                 Requires a BIOM formatted file for input    Outputs                  Creates a normalized and scaled output abundance matrix in Tabular format  Additionally can create simple statistics and the RScript       ,metagenomeseq_normalizaton,biom1,metagenomeSeq Normalization,"tabular,txt"
386,MetaPhlAn2 files,,MetaPhlAn is a computational tool to profile the structure and the composition of microbial communities  Bacteria  Archaea  Eukaryotes and Viruses  from metagenomic shotgun sequencing data with species level resolution  For more information  check the  user manual     ,merge_metaphlan_tables,"tabular,txt",Merge,tabular
387,to profile the composition of microbial communities,,MetaPhlAn is a computational tool to profile the structure and the composition of microbial communities  Bacteria  Archaea  Eukaryotes and Viruses  from metagenomic shotgun sequencing data with species level resolution  For more information  check the  user manual     ,metaphlan2,"fastq,fasta,sam,fasta,json",MetaPhlAn2,"tabular,sam,biom1"
388,output for Krona,,MetaPhlAn is a computational tool to profile the structure and the composition of microbial communities  Bacteria  Archaea  Eukaryotes and Viruses  from metagenomic shotgun sequencing data with species level resolution  For more information  check the  user manual     ,metaphlan2krona,"tabular,txt",Format MetaPhlAn2,tabular
389,"with hierarchical clustering of both samples
and microbial clades for MetaPhlAn2",,MetaPhlAn is a computational tool to profile the structure and the composition of microbial communities  Bacteria  Archaea  Eukaryotes and Viruses  from metagenomic shotgun sequencing data with species level resolution  For more information  check the  user manual     ,metaphlan_hclust_heatmap,"tabular,txt",Generate heatmap,"pdf,png,svg"
390,assembler for metagenomics datasets,,SPAdes   St  Petersburg genome assembler   is intended for both standard isolates and single cell MDA bacteria assemblies  See  for more details on SPAdes ,metaspades,fastq,metaSPAdes,"fasta,txt"
391,"mapper for full-length T- and B-cell repertoire sequencing
    ",,      This software is a smart wrapper for the IgBlast V  D  J mapping tool designed to facilitate analysis immune     receptor libraries profiled using high throughput sequencing      ,migmap,"fasta,fastq",MiGMAP,"tabular,txt"
392,A fast pairwise aligner for genomic and spliced nucleotide sequences,,  Users  Guide               Minimap2 is a versatile sequence alignment program that aligns DNA or mRNA sequences against a large reference database  Typical use cases include   1  mapping PacBio or Oxford Nanopore genomic reads to the human genome   2  finding overlaps between long reads with error rate up to  15    3  splice aware alignment of PacBio Iso Seq or Nanopore cDNA or Direct RNA reads against a reference genome   4  aligning Illumina single  or paired end reads   5  assembly to assembly alignment   6  full genome alignment between two closely related species with divergence below  15    For  10kb noisy reads sequences  minimap2 is tens of times faster than mainstream long read mappers such as BLASR  BWA MEM  NGMLR and GMAP  It is more accurate on simulated long reads and produces biologically meaningful alignment ready for downstream analyses  For  100bp Illumina short reads  minimap2 is three times as fast as BWA MEM and Bowtie2  and as accurate on simulated data  Detailed evaluations are available from the  minimap2 preprint    General usage                Minimap2 seamlessly works with gzip d FASTA and FASTQ formats as input  You don t need to convert between FASTA and FASTQ or decompress gzip d files first   For the human reference genome  minimap2 takes a few minutes to generate a minimizer index for the reference before mapping  To reduce indexing time  you can optionally save the index with option    d   and replace the reference sequence file with the index file on the minimap2 command line      Importantly     it should be noted that once you build the index  indexing parameters such as    k       w       H   and    I   can t be changed during mapping  If you are running minimap2 for different data types  you will probably need to keep multiple indexes generated with different parameters  This makes minimap2 different from BWA which always uses the same index regardless of query data types   Use cases            Minimap2 uses the same base algorithm for all applications  However  due to the different data types it supports  e g  short vs long reads  DNA vs mRNA reads   minimap2 needs to be tuned for optimal performance and accuracy  It is usually recommended to choose a preset with option    x    which sets multiple parameters at the same time  The default setting is the same as   map ont     Map long noisy genomic reads                               The difference between   map pb   and   map ont   is that   map pb   uses homopolymer compressed  HPC  minimizers as seeds  while   map ont   uses ordinary minimizers as seeds  Emperical evaluation suggests HPC minimizers improve performance and sensitivity when aligning PacBio reads  but hurt when aligning Nanopore reads   Map long mRNA cDNA reads                            There are different long read RNA seq technologies  including tranditional full length cDNA  EST  PacBio Iso seq  Nanopore 2D cDNA seq and Direct RNA seq  They produce data of varying quality and properties  By default     x splice   assumes the read orientation relative to the transcript strand is unknown  It tries two rounds of alignment to infer the orientation and write the strand to the   ts   SAM PAF tag if possible  For Iso seq  Direct RNA seq and tranditional full length cDNAs  it would be desired to apply    u f   to force minimap2 to consider the forward transcript strand only  This speeds up alignment with slight improvement to accuracy  For noisy Nanopore Direct RNA seq reads  it is recommended to use a smaller k mer size for increased sensitivity to the first or the last exons   It is worth noting that by default    x splice   prefers GT A G    C T AG over GT C T    A G AG  and then over other splicing signals  Considering one additional base improves the junction accuracy for noisy reads  but reduces the accuracy when aligning against the widely used SIRV control data  This is because SIRV does not honor the evolutionarily conservative splicing signal  If you are studying SIRV  you may apply     splice flank no   to let minimap2 only model GT  AG  ignoring the additional base   Find overlaps between long reads                                   Similarly    ava pb   uses HPC minimizers while   ava ont   uses ordinary minimizers  It is usually not recommended to perform base level alignment in the overlapping mode because it is slow and may produce false positive overlaps  However  if performance is not a concern  you may try to add    a   or    c   anyway   Map short accurate genomic reads                                    When two read files are specified  minimap2 reads from each file in turn and merge them into an interleaved stream internally  Two reads are considered to be paired if they are adjacent in the input stream and have the same name  with the     0 9    suffix trimmed if present   Single  and paired end reads can be mixed   Minimap2 does not work well with short spliced reads  There are many capable RNA seq mappers for short reads   Full genome assembly alignment                                 For cross species full genome alignment  the scoring system needs to be tuned according to the sequence divergence   Advanced features                    Working with  65535 CIGAR operations                                       Due to a design flaw  BAM does not work with CIGAR strings with  65535 operations  SAM and CRAM work   However  for ultra long nanopore reads minimap2 may align  1  of read bases with long CIGARs beyond the capability of BAM  If you convert such SAM CRAM to BAM  Picard and recent samtools will throw an error and abort  Older samtools and other tools may create corrupted BAM   To avoid this issue  you can add option    L   at the minimap2 command line  This option moves a long CIGAR to the   CG   tag and leaves a fully clipped CIGAR at the SAM CIGAR column  Current tools that don t read CIGAR  e g  merging and sorting  still work with such BAM records  tools that read CIGAR will effectively ignore these records  It has been decided that future tools will seamlessly recognize long cigar records generated by option   L      TD DR    if you work with ultra long reads and use tools that only process BAM files  please add option    L     The cs optional tag                      The   cs   SAM PAF tag encodes bases at mismatches and INDELs  It matches regular expression       0 9      a z  a z          A Za z         Like CIGAR    cs   consists of series of operations  Each leading character specifies the operation  the following sequence is the one involved in the operation   The   cs   tag is enabled by command line option     cs    The following alignment  for example      code        CGATCGATAAATAGAGTAG   GAATAGCA                                        CGATCG   AATAGAGTAGGTCGAATtGCA  is represented as    6 ata 10 gtc 4 at 3    where     0 9     represents an identical block     ata   represents a deltion     gtc   an insertion and    at   indicates reference base   a   is substituted with a query base   t    It is similar to the   MD   SAM tag but is standalone and easier to parse   If     cs long   is used  the   cs   string also contains identical sequences in the alignment  The above example will become    CGATCG ata AATAGAGTAG gtc GAAT at GCA    The long form of   cs   encodes both reference and query sequences in one string   Algorithm overview                     In the following  minimap2 command line options have a dash ahead and are highlighted in bold  The description may help to tune minimap2 parameters   1  Read    I      4G   reference bases  extract        k        w    minimizers and index them in a hash table   2  Read    K      200M   query bases  For each query sequence  do step 3    through 7   3  For each     k        w    minimizer on the query  check against the    reference index  If a reference minimizer is not among the top    f         2e 4   most frequent  collect its the occurrences in the    reference  which are called  seeds    4  Sort seeds by position in the reference  Chain them with dynamic    programming  Each chain represents a potential mapping  For read    overlapping  report all chains and then go to step 8  For reference    mapping  do step 5 through 7   5  Let  P  be the set of primary mappings  which is an empty set    initially  For each chain from the best to the worst according to    their chaining scores  if on the query  the chain overlaps with a    chain in  P  by    mask level      0 5   or higher fraction of the    shorter chain  mark the chain as  secondary  to the chain in  P      otherwise  add the chain to  P    6  Retain all primary mappings  Also retain up to    N      5   top    secondary mappings if their chaining scores are higher than    p         0 8   of their corresponding primary mappings   7  If alignment is requested  filter out an internal seed if it    potentially leads to both a long insertion and a long deletion     Extend from the left most seed  Perform global alignments between    internal seeds  Split the chain if the accumulative score along the    global alignment drops by    z      400    disregarding long gaps     Extend from the right most seed  Output chains and their alignments   8  If there are more query sequences in the input  go to step 2 until no    more queries are left   9  If there are more reference sequences  reopen the query file from the    start and go to step 1  otherwise stop   Limitations                 Minimap2 may produce suboptimal alignments through long    low complexity regions where seed positions may be suboptimal  This    should not be a big concern because even the optimal alignment may be    wrong in such regions      ,minimap2,"fasta,fastqsanger,fastqsanger.gz,fasta",Map with minimap2,bam
393,,,Given a genome file in FASTA or Genbank format  MLST will scan the file against PubMLST typing schemes ,mlst,"fasta,genbank",MLST,tabular
394,,,MLST List will list all the scheme names used by MLST  Selecting the long list option will also provide the alleles for all MLST schemes ,mlst_list,,MLST List,txt
395,Calculate the number of potentially misaligned bases,,    MOTHUR OVERVIEW     Command Documentation    The align check  command allows you to calculate the number of potentially misaligned bases in a 16S rRNA gene sequence alignment using a secondary structure map    If you are familiar with the editor window in ARB  this is the same as counting the number of          and   signs       secondary structure map       align check        ,mothur_align_check,"mothur.align,mothur.map,mothur.count_table,mothur.names",Align.check,mothur.align.check
396,Align sequences to a template alignment,,    MOTHUR OVERVIEW     Command Documentation    The align seqs  command aligns a user supplied fasta formatted candidate sequence file to a user supplied fasta formatted template alignment    The general approach is to  i  find the closest template for each candidate using kmer searching  blastn  or suffix tree searching   ii  to make a pairwise alignment between the candidate and de gapped template sequences using the Needleman Wunsch  Gotoh  or blastn algorithms  and  iii  to re insert gaps to the candidate and template pairwise alignments using the NAST algorithm so that the candidate sequence alignment is compatible with the original template alignment   In general the alignment is very fast   we are able to align over 186 000 full length sequences to the SILVA alignment in less than 3 hrs with a quality as good as the SINA aligner  Furthermore  this rate can be accelerated using multiple processors  While the aligner doesn t explicitly take into account the secondary structure of the 16S rRNA gene  if the template database is based on the secondary structure  then the resulting alignment will at least be implicitly based on the secondary structure       template alignment       align seqs         ,mothur_align_seqs,fasta,Align.seqs,"mothur.align,mothur.align.report,mothur.accnos"
397,Analysis of molecular variance,,    MOTHUR OVERVIEW     Command Documentation    The amova  command calculates the analysis of molecular variance from a phylip distance matrix   a nonparametric analog of traditional analysis of variance  This method is widely used in population genetics to test the hypothesis that genetic diversity within two populations is not significantly different from that which would result from pooling the two populations   A design file partitions a list of names into groups   It is a tab delimited file with 2 columns  name and group  e g                      duck bird  cow mammal  pig mammal  goose bird  cobra reptile                   The Make Design tool can construct a design file from a Mothur dataset that contains group names        phylip distance matrix       amova         ,mothur_amova,"mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.design",Amova,tabular
398,Non-parametric multivariate analysis of changes in community structure,,    MOTHUR OVERVIEW     Command Documentation    The anosim  command uses a phylip distance matrix  and a design file to calculate the non parametric multivariate analysis of changes in community structure   A design file partitions a list of names into groups   It is a tab delimited file with 2 columns  name and group  e g                                    duck    bird         cow     mammal         pig     mammal         goose   bird         cobra   reptile                          The Make Design tool can construct a design file from a Mothur dataset that contains group names        phylip distance matrix       anosim         ,mothur_anosim,"mothur.dist,mothur.lower.dist,mothur.square.dist,tabular",Anosim,tabular
399,Order Sequences by OTU,,    MOTHUR OVERVIEW     Command Documentation    The bin seqs  command generates fasta formatted files where sequences are ordered according to the OTU from the list file  that they belong to  Such an output may be helpful for generating primers specific to an OTU or for classification of sequences       list file       bin seqs        ,mothur_bin_seqs,"fasta,mothur.list,mothur.names,mothur.groups,mothur.count_table",Bin.seqs,
400,Find putative chimeras using bellerophon,,    MOTHUR OVERVIEW     Command Documentation    The chimera bellerophon  command identifies putative chimeras using the bellerophon  approach   Advantages of Bellerophon    1  You can process all sequences from a PCR clone library in a single analysis and don t have to inspect outputs for every sequence in the dataset   2  The approximate putative breakpoint is calculated using a sliding window  see above  and will help verification of the chimera manually   3  A chimeric sequence is not only tested against two  putative  parent sequences but rather is assessed by how well it fits into the complete phylogenetic environment of a multiple sequence alignment  Hence sequences do not become invisible to the program as is the case with CHIMERA CHECK  see Ref 1 below    4  The calculations Bellerophon uses to detect chimeric sequences are computationally relatively cheap and results are quickly calculated for datasets with up 50 sequences   1 min   Larger datasets take longer   100 sequences  30 min  300 sequences  8 hours   Tips for using Bellerophon    1  Bellerophon works most efficiently if the parent sequences or non chimeric sequences closely related to the parent sequences are present in the dataset analyzed  Therefore  as many sequences as possible from the one PCR clone library should be included in the analysis since the parent sequences of any chimera are most likely to be in that dataset  Addition of non chimeric outgroup sequences  e g  from isolates  may help refine an analysis by providing reference points  and a broader phylogenetic context  in the analysis  but be aware of increasing analysis time with bigger datasets   2  Bellerophon is compromised by using sequences of different lengths as this can produce artificial skews in distance matrices of fragments of the alignment  Datasets containing sequences of the same length and covering the same portion of the gene should be used  usually not an issue with sequences from a PCR clone library   The filter will automatically remove sequences too short for the window size  i e  less than 600 bp for a window size of 300   3  If possible multiple window sizes should be used as the number of identified chimeras can vary with the choice of the window size   4  Re running the dataset without the first reported chimeras may identify additional putative chimeras by reducing noise in the analysis  Ideally  the dataset should continue to be re run removing previously reported chimeras until no chimeras are identified   5  Bellerophon should be used in concert with other detection methods such as CHIMERA CHECK and putatively identified chimeras should always be confirmed by manual inspection of the sequences for signature shifts        bellerophon       chimera bellerophon         ,mothur_chimera_bellerophon,fasta,Chimera.bellerophon,"txt,mothur.accnos"
401,Find putative chimeras using ccode,,    MOTHUR OVERVIEW     Command Documentation    The chimera ccode  command identifies putative chimeras using the ccode approach  Chimera and Cross Over Detection and Evaluation    Ccode  compares differences in distances  for each word  between query sequence and reference sequences  and reference sequences and themselves   This method was written using the algorithms described in the paper   Evaluating putative chimeric sequences from PCR amplified products  by Juan M  Gonzalez  Johannes Zimmerman and Cesareo Saiz Jimenez   The program can analyze sequences for any required word length  Generally  values of 5 20  of sequence length appear to deliver accurate results  for example  working on 16S rDNA sequences with a full length of  1500 nt  It should be noted that the use of fragments either too long or too short might result in a reduction of sensitivity       Ccode       paper       chimera ccode         ,mothur_chimera_ccode,"mothur.align,fasta,mothur.filter",Chimera.ccode,"txt,mothur.accnos,tabular"
402,Find putative chimeras using chimeraCheck,,    MOTHUR OVERVIEW     Command Documentation    The chimera check  command identifies putative chimeras using the chimeraCheck approach  It looks at distance of left side of query to it s closest match   distance of right side of query to it s closest match   distance of whole query and its closest match over several windows   Note  following the RDP model this method does not determine whether or not a sequence is chimeric  but allows you to determine that based on the IS values produced       chimera check         ,mothur_chimera_check,"mothur.align,fasta,mothur.names",Chimera.check,txt
403,Find putative chimeras using chimeraCheck,,    MOTHUR OVERVIEW     Command Documentation    The chimera perseus  command reads a fasta and name file  and outputs potentially chimeric sequences       chimera perseus         ,mothur_chimera_perseus,"mothur.align,mothur.names,mothur.count_table,mothur.groups",Chimera.perseus,"tabular,mothur.accnos"
404,Find putative chimeras using pintail,,    MOTHUR OVERVIEW     Command Documentation    The chimera pintail  command identifies putative chimeras using the pintail approach   It looks at the variation between the expected differences and the observed differences in the query sequence over several windows   This method was written using the algorithms described in the paper   At Least 1 in 20 16S rRNA Sequence Records Currently Held in the Public Repositories is Estimated To Contain Substantial Anomalies  by Kevin E  Ashelford 1  Nadia A  Chuzhanova 3  John C  Fry 1  Antonia J  Jones 2 and Andrew J  Weightman 1   The Pintail algorithm is a technique for determining whether a 16S rDNA sequence is anomalous   It is based on the idea that the extent of local base differences between two aligned 16S rDNA sequences should be roughly the same along the length of the alignment  having allowed for the underlying pattern of hypervariable and conserved regions known to exist within the 16S rRNA gene    In other words  evolutionary distance between two reliable sequences should be constant along the length of the gene   In contrast  if an error free sequence is compared with an anomalous sequence  evolutionary distance along the alignment is unlikely to be constant  especially if the anomaly in question is a chimera and formed from phylogenetically different parental sequences   The Pintail algorithm is designed to detect and quantify such local variations and in doing so generates the Deviation from Expectation  DE  statistic   The higher the DE value  the greater the likelihood that the query is anomalous   The algorithm works as follows  The sequence to be checked  the query  is first globally aligned with a phylogenetically similar sequence known to be error free  the subject    At regular intervals along the resulting alignment  the local evolutionary distance between query and subject is estimated by recording percentage base mismatches within a sampling window of fixed length   The resulting array of percentages  observed percentage differences  reflects variations in evolutionary distance between the query and subject along the length of the 16S rRNA gene   Subtracting observed percentage differences from an equivalent array of expected percentage differences  predicted values for error free sequences   we obtain a set of deviations  the standard deviation of which  Deviation from Expectation  DE  summarises the variation between observed and expected datasets   The greater the DE value  the greater the disparity there is between observed and expected percentage differences  and the more likely it is that the query sequence is anomalous        paper       chimera pintail         ,mothur_chimera_pintail,"fasta,mothur.filter,mothur.freq,mothur.quan",Chimera.pintail,"txt,mothur.accnos,mothur.freq,mothur.quan"
405,Find putative chimeras using slayer,,    MOTHUR OVERVIEW     Command Documentation    The chimera slayer  command identifies putative chimeras using the slayer approach   ChimeraSlayer  is a chimeric sequence detection utility  compatible with near full length Sanger sequences and shorter 454 FLX sequences   500 bp    Chimera Slayer involves the following series of steps that operate to flag chimeric 16S rRNA sequences        A  the ends of a query sequence are searched against an included database of reference chimera free 16S sequences to identify potential parents of a chimera       B  candidate parents of a chimera are selected as those that form a branched best scoring alignment to the NAST formatted query sequence       C  the NAST alignment of the query sequence is improved in a  chimera aware  profile based NAST realignment to the selected reference parent sequences  and      D  an evolutionary framework is used to flag query sequences found to exhibit greater sequence homology to an in silico chimera formed between any two of the selected reference parent sequences   Note  It is not recommended to blindly discard all sequences flagged as chimeras  Some may represent naturally formed chimeras that do not represent PCR artifacts  Sequences flagged may warrant further investigation        ChimeraSlayer       chimera slayer         ,mothur_chimera_slayer,"fasta,mothur.count_table,mothur.names,mothur.groups",Chimera.slayer,"txt,mothur.accnos"
406,Find putative chimeras using uchime,,    MOTHUR OVERVIEW     Command Documentation    The chimera uchime  command reads a fasta file and reference file and outputs potentially chimeric sequences  The original uchime program was written by Robert C  Edgar and donated to the public domain        chimera uchime    Version 1 23 0  Upgrades tool dependency to mothur 1 33 and adds support for count  mothur 1 28  and dereplicate  mothur 1 29  options       ,mothur_chimera_uchime,"mothur.align,fasta,fasta,mothur.groups,mothur.count_table,mothur.names",Chimera.uchime,"txt,mothur.accnos,mothur.count_table"
407,Trim sequences to a specified length,,    MOTHUR OVERVIEW     Command Documentation    The chop seqs  command reads a fasta file of sequences and outputs a  chop fasta file containing the trimmed sequences  It works on both aligned and unaligned sequences       chop seqs    v1 20 0  Updated to 1 33  Added name  group and count options for mothur version 1 31 0      ,mothur_chop_seqs,"fasta,mothur.align,mothur.names,mothur.groups,mothur.count_table",Chop.seqs,
408,Assign sequences to taxonomy,,    MOTHUR OVERVIEW     Command Documentation    The classify otu  command assigns sequences to chosen taxonomy outline   The basis parameter allows you indicate what you want the summary file to represent  options are otu and sequence  Default is otu  For example consider the following basis sequence could give Clostridiales 3 105 16 43 46  where 105 is the total number of sequences whose otu classified to Clostridiales  16 is the number of sequences in the otus from groupA  43 is the number of sequences in the otus from groupB  and 46 is the number of sequences in the otus from groupC  Now for basis otu could give Clostridiales 3 7 6 1 2  where 7 is the number of otus that classified to Clostridiales  6 is the number of otus containing sequences from groupA  1 is the number of otus containing sequences from groupB  and 2 is the number of otus containing sequences from groupC       classify otu    v1 21 0  Updated to use Mothur 1 33  Added count parameter  1 28 0  and persample parameter  1 29 0       ,mothur_classify_otu,"mothur.list,mothur.names,mothur.count_table,mothur.seq.taxonomy,tabular,mothur.groups",Classify.otu,
409,description,,  MOTHUR OVERVIEW      Command Documentation         classify rf       ,mothur_classify_rf,"mothur.shared,mothur.design",Classify.rf,tabular
410,Assign sequences to taxonomy,,    MOTHUR OVERVIEW     Command Documentation    The classify seqs  command assigns sequences to chosen taxonomy outline       classify seqs     v1 22 0  Updated for Mothur 1 33  Added count parameter  1 28   added relabund parameter  1 33   bayesian term changed to wang       ,mothur_classify_seqs,"fasta,mothur.seq.taxonomy,mothur.count_table,mothur.names",Classify.seqs,"mothur.seq.taxonomy,mothur.tax.summary,tabular"
411,Get a consensus taxonomy for each node on a tree,,    MOTHUR OVERVIEW      Command Documentation    The classify tree  command is used to get a consensus taxonomy for each node on a tree  Input is a taxonomy  and a tree  with optional name  or group  reference  The output is a tree  and a summary      TreeNode  NumRep  Taxonomy   243   2   Bacteria 100   Firmicutes  100   Clostridia  100  Clostridiales 100   Ruminococcaceae  100  Faecalibacterium 100     244   3   Bacteria 100   Firmicutes  100   Clostridia  100  Clostridiales 100   Ruminococcaceae  100  Faecalibacterium 100     245   4   Bacteria 100   Firmicutes  100   Clostridia  100  Clostridiales 100   Ruminococcaceae  100  Faecalibacterium 100               taxonomy       tree       name       group       classify tree    v 1 25 0  Trivial upgrade to Mothur 1 33      ,mothur_classify_tree,"mothur.ref.taxonomy,txt,mothur.names,mothur.groups",Classify.tree,"txt,tabular"
412,Generate a tree using relaxed neighbor joining,,    MOTHUR OVERVIEW     Command Documentation    The clearcut  command runs clearcut  The clearcut command allows mothur users to run the clearcut program  from within mothur  The clearcut program written by Initiative for Bioinformatics and Evolutionary Studies  IBEST  at the University of Idaho  For more information about clearcut please refer to   Clearcut is a stand alone reference implementation of relaxed neighbor joining  RNJ    Clearcut is capable of taking either a distance matrix or a multiple sequence alignment  MSA  as input   If necessary  Clearcut will compute corrected distances based on a configurable distance correction model  Jukes Cantor or Kimura    Clearcut outputs a phylogenetic tree in Newick format and an optional corrected distance matrix       clearcut program       clearcut    v 1 20 0  Trivial upgrade to Mothur 1 33      ,mothur_clearcut,"mothur.align,mothur.dist,mothur.lower.dist,mothur.square.dist",Clearcut,"mothur.tre,mothur.lower.dist"
413,Assign sequences to OTUs (Dotur implementation),,    MOTHUR OVERVIEW     Command Documentation    The cluster classic  command assign sequences to OTUs  Operational Taxonomy Unit        cluster classic         ,mothur_cluster_classic,"mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.names,mothur.count_table",Cluster.classic,"mothur.rabund,mothur.sabund,mothur.list"
414, Group sequences that are part of a larger sequence,,    MOTHUR OVERVIEW     Command Documentation    The cluster fragments  command groups sequences that are part of a larger sequence       cluster fragments    v1 21  Updated to Mothur 1 33  Added count parameter        ,mothur_cluster_fragments,"fasta,mothur.names,mothur.count_table",Cluster.fragments,mothur.names
415,Assign sequences to OTUs (Operational Taxonomic Unit) splits large matrices,,    MOTHUR OVERVIEW      Command Documentation    The cluster split  command assign sequences to OTUs  Operational Taxonomy Unit        cluster split    v1 28 0  Upgraded to Mothur 1 33  introduced cluster boolean        ,mothur_cluster_split,"mothur.pair.dist,mothur.names,mothur.count_table,mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.seq.taxonomy,mothur.align,fasta",Cluster.split,"mothur.rabund,mothur.sabund,mothur.list,txt"
416,Assign sequences to OTUs (Operational Taxonomic Unit),,    MOTHUR OVERVIEW     Command Documentation    The cluster  command assign sequences to OTUs  Operational Taxonomy Unit    The assignment is based on a phylip formatted distance matrix  or a  column formatted distance matrix  and name  file   It generates a list   a sabund   Species Abundance   and a rabund   Relative Abundance  file       phylip formatted distance matrix       column formatted distance matrix       name       list       rabund       sabund       cluster         ,mothur_cluster,"mothur.pair.dist,mothur.names,mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.count_table",Cluster,"mothur.rabund,mothur.sabund,mothur.list"
417,Generate collector's curves for calculators on OTUs,,    MOTHUR OVERVIEW     Command Documentation    The collect shared  command generates collector s curves for calculators   which describe the similarity between communities or their shared richness  Collector s curves describe how richness or diversity change as you sample additional individuals  If a collector s curve becomes parallel to the x axis  you can be reasonably confident that you have done a good job of sampling and can trust the last value in the curve   For calc parameter choices see        calculators       collect shared        ,mothur_collect_shared,mothur.shared,Collect.shared,
418,Generate collector's curves for OTUs,,    MOTHUR OVERVIEW      Command Documentation    The collect single  command generates collector s curves using calculators   that describe the richness  diversity  and other features of individual samples  Collector s curves describe how richness or diversity change as you sample additional individuals  If a collector s curve becomes parallel to the x axis  you can be reasonably confident that you have done a good job of sampling and can trust the last value in the curve  Otherwise  you need to keep sampling   For calc parameter choices see        calculators       collect single        ,mothur_collect_single,"mothur.list,mothur.rabund,mothur.sabund,mothur.shared",Collect.single,
419,Find a consensus sequence for each OTU or phylotype,,    MOTHUR OVERVIEW     Command Documentation    The consensus seqs  command can be used in 2 ways  create a consensus sequence from a fastafile  or with a listfile create a consensus sequence for each otu  Sequences must be aligned       consensus seqs        ,mothur_consensus_seqs,"mothur.align,mothur.names,mothur.list,mothur.count_table",Consensus.seqs,"tabular,mothur.align"
420,tests whether presence-absence patterns differ from chance,,    MOTHUR OVERVIEW     Command Documentation    The cooccurrence  command variance calculates four metrics and tests their significance to assess whether presence absence patterns are different than what one would expect by chance    The input is a shared  file   The output can be filtered by groups and labels       metric    The metric parameter options are   cscore      checker      combo   and   vratio    Default cscore  The cscore or checkerboard score  1  is a metric that measures species segregation  It is the mean number of checkerboard units per species pair  The checker metric  2  counts the number of species pairs forming a perfect checkerboard  The combo metric  3  is the number of unique species pairs  The vratio or variance ratio  4  is a measure of the species association calculated by the ratio of the variance in total species number to the sum of the variances of the species         1  Stone  L   and A  Roberts  1990  The checkerboard score and species distributions  Ocelogia  85 74 79    2  Diamond  J  M  1975  Assembly of species communities  Pages 342 444 in M  L  Cody and J  M  Diamond  editors  Ecology and evolution of communities  Harvard University Press  Cambridge  Massachusetts  USA    3  Pielou  D  P   and E  C  Pielou  1968 Association among species of infrequent occurrence  the insect and spider fauna of Polypours betulinus  Bulliard  Fries  Journal of Theoretical Biology 21 202 216    4  Schluter  D  1984  A variance test for detecting species associations  with some example applications  Ecology 65 998 1005    5  Gotelli  Nicholas J  2000  NULL MODEL ANALYSIS OF SPECIES CO OCCURRENCE PATTERNS  Ecology 81 2606 2621       matrixmodel    The matrixmodel parameter allows you to select the model you would like to use  Options are sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8 and sim9  Default sim2   Each sim implements a different algorithm for generating null matrices with constraints on the rows  species  and columns  sites                                                                                                    Rows                  Columns equiprobable   Columns proportional    Column totals fixed                                                                                                Rows equiprobable     sim1                   sim6                    sim3   Rows proportional     sim7                   sim8                    sim5   Row totals fixed      sim2                   sim4                    sim9                                                                                               Equiprobable rows or columns means that each row  column or both is not dependent on the original co occurrence matrix  Each species or site has an equal change of occurring in the null matrix  Proportional rows or columns means that the proportion of occurrences in rows  columns or both in the original co occurrence matrix are preserved but the totals may differ  Each species or site s chances of occurring are proportional to their occurrence in the original co occurrence matrix  Fixed row or column totals preserves the total number of occurrences in rows  columns or both in the original co occurrence matrix  Sim9 is a special case that is not probabilistic  Since both the row and column totals are preserved the only way to randomize the matrix is with a checkerboard swap  When a checkerboard appears in the matrix the 1s and 0s are swapped to their mirror image to preserve the species and site totals   Checkerboard      10   01  Swap      01   10   suggested metric matrixmodel combinations                                                  cscore    checker   combo    vratio                                                sim9      sim9      sim9     sim2      sim2      sim2      sim2     sim4                          sim4     sim8                          sim8                                                   Careful readers will note that none of the suggested matrixmodels have equiprobable rows  species   This is because tests of co occurrence are quite sensitive to the frequency of species occurrence  As such  rowtotals should be maintained or at least kept proportional in the null models  Sim9 is well suited to co occurrence matrices that have an  island list  structure  Island lists are often found in classical ecology datasets that contain species with well defined habitat patches and are rarely degenerate  matrices that contain empty rows or columns   Sim2 is well suited for co occurrence matrices that have a  sample list  structure  Sample list structured data are found where species have relatively homogeneous habitats and degenerate matrices are not uncommon  In these matrices species will often occur in only one site  The default values of cscore and sim2 have been selected because the c score is not very sensitive to noise in the data and when used with sim9 or sim2 is not particularly prone to false positives  Sim2 has been chosen because of the prevalence of degenerate matrices  These are just guidelines  however  be sure to select a metric and matrix model that is best suited to the type of data you are analyzing  It should be noted that sim9 cannot be used with vratio because in sim9 both the column and row totals are maintained  hence there will be no variance  Please see  5  for more details on metric null model selection        shared       cooccurrence    v1 26 0  Updated to Mothur 1 33      ,mothur_cooccurrence,mothur.shared,Cooccurrence,tabular
421,correlation of data to axes,,    MOTHUR OVERVIEW     Command Documentation    The corr axes  command calculates the correlation of data to axes       corr axes    v 1 21 0  Updated to mothur 1 33       ,mothur_corr_axes,"mothur.axes,mothur.shared,mothur.relabund,tabular",Corr.axes,mothur.axes
422,counts the number of sequences represented by a specific group or set of groups,,    MOTHUR OVERVIEW     Command Documentation    The count groups  command counts sequences from a specific group or set of groups from a group  or shared  file       shared       group       count groups        ,mothur_count_groups,"mothur.groups,mothur.shared,mothur.count_table,mothur.accnos",Count.groups,tabular
423,(aka make.table) counts the number of sequences represented by the representative,,    MOTHUR OVERVIEW     Command Documentation    The count seqs  command counts the number of sequences represented by the representative sequence in a name  file and generates a count table   If a group  file is given  it will also provide the group count breakdown       name       group       count seqs       count table    v 1 21 0  Updated to Mothur 1 33      ,mothur_count_seqs,"mothur.names,mothur.groups",Count.seqs,mothur.count_table
424,"creates a database file from a list, repnames, repfasta and contaxonomy file",,    MOTHUR OVERVIEW     Command Documentation    The create database  command reads a list  or shared  file   cons taxonomy   rep fasta   rep names and optional group file  and creates a database file       list       shared       create database    v 1 28 0  Updated to Mothur 1 33  added count paramter        ,mothur_create_database,"mothur.list,mothur.shared,fasta,mothur.names,mothur.count_table,mothur.cons.taxonomy,mothur.groups",Create.database,tabular
425,Remove gap characters from sequences,,    MOTHUR OVERVIEW     Command Documentation    The degap seqs  command reads a fasta file and outputs a fasta containing the sequences after all gap characters are removed       degap seqs    v1 21 0  Updated to Mothur 1 33       ,mothur_degap_seqs,fasta,Degap.seqs,
426,Return all sequences,,    MOTHUR OVERVIEW     Command Documentation    The deunique seqs  command is the reverse of the unique seqs command  and creates a fasta file from a fasta and name  file       name       deunique seqs    v 1 21 0  Updated to Mothur 1 33  added option to provide count instead of names file  new groups file as output       ,mothur_deunique_seqs,"fasta,mothur.names,mothur.count_table",Deunique.seqs,mothur.groups
427,Reinsert the redundant sequence identiers back into a unique tree.,,    MOTHUR OVERVIEW      Command Documentation    The deunique tree  command is the reinserts the redundant sequence identiers back into a unique tree using a name  file       name       deunique tree    v1 21 0  Updated to Mothur 1 33       ,mothur_deunique_tree,"mothur.tre,mothur.names",Deunique.tree,
428,calculate uncorrected pairwise distances between aligned sequences,,    MOTHUR OVERVIEW     Command Documentation    The dist seqs  command will calculate uncorrected pairwise distances between aligned sequences   The command will generate a column formatted distance matrix  that is compatible with the column option in the read dist command  The command is also able to generate a phylip formatted distance matrix   There are several options for how to handle gap comparisons and terminal gaps       column formatted distance matrix       phylip formatted distance matrix       dist seqs    v 1 20 0  Updated to Mothur 1 33       ,mothur_dist_seqs,"mothur.align,fasta",Dist.seqs,mothur.pair.dist
429,Generate a phylip-formatted dissimilarity distance matrix among multiple groups,,    MOTHUR OVERVIEW     Command Documentation    The dist shared  command will generate a phylip formatted distance matrix  that describes the dissimilarity  1 similarity  among multiple groups from a shared  file  For calc parameter choices see        phylip formatted distance matrix       shared       dist shared    v1 26 0  Updated to Mothur 1 33  Omitted calculators since they do not appear to be available        ,mothur_dist_shared,mothur.shared,Dist.shared,
430,Convert fastq to fasta and quality,,    MOTHUR OVERVIEW     Command Documentation    The fastq info  command reads a fastq file and creates a fasta and quality file        fastq info        ,mothur_fastq_info,"fastq,mothur.oligos",Fastq.info,"fasta,qual454,fastq"
431,removes columns from alignments,,    MOTHUR OVERVIEW     Command Documentation    The filter seqs  command removes columns from alignments based on a criteria defined by the user  For example  alignments generated against reference alignments  e g  from RDP  SILVA  or greengenes  often have columns where every character is either a     or a      These columns are not included in calculating distances because they have no information in them  By removing these columns  the calculation of a large number of distances is accelerated  Also  people also like to mask their sequences to remove variable regions using a soft or hard mask  e g  Lane s mask   This type of masking is only encouraged for deep level phylogenetic analysis  not fine level analysis such as that needed with calculating OTUs       filter seqs    v 1 20 0  Updated to Mothur 1 33       ,mothur_filter_seqs,"mothur.align,mothur.filter",Filter.seqs,"mothur.filter,fasta"
432,remove OTUs based on various critieria,,    MOTHUR OVERVIEW     Command Documentation    The filter shared  is used to remove OTUs based on various critieria       filter shared         ,mothur_filter_shared,mothur.shared,Filter.shared,
433,description,,  MOTHUR OVERVIEW      Command Documentation         get communitytype       ,mothur_get_communitytype,mothur.shared,Get.communitytype,tabular
434,fraction of OTUs for samples or abundances,,    MOTHUR OVERVIEW     Command Documentation    The get coremicrobiome  command determines the fraction of OTUs that are found in varying numbers of samples for different minimum relative abundances       get coremicrobiome    v1 27 0  Updated to Mothur 1 33       ,mothur_get_coremicrobiome,"mothur.shared,mothur.relabund",Get.coremicrobiome,
435,selects distances from a phylip or column file,,    MOTHUR OVERVIEW     Command Documentation    The get dists  command selects distances from a phylip or column file related to groups or sequences listed in an accnos file       get dists    v 1 20 0  Updated to Mothur 1 33      ,mothur_get_dists,"mothur.pair.dist,mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.accnos",Get.dists,
436,group names from shared or from list and group,,    MOTHUR OVERVIEW     Command Documentation    The get group  command generate principle components plot data       get group    v 1 20 0  Updated to Mothur 1 33      ,mothur_get_group,mothur.shared,Get.group,mothur.groups
437,Select groups,,    MOTHUR OVERVIEW      Command Documentation    The get groups  command selects sequences from a specific group or set of groups from the following file types  fasta  fasta  name   group   list   taxonomy        name       group       list       taxonomy       get groups         ,mothur_get_groups,"mothur.groups,mothur.count_table,mothur.accnos,fasta,mothur.align,mothur.names,mothur.list,mothur.shared,mothur.seq.taxonomy,tabular",Get.groups,"mothur.groups,mothur.count_table,mothur.names,mothur.seq.taxonomy,mothur.design"
438,"label names from list, sabund, or rabund file",,    MOTHUR OVERVIEW     Command Documentation    The get label  command generate principle components plot data       get label    v 1 20 0  Updated to Mothur 1 33      ,mothur_get_label,"mothur.list,mothur.sabund,mothur.rabund",Get.label,tabular
439,Picks by taxon,,    MOTHUR OVERVIEW     Command Documentation    The get lineage  command reads a taxonomy  file and a taxon and generates a new file that contains only the sequences in the that are from that taxon  You may also include either a fasta  name   group   list   or align report  file to this command and mothur will generate new files for each of those containing only the selected sequences       taxonomy       name       group       list       align report       get lineage         ,mothur_get_lineage,"mothur.seq.taxonomy,mothur.cons.taxonomy,mothur.shared,mothur.list,fasta,mothur.groups,mothur.align.report,mothur.names,mothur.count_table",Get.lineage,"mothur.seq.taxonomy,mothur.groups,mothur.names,mothur.align.report"
440,creates a mimarks package form with your groups,,    MOTHUR OVERVIEW     Command Documentation    The get mimarkspackage  command creates a mimarks package form with your groups       get mimarkspackage         ,mothur_get_mimarkspackage,"mothur.groups,mothur.oligos",Get.mimarkspackage,tabular
441,Selects OTU labels,,    MOTHUR OVERVIEW      Command Documentation    The get otulabels  command selects otu labels from the output from classify otu   corr axes  and otu association   This can be useful especially with subsampled datasets or when groups have been selected       classify otu       corr axes       otu association    v 1 27 0  Added list and shared parameters  updated to Mothur 1 33      ,mothur_get_otulabels,"mothur.otulabels,mothur.list,mothur.shared,mothur.cons.taxonomy,mothur.otu.corr,mothur.axes",Get.otulabels,
442,Get otus for each distance in a otu list,,    MOTHUR OVERVIEW      Command Documentation    The get otulist  command parses a list file and creates an  otu file for each distance containing 2 columns  The first column is the OTU number the second column is a list of sequences in that OTU       get otulist    v 1 20 0  Updated to Mothur 1 33      ,mothur_get_otulist,mothur.list,Get.otulist,
443,Generate a fasta with a representative sequence for each OTU,,    MOTHUR OVERVIEW      Command Documentation    The get oturep  command generates a fasta formatted sequence file containing only a representative sequence for each OTU   The opposite of the bin seqs command       get oturep    v1 23 0  Updated to Mothur 1 33  added count and method parameter      ,mothur_get_oturep,"mothur.list,mothur.pair.dist,mothur.names,mothur.count_table,mothur.dist,mothur.lower.dist,mothur.square.dist,fasta,mothur.groups",Get.oturep,
444,Get otus containing sequences from specified groups,,    MOTHUR OVERVIEW     Command Documentation    The get otus  command selects otus from a list  containing sequences from a specific group or set of groups       list       get otus    v 1 20 0  Updated to Mothur 1 33      ,mothur_get_otus,"mothur.list,mothur.groups,mothur.accnos",Get.otus,"mothur.groups,mothur.list"
445,Get rabund from a otu list or sabund,,    MOTHUR OVERVIEW     Command Documentation    The get rabund  command generates an rabund  file from a list  or sabund  file       rabund       list       sabund       get rabund         ,mothur_get_rabund,"mothur.list,mothur.sabund,mothur.count_table",Get.rabund,mothur.rabund
446,Calculate the relative abundance of each otu,,    MOTHUR OVERVIEW     Command Documentation    The get relabund  command calculates the relative abundance of each otu in a sample from a shared  file  It outputs a  relabund  file       shared       get relabund    v 1 21 0  Updated to Mothur 1 33      ,mothur_get_relabund,mothur.shared,Get.relabund,mothur.relabund
447,Get sabund from a otu list or rabund,,            MOTHUR OVERVIEW      Command Documentation    The get sabund  command generates an sabund  file from a list  or rabund  file       sabund       list       rabund       get sabund         ,mothur_get_sabund,"mothur.list,mothur.rabund,mothur.count_table",Get.sabund,mothur.sabund
448,Picks sequences by name,,    MOTHUR OVERVIEW     Command Documentation    The get seqs  command takes a list of sequence names and either a fasta  name   group   list   align report  or taxonomy  file to generate a new file that contains only the sequences in the list  This command may be used in conjunction with the list seqs  command to help screen a sequence collection       name       group       list       align report       taxonomy       list seqs       get seqs    v 1 27 0   Updated to Mothur 1 33  added count and fastq params      ,mothur_get_seqs,"mothur.accnos,fasta,qual,fastq,mothur.count_table,mothur.names,mothur.groups,mothur.align.report,mothur.list,mothur.seq.taxonomy",Get.seqs,"mothur.names,mothur.groups,mothur.align.report,mothur.list,mothur.seq.taxonomy"
449,Get shared sequences at each distance from list and group,,    MOTHUR OVERVIEW     Command Documentation    The get sharedseqs  command takes a list and group file and outputs a  shared seqs file for each distance  This is useful for those cases where you might be interested in identifying sequences that are either unique or shared by specific groups  which you could then classify       get sharedseqs    v1 21 0  Updated to Mothur 1 33  added shared file option      ,mothur_get_sharedseqs,"mothur.shared,mothur.list,mothur.groups,fasta",Get.sharedseqs,
450,Assign sequences to OTUs (Operational Taxonomic Unit),,    MOTHUR OVERVIEW     Command Documentation    The hcluster  command assign sequences to OTUs  Operational Taxonomy Unit    The assignment is based on a phylip formatted distance matrix  or a  column formatted distance matrix  and name  file   It generates a list   a sabund   Species Abundance   and a rabund   Relative Abundance  file       phylip formatted distance matrix       column formatted distance matrix       name       list       rabund       sabund         ,mothur_hcluster,"mothur.pair.dist,mothur.names,mothur.dist,mothur.lower.dist,mothur.square.dist",Hcluster,"mothur.rabund,mothur.sabund,mothur.list"
451,Generate a heatmap for OTUs,,    MOTHUR OVERVIEW      Command Documentation    The heatmap bin  command generates a heat map from data provided in either a list  or a shared  file       list       shared       heatmap bin    v 1 21 0  Updated to Mothur 1 33      ,mothur_heatmap_bin,"mothur.list,mothur.rabund,mothur.sabund,mothur.shared,mothur.relabund",Heatmap.bin,
452,Generate a heatmap for pariwise similarity,,    MOTHUR OVERVIEW     Command Documentation    The heatmap sim  command generates a heat map from data provided in either a shared  file  a phylip  distance matrix  or a column  distance matrix and a name  file   For calc parameter choices see        shared       phylip       column       name       heatmap sim    v 1 24 0  Updated to Mothur 1 33  added count parameter      ,mothur_heatmap_sim,"mothur.shared,mothur.pair.dist,mothur.names,mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.count_table",Heatmap.sim,svg
453,Homogeneity of molecular variance,,    MOTHUR OVERVIEW     Command Documentation    The homova  command calculates the homogeneity of molecular variance  HOMOVA  from a phylip distance matrix   a nonparametric analog of Bartlett s test for homo  geneity of variance  which has been used in population genetics to test the hypothesis that the genetic diversity within two or more populations is homogeneous   A design file partitions a list of names into groups   It is a tab delimited file with 2 columns  name and group  e g                                    duck    bird         cow     mammal         pig     mammal         goose   bird         cobra   reptile                          The Make Design tool can construct a design file from a Mothur dataset that contains group names       phylip distance matrix       homova    v 1 20 0  Updated to Mothur 1 33  added sets parameter      ,mothur_homova,"mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.design",Homova,tabular
454,"Identify indicator ""species"" for nodes on a tree",,    MOTHUR OVERVIEW     Command Documentation    The indicator  command reads a shared  or relabund  file and a tree file  and outputs a  indicator summary file and when a tree file is given a  indicator tre file  The summary file lists the indicator value for each OTU for each node   The new tree contains labels at each internal node  The label is the node number so you can relate the tree to the summary file       shared       relabund       indicator    v 1 22 0  Updated to Mothur 1 33      ,mothur_indicator,"mothur.shared,mothur.relabund,mothur.tre,mothur.design",Indicator,"mothur.tre,tabular"
455,description,,  MOTHUR OVERVIEW      Command Documentation         lefse       ,mothur_lefse,"mothur.shared,mothur.design",Lefse,tabular
456,Cramer-von Mises tests communities for the same structure,,    MOTHUR OVERVIEW      Command Documentation    The libshuff  method is a generic test that describes whether two or more communities have the same structure using the Cramer von Mises test statistic  The significance of the test statistic indicates the probability that the communities have the same structure by chance  Because each pairwise comparison requires two significance tests  a correction for multiple comparisons  e g  Bonferroni s correction  must be applied       libshuff         ,mothur_libshuff,"mothur.lower.dist,mothur.square.dist,mothur.groups",Libshuff,tabular
457,Lists otu labels from shared or relabund file,,    MOTHUR OVERVIEW     Command Documentation    The list otulabels  command lists otu labels from shared  or relabund  file  This list can be used especially with subsampled datasets when used with output from classify otu   otu association   or corr axes  to select specific otus using the get otulabels  or remove otulabels  commands       list otulabels       classify otu       otu association       corr axes       remove otulabels       shared       relabund    v 1 27 0  Updated to mothur 1 33  added list file for otu      ,mothur_list_otulabels,"mothur.shared,mothur.relabund,mothur.list",List.otulabels,
458,Lists the names (accnos) of the sequences,,    MOTHUR OVERVIEW     Command Documentation    The list seqs  command writes out the names of the sequences found within a fasta  name   group   list   align report  or taxonomy  file       name       group       list       align report       taxonomy       list seqs    v 1 20 0  Updated to mothur 1 33  added count and fastq option      ,mothur_list_seqs,"fasta,fastq,mothur.names,mothur.groups,mothur.align.report,mothur.list,mothur.seq.taxonomy,mothur.count_table",List.seqs,mothur.accnos
459,Make biom files from a shared file,,    MOTHUR OVERVIEW     Command Documentation    The make biom command converts a shared  shared file to biom  files  The output can be filtered by groups and labels        shared       biom        make biom        ,mothur_make_biom,"mothur.shared,mothur.cons.taxonomy,tabular,mothur.ref.taxonomy",Make.biom,
460,Aligns paired forward and reverse fastq files to contigs as fasta and quality,,    MOTHUR OVERVIEW     Command Documentation    The make contigs  command reads a forward fastq file and a reverse fastq file and outputs new fasta and quality files       make contigs    v 1 27 0  Updated to use Mothur 1 33  Added findex and rindex parmaeters  optionally used with the oligos file       ,mothur_make_contigs,"fastq,mothur.oligos",Make.contigs,"fasta,qual,txt,mothur.groups"
461,Assign groups to Sets,,    MOTHUR OVERVIEW     Command Documentation    Make Design creates a design file for use in mothur commands  merge groups   indicator   and metastats   A design file looks like the group file  It is a 2 column tab delimited file  where the first column is the group name and the second column is the set the group belongs to       merge groups       indicator       metastats        ,mothur_make_design,"mothur.shared,mothur.groups",Make Design,mothur.design
462,Convert fasta and quality to fastq,,            MOTHUR OVERVIEW     Command Documentation    The fastq info  command reads a fasta file and quality file and creates a fastq        fastq info        ,mothur_make_fastq,"fasta,qual454,qualillumina,qualsolid,qual",Make.fastq,fasta
463,Make a group file,,    MOTHUR OVERVIEW     Command Documentation    The make group  command reads a fasta file or series of fasta files and creates a group  file       group       make group         ,mothur_make_group,fasta,Make.group,mothur.groups
464,create a lefse formatted input file from mothur's output files,,    MOTHUR OVERVIEW     Command Documentation    The make lefse  allows you to create a lefse formatted input file from mothur s output files       make lefse         ,mothur_make_lefse,"mothur.shared,mothur.relabund,mothur.cons.taxonomy,tabular",Make.lefse,tabular
465,allows you to create custom lookup files for use with shhh.flows,,    MOTHUR OVERVIEW     Command Documentation    The make lookup  allows you to create custom lookup files for use with shhh flows       make lookup         ,mothur_make_lookup,"fasta,mothur.sff.flow,tabular",Make.lookup,txt
466,Make a shared file from a list and a group,,    MOTHUR OVERVIEW     Command Documentation    The make shared  command takes a list  and a group  file and outputs a shared  file  as well as a rabund  file for each group        list       group       shared       rabund       make shared        ,mothur_make_shared,"mothur.list,mothur.groups,mothur.count_table,biom1",Make.shared,"mothur.shared,mothur.groups"
467,creates the necessary files for a NCBI submission,,    MOTHUR OVERVIEW     Command Documentation    The make sra  creates the necessary files for a NCBI submission       make sra         ,mothur_make_sra,"tabular,sff,mothur.oligos,txt,fastq",Make.sra,"fasta,qual,mothur.sff.flow,sff,xml"
468,Mantel correlation coefficient between two matrices.,,    MOTHUR OVERVIEW     Command Documentation    The mantel  command calculates the Mantel correlation coefficient between two matrices        matrices    www mothur org wiki Phylip formatted distance matrix     mantel         ,mothur_mantel,"mothur.dist,mothur.lower.dist,mothur.square.dist",Mantel,tabular
469,Merge data,,  MOTHUR OVERVIEW     Command Documentation    The merge files  command merge inputs into a single output       merge files         ,mothur_merge_files,"fasta,qual,mothur.groups,mothur.names,mothur.accnos",Merge.files,
470,Merge groups in a shared file,,    MOTHUR OVERVIEW     Command Documentation    The merge groups  command reads a shared  file and a design file and merges the groups in the shared file that are in the same grouping in the design file   A design file partitions a list of names into groups   It is a tab delimited file with 2 columns  name and group  e g                                                                                    duck    bird                                 cow     mammal                                 pig     mammal                                 goose   bird                                 cobra   reptile                                                  The Make Design tool can construct a design file from a Mothur dataset that contains group names       shared       merge groups        ,mothur_merge_groups,"mothur.shared,mothur.groups,tabular",Merge.groups,"mothur.shared,mothur.groups"
471,Merge SFF files,,    MOTHUR OVERVIEW       Mothur      Command Documentation    The merge sfffiles  command merge inputs into a single output       merge sfffiles         ,mothur_merge_sfffiles,sff,Merge.sfffiles,sff
472,Merge tax.summary files,,    MOTHUR OVERVIEW       Mothur      Command Documentation    The merge taxsummary command takes a list of tax summary files separated by dashes and merges them into one file       merge taxsummary         ,mothur_merge_taxsummary,mothur.tax.summary,Merge.taxsummary,mothur.tax.summary
473,generate principle components plot data,,    MOTHUR OVERVIEW     Command Documentation    The metastats  command generate principle components plot data       metastats    v 1 21 0  Updated to mothur 1 33      ,mothur_metastats,"mothur.shared,mothur.design",Metastats,
474,Reads bioSample Attributes xml and generates source for get.mimarkspackage command,,    MOTHUR OVERVIEW     Command Documentation    The mimarks attributes  Reads bioSample Attributes xml and generates source for make sra command        ,mothur_mimarks_attributes,xml,Get.mimarkspackage,txt
475,generate non-metric multidimensional scaling data,,    MOTHUR OVERVIEW       Mothur      Command Documentation    The nmds  command generates non metric multidimensional scaling data from a phylip distance matrix        phylip distance matrix       nmds    v1 20 0  Updated to mothur 1 33      ,mothur_nmds,"mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.axes",Nmds,"mothur.axes,tabular"
476,Normalize the number of sequences per group to a specified level,,    MOTHUR OVERVIEW     Command Documentation    The normalize shared  command normalizes the number of sequences per group to a specified level   The input is a shared  or relabund  file       shared       relabund       normalize shared        ,mothur_normalize_shared,"mothur.shared,mothur.relabund",Normalize.shared,
477,Calculate the correlation coefficient for the otus,,    MOTHUR OVERVIEW     Command Documentation    The otu association  command calculates the correlation coefficient for the otus in a shared  or relabund  file       shared       relabund       otu association    v 1 25 0  Updated to mothur 1 33  added cutoff option      ,mothur_otu_association,"mothur.shared,mothur.relabund,tabular",Otu.association,
478,Relate OTUs at different distances,,    MOTHUR OVERVIEW     Command Documentation    The otu hierarchy  command relates OTUs from a list  at different distances       list       otu hierarchy         ,mothur_otu_hierarchy,mothur.list,Otu.hierarchy,tabular
479,calculate uncorrected pairwise distances between sequences,,    MOTHUR OVERVIEW       Mothur      Command Documentation    The pairwise seqs  command will calculate uncorrected pairwise distances between sequencesi as a column formatted distance matrix  or  phylip formatted distance matrix        column formatted distance matrix       phylip formatted distance matrix       pairwise seqs         ,mothur_pairwise_seqs,fasta,Pairwise.seqs,mothur.pair.dist
480,Generate a List file for each group,,    MOTHUR OVERVIEW     Command Documentation    The parse list  command reads a list  file and group  file and generates a list  file for each group  in the groupfile       list       group       parse list    v 1 19 0  Updated to mothur 1 33  added count parameter      ,mothur_parse_list,"mothur.list,mothur.groups,mothur.count_table",Parse.list,
481,Describes whether two or more communities have the same structure,,    MOTHUR OVERVIEW     Command Documentation    The parsimony  command implements the parsimony method  aka P test   which was previously implemented in TreeClimber and is also available in MacClade and on the UniFrac website  The parsimony method is a generic test that describes whether two or more communities have the same structure  The significance of the test statistic can only indicate the probability that the communities have the same structure by chance  The value does not indicate a level of similarity       parsimony    v 1 20 0  Added count parameter       ,mothur_parsimony,"mothur.tre,mothur.groups,mothur.names,mothur.count_table",Parsimony,tabular
482,Principal Coordinate Analysis for a shared file,,    MOTHUR OVERVIEW     Command Documentation    The pca  command generate principle components plot data for a shared  or relabund  file       shared       relabund       pca        ,mothur_pca,"mothur.shared,mothur.relabund",Pca,
483,Principal Coordinate Analysis for a distance matrix,,    MOTHUR OVERVIEW     Command Documentation    The pcoa  command performs principal coordinate analysis on a phylip formatted distance matrix        phylip formatted distance matrix       pcoa        ,mothur_pcoa,"mothur.dist,mothur.lower.dist,mothur.square.dist",Pcoa,"mothur.axes,tabular"
484,Trim sequences,,    MOTHUR OVERVIEW     Command Documentation    The pcr seqs  command assigns sequences to chosen taxonomy outline       pcr seqs         ,mothur_pcr_seqs,"mothur.align,fasta,mothur.oligos,mothur.align,mothur.seq.taxonomy,mothur.names,mothur.groups",Pcr.seqs,"mothur.seq.taxonomy,mothur.groups,mothur.names,mothur.accnos"
485,Alpha Diversity calculates unique branch length,,    MOTHUR OVERVIEW      Command Documentation    The phylo diversity  command calculates alpha diversity as the total of the unique branch length       phylo diversity    v 1 21 0  Updated to Mothur 1 33  added count parameter       ,mothur_phylo_diversity,"mothur.tre,mothur.groups,mothur.names,mothur.count_table",Phylo.diversity,tabular
486,Assign sequences to OTUs based on taxonomy,,    MOTHUR OVERVIEW     Command Documentation    The phylotype  command assign sequences to OTUs based on their taxonomy and outputs a a list   a sabund   Species Abundance   and a rabund   Relative Abundance  file       list       rabund       sabund       phylotype         ,mothur_phylotype,"mothur.seq.taxonomy,mothur.names",Phylotype,"mothur.rabund,mothur.sabund,mothur.list"
487,Remove sequences due to pyrosequencing errors,,    MOTHUR OVERVIEW     Command Documentation    The pre cluster  command implements a pseudo single linkage algorithm with the goal of removing sequences that are likely due to pyrosequencing errors  The basic idea is that abundant sequences are more likely to generate erroneous sequences than rare sequences  With that in mind  the algorithm proceeds by ranking sequences in order of their abundance  Then we walk through the list of sequences looking for rarer sequences that are within some threshold of the original sequence  Those that are within the threshold are merged with the larger sequence  The original Huse method performs this task on a distance matrix  whereas we do it based on the original sequences  The advantage of our approach is that the algorithm works on aligned sequences instead of a distance matrix  This is advantageous because by pre clustering you remove a large number of sequences making the distance calculation much faster       pre cluster    v1 24 0  Updated to mothur 1 33  added count and topdown parameter      ,mothur_pre_cluster,"fasta,mothur.names,mothur.count_table,mothur.groups",Pre.cluster,"mothur.names,mothur.count_table"
488,identify sequence fragments that are specific to particular OTUs,,    MOTHUR OVERVIEW     Command Documentation    The primer design  allows you to identify sequence fragments that are specific to particular OTUs       primer design         ,mothur_primer_design,"mothur.align,mothur.list,mothur.names,mothur.count_table",Primer.design,"mothur.align,tabular,mothur.list"
489,Generate inter-sample rarefaction curves for OTUs,,    MOTHUR OVERVIEW     Command Documentation    The rarefaction shared  command generates inter sample rarefaction curves using a re sampling without replacement approach  The traditional way that ecologists use rarefaction is not to randomize the sampling order within a sample  rather between samples  For instance  if we wanted to know the number of OTUs in the human colon  we might sample from various sites within the colon  and sequence a bunch of 16S rRNA genes  By determining the number of OTUs in each sample and comparing the composition of those samples it is possible to determine how well you have sampled the biodiversity within the individual   For calc parameter choices see        rarefaction shared        ,mothur_rarefaction_shared,"mothur.shared,mothur.design",Rarefaction.shared,tabular
490,Generate intra-sample rarefaction curves for OTUs,,    MOTHUR OVERVIEW     Command Documentation    The rarefaction single  command generates intra sample rarefaction curves using a re sampling without replacement approach  Rarefaction curves provide a way of comparing the richness observed in different samples   For calc parameter choices see        rarefaction single        ,mothur_rarefaction_single,"mothur.list,mothur.rabund,mothur.sabund,mothur.shared",Rarefaction.single,
491,Removes distances from a phylip or column file,,    MOTHUR OVERVIEW     Command Documentation    The remove dists  removes distances from a phylip or column file related to groups or sequences listed in an accnos file       remove dists         ,mothur_remove_dists,"mothur.pair.dist,mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.accnos",Remove.dists,
492,"Remove groups from groups,fasta,names,list,taxonomy",,   MOTHUR OVERVIEW     Command Documentation    The remove groups  command removes sequences from a specific group or set of groups from the following file types  fasta  name   group   list   taxonomy        name       group       list       taxonomy       remove groups         ,mothur_remove_groups,"mothur.groups,mothur.count_table,mothur.align,fasta,mothur.names,mothur.list,mothur.seq.taxonomy,mothur.shared",Remove.groups,"mothur.groups,mothur.count_table,mothur.names,mothur.seq.taxonomy"
493,Picks by taxon,,    MOTHUR OVERVIEW     Command Documentation    The remove lineage  command reads a taxonomy  file and a taxon and generates a new file that contains only the sequences in the that are not from that taxon  You may also include either a fasta  name   group   list   or align report  file to this command and mothur will generate new files for each of those containing only the selected sequences       taxonomy       name       group       list       align report       remove lineage         ,mothur_remove_lineage,"mothur.seq.taxonomy,mothur.cons.taxonomy,mothur.shared,mothur.list,fasta,mothur.groups,mothur.align.report,mothur.names,mothur.count_table",Remove.lineage,"mothur.seq.taxonomy,mothur.groups,mothur.count_table,mothur.names,mothur.align.report"
494,Removes OTU labels,,    MOTHUR OVERVIEW     Command Documentation    The remove otulabels  command removes otu labels from the output from classify otu   corr axes  and otu association   This can be useful especially with subsampled datasets or when groups have been selected       classify otu       corr axes       otu association       remove otulabels        ,mothur_remove_otulabels,"mothur.otulabels,mothur.list,mothur.shared,mothur.cons.taxonomy,mothur.otu.corr,mothur.axes",Remove.otulabels,
495,Remove otus containing sequences from specified groups,,    MOTHUR OVERVIEW     Command Documentation    The remove otus  command removes otus from a list  containing sequences from a specific group or set of groups       list       remove otus         ,mothur_remove_otus,"mothur.list,mothur.groups",Remove.otus,"mothur.groups,mothur.list"
496,Remove rare OTUs,,    MOTHUR OVERVIEW     Command Documentation    The remove rare  command reads one of the following file types  list   rabund   sabund  or shared  file  It outputs a new file after removing the rare otus       list       sabund       rabund       shared       remove rare         ,mothur_remove_rare,"mothur.shared,mothur.list,mothur.groups,mothur.count_table,mothur.list,mothur.rabund,mothur.sabund",Remove.rare,mothur.groups
497,Remove sequences by name,,    MOTHUR OVERVIEW     Command Documentation    The remove seqs  command takes a list of sequence names and either a fasta  name   group   list   align report  or taxonomy  file to generate a new file that does not contain the sequences in the list  This command may be used in conjunction with the list seqs  command to help screen a sequence collection       name       group       list       align report       taxonomy       list seqs       remove seqs        ,mothur_remove_seqs,"mothur.accnos,fasta,qual,fastq,mothur.names,mothur.groups,mothur.align.report,mothur.list,mothur.seq.taxonomy,mothur.count_table",Remove.seqs,"mothur.names,mothur.groups,mothur.align.report,mothur.list,mothur.seq.taxonomy"
498,Reverse complement the sequences,,    MOTHUR OVERVIEW     Command Documentation    The reverse seqs  command will generate a fasta containing the reverse complement of each sequence in the input fasta       reverse seqs        ,mothur_reverse_seqs,"fasta,mothur.align",Reverse.seqs,
499,Screen sequences,,    MOTHUR OVERVIEW     Command Documentation    The screen seqs  command enables you to keep sequences that fulfill certain user defined criteria  Furthermore  it enables you to cull those sequences not meeting the criteria from a name   group   or align report  file       name       group       align report       screen seqs         ,mothur_screen_seqs,"fasta,mothur.align,qual,mothur.names,mothur.groups,mothur.align.report,mothur.summary,tabular,taxonomy,mothur.count_table",Screen.seqs,"mothur.accnos,mothur.names,mothur.groups,mothur.align.report,mothur.count_table"
500,Determine the quality of OTU assignment,,    MOTHUR OVERVIEW     Command Documentation    The sens spec  command takes a list  and either a column   or phylip  distance matrix to determine the quality of OTU assignment        list       column       phylip       sens spec        ,mothur_sens_spec,"mothur.list,mothur.dist,phylip,tabular",Sens.spec,tabular
501,assess error rates in sequencing data,,    MOTHUR OVERVIEW     Command Documentation    The seq error  command evaluates error rate for sequences by comparing to the fasta formatted template alignment   This is demonstrated in  Error analysis      template alignment       seq error         ,mothur_seq_error,"mothur.align,fasta,mothur.names,qual,mothur.align.report,mothur.count_table",Seq.error,"tabular,fasta,mothur.align"
502,Summarize the quality of sequences,,    MOTHUR OVERVIEW     Command Documentation    The sffinfo  command will summarize the quality of sequences in an unaligned or aligned fasta formatted sequence file        sffinfo        ,mothur_sffinfo,"sff,mothur.oligos,mothur.accnos",Sffinfo,"fasta,qual454,txt,mothur.sff.flow,sff"
503,Denoise flowgrams (PyroNoise algorithm),,    MOTHUR OVERVIEW     Command Documentation    The shhh flows  command is Pat Schloss s translation of Chris Quince s PyroNoise algorithm  1  from C to C   with the incorporation of mothur s bells and whistles  Based on processing of test datasets provided by Quince  shhh flows gives the same similar output to AmpliconNoise  shhh flows uses a expectation maximization algorithm to correct flowgrams to identify the idealized form of each flowgram and translate that flowgram to a DNA sequence  Our testing has shown that when Titanium data are trimmed to 450 flows using trim flows  shhh flows provides the highest quality data for any other method available  In contrast  when we use the min max number of flows suggested by Quince of 360 720  the error rate is not that great  This much improved error rate does come at a computational cost  Whereas the features in trim seqs take on the order of minutes  shhh flows can take on the order of hours   You will also need a lookup file that tells shhh flows the probability of observing an intensity value for a given homopolymer length  You can get mothur compatible files at        shhh flows         ,mothur_shhh_flows,"mothur.sff.flow,tabular",Shhh.flows,"fasta,qual454,mothur.names,mothur.groups,tabular"
504,Denoise program (Quince SeqNoise),,    MOTHUR OVERVIEW     Command Documentation    The shhh seqs  command is a mothur based rewrite of Chris Quince s sequence denoting program  SeqNoise   Schloss prefers pre cluster for this operation       shhh seqs         ,mothur_shhh_seqs,"fasta,mothur.names,mothur.groups",Shhh.seqs,"mothur.names,txt"
505,put sequences in different files in the same order,,    MOTHUR OVERVIEW     Command Documentation    The sort seqs  command puts sequences from a fasta  name  group  quality  flow or taxonomy file in the same order  You can provide an accnos file to indicate the order you want  otherwise mothur will use the order of the first file it reads       sort seqs         ,mothur_sort_seqs,"fasta,qual454,mothur.sff.flow,mothur.groups,mothur.names,mothur.seq.taxonomy,mothur.accnos,mothur.count_table",Sort.seqs,
506,Separate sequences into rare and abundant groups,,    MOTHUR OVERVIEW     Command Documentation    The split abund  command reads a fasta file and a list  or a name  file and splits the sequences into rare and abundant groups       list       name       split abund        ,mothur_split_abund,"fasta,mothur.names,mothur.list,mothur.count_table,mothur.groups",Split.abund,"mothur.groups,mothur.names,mothur.count_table,mothur.accnos"
507,Generates a fasta file for each group,,    MOTHUR OVERVIEW     Command Documentation    The split groups  command reads a fasta file and group  file and generates a fasta file for each group in the groupfile   A name  file can also be split into groups       group       name       split groups        ,mothur_split_groups,"fasta,mothur.names,mothur.groups,mothur.count_table",Split.groups,
508,Create a sub sample,,    MOTHUR OVERVIEW     Command Documentation    The sub sample  command can be used as a way to normalize your data  or to create a smaller set from your original set  It takes as an input the following file types  fasta  list   shared   rabund  and sabund  to generate a new file that contains a sampling of your original file       list       shared       rabund       sabund       sub sample         ,mothur_sub_sample,"fasta,mothur.names,mothur.groups,mothur.list,mothur.shared,mothur.sabund,mothur.rabund,mothur.count_table,mothur.seq.taxonomy,mothur.ref.taxonomy",Sub.sample,"mothur.sabund,mothur.rabund,mothur.names,mothur.groups"
509,Summarize the quality scores,,    MOTHUR OVERVIEW     Command Documentation    The summary qual  command reads a quality file and an optional name  and summarizes the quality information       summary qual        ,mothur_summary_qual,"qual,mothur.names,mothur.count_table",Summary.qual,mothur.summary
510,Summarize the quality of sequences,,    MOTHUR OVERVIEW     Command Documentation    The summary seqs  command will summarize the quality of sequences in an unaligned or aligned fasta formatted sequence file        summary seqs        ,mothur_summary_seqs,"fasta,mothur.align,mothur.names,mothur.count_table",Summary.seqs,mothur.summary
511,Summary of calculator values for OTUs,,    MOTHUR OVERVIEW     Command Documentation    The summary shared  command produce a summary file that has the calculator value for each line in the OTU data of the shared  file and for all possible comparisons between the different groups in the group  file   This can be useful if you aren t interested in generating collector s or rarefaction curves for your multi sample data analysis  It would be worth your while  however  to look at the collector s curves for the calculators you are interested in to determine how sensitive the values are to sampling  If the values are not sensitive to sampling  then you can trust the values  Otherwise  you need to keep sampling   For calc parameter choices see        shared       group       summary shared        ,mothur_summary_shared,mothur.shared,Summary.shared,tabular
512,Summary of calculator values for OTUs,,    MOTHUR OVERVIEW     Command Documentation    The summary single  command produce a summary file that has the calculator value for each line in the OTU data and for all possible comparisons between the different groups in the group  file   This can be useful if you aren t interested in generating collector s or rarefaction curves for your multi sample data analysis  It would be worth your while  however  to look at the collector s curves for the calculators you are interested in to determine how sensitive the values are to sampling  If the values are not sensitive to sampling  then you can trust the values  Otherwise  you need to keep sampling   For calc parameter choices see        group       summary single        ,mothur_summary_single,"mothur.list,mothur.rabund,mothur.sabund,mothur.shared",Summary.single,tabular
513,Assign sequences to taxonomy,,    MOTHUR OVERVIEW     Command Documentation    The summary tax  command reads a taxonomy file and an optional name and or group file  and summarizes the taxonomy information       summary tax        ,mothur_summary_tax,"mothur.seq.taxonomy,mothur.names,mothur.groups,tabular,mothur.count_table",Summary.tax,mothur.summary
514,Generate a newick tree for dissimilarity among groups,,    MOTHUR OVERVIEW     Command Documentation    The tree shared  command will generate a newick formatted tree file that describes the dissimilarity  1 similarity  among multiple groups   For calc parameter choices see        tree shared         ,mothur_tree_shared,"mothur.pair.dist,mothur.names,mothur.dist,mothur.lower.dist,mothur.square.dist,mothur.shared,mothur.count_table",Tree.shared,mothur.tre
515,"partition by barcode, trim to length, cull by length and mismatches",,    MOTHUR OVERVIEW     Command Documentation    The trim flows  command is analogous to the trim seqs command  except that it uses the flowgram data that comes bundled in the sff file that is generated by 454 sequencing  It s primary usage is as a preliminary step to running shhh seqs  Chris Quince has a series of perl scripts that fulfill a similar role  1   This command will allow you to partition your flowgram data by sample based on the barcode  trim the flows to a specified length range  and cull sequences that are too short or have too many mismatches to barcodes and primers       trim flows         ,mothur_trim_flows,"mothur.sff.flow,mothur.oligos",Trim.flows,"mothur.sff.flow,tabular,fasta"
516,"Trim sequences - primers, barcodes, quality",,    MOTHUR OVERVIEW     Command Documentation    The trim seqs  command provides the preprocessing features needed to screen and sort pyrosequences   The command will enable you to trim off primer sequences and barcodes  use the barcode information to generate a group file and split a fasta file into sub files  screen sequences based on the qual file that comes from 454 sequencers  cull sequences based on sequence length and the presence of ambiguous bases and get the reverse complement of your sequences  While this analysis is clearly geared towards pyrosequencing collections  it can also be used with traditional Sanger sequences       trim seqs         ,mothur_trim_seqs,"fasta,mothur.names,mothur.oligos,qual454,mothur.count_table",Trim.seqs,"mothur.names,mothur.count_table,mothur.groups"
517,Describes whether two or more communities have the same structure,,    MOTHUR OVERVIEW     Command Documentation    The unifrac unweighted  command the unweighted UniFrac algorithm  The unifrac weighted command implements the weighted version of the command  Both of these methods are available through the UniFrac website  The UniFrac methods are generic tests that describes whether two or more communities have the same structure  The significance of the test statistic can only indicate the probability that the communities have the same structure by chance  The value does not indicate a level of similarity       unifrac unweighted         ,mothur_unifrac_unweighted,"mothur.tre,mothur.groups,mothur.names,mothur.count_table",unifrac.unweighted,"tabular,mothur.lower.dist,mothur.tre"
518,Describes whether two or more communities have the same structure,,    MOTHUR OVERVIEW     Command Documentation    The unifrac weighted  command implements the weighted UniFrac algorithm  The unifrac unweighted command implements the unweighted version of the command  Both of these methods are available through the UniFrac website  The UniFrac methods are generic tests that describes whether two or more communities have the same structure  The significance of the test statistic can only indicate the probability that the communities have the same structure by chance  The value does not indicate a level of similarity       unifrac weighted         ,mothur_unifrac_weighted,"mothur.tre,mothur.groups,mothur.names,mothur.count_table",unifrac.weighted,"tabular,mothur.lower.dist,mothur.tre"
519,Return unique sequences,,    MOTHUR OVERVIEW     Command Documentation    The unique seqs  command returns only the unique sequences found in a fasta formatted sequence file and a name  file that indicates those sequences that are identical to the reference sequence       name       unique seqs         ,mothur_unique_seqs,"fasta,mothur.names,mothur.count_table",Unique.seqs,"mothur.names,mothur.count_table"
520,Generate Venn diagrams for groups ,,    MOTHUR OVERVIEW     Command Documentation    The venn  command generates Venn diagrams to compare the richness shared among 2  3  or 4 groups   For calc parameter choices see        venn         ,mothur_venn,"mothur.shared,mothur.list",Venn,
521,analyzes collections of multi-condition ChIP-seq data,,MultiGPS is a framework for analyzing collections of multi condition ChIP seq datasets and characterizing differential binding events between conditions   MultiGPS encourages consistency in the reported binding event locations across conditions and provides accurate estimation of ChIP enrichment levels at each event  MultiGPS performs significant EM optimization of binding events along the genome and across experimental conditions  and it integrates motif finding via MEME   The tool loads all data into memory  so the potential exists for time and memory intensive analyses if running over many conditions or large datasets ,multigps,"bam,bed,scidx,tabular,txt,fasta",MultiGPS,"tabular,html"
522,aggregate results from bioinformatics analyses into a single report,, MultiQC     aggregates results from bioinformatics analyses across many samples into a single report  It takes results of multiple analyses and creates a report that can be viewed as a single beautiful web page  It s a general use tool  perfect for summarizing the output from numerous bioinformatics tools ,multiqc,"txt,txt,tabular,tsv,csv,txt,tabular,tabular,tsv,txt,xls,tabular,csv,xls,tabular,tabular",MultiQC,"html,txt"
523,Antibiotic resistance predictions,,  ATTRIBUTION    ,mykrobe_genotype,fasta,mkyrobe genotype,json
524,Antibiotic resistance predictions,,      ATTRIBUTION    ,mykrobe_predict,,mkyrobe predict,json
525,search NCBI for citations in PubMed,, NCBI ECitMatch                 Search for citation PubMed IDs  These can be provided via a tabular file  or via direct input  If provided via file  the columns should be ordered   1  Journal Name 2  Year 3  Volume 4  First Page 5  Author Name 6  Citation Key   An example query                                                  Parameter       Value                                                                     Journal Title   proc natl acad sci u s a                                                  Year            1991                                                                      Volume          88                                                                        First Page      3248                                                                      Author Name     mann bj                                                                   Citation Key    citation 1                                                                 REFERENCES    DISCLAIMER        ,ncbi_eutils_ecitmatch,tabular,NCBI ECitMatch,tabular
526,fetch records from NCBI,, NCBI Entrez EFetch                     Responds to a list of UIDs in a given database with the corresponding data records in a specified format   Example Queries                  Fetch PMIDs 17284678 and 9997 as text abstracts                                                                     Parameter              Value                                                                                                    NCBI Database to Use   PubMed                                                                                                   ID List                17284678 9997                                                                                            Output Format          Abstract                                                                                                Fetch FASTA for a transcript and its protein product  GIs 312836839 and 34577063                                                                     Parameter              Value                                                                                                    NCBI Database to Use   Protein                                                                                                  ID List                312836839 34577063                                                                                       Output Format          Fasta                                                                                                    REFERENCES    DISCLAIMER        ,ncbi_eutils_efetch,,NCBI EFetch,
527,Provides the number of records retrieved in all Entrez databases by a single text query.,, NCBI Entrez EGQuery                      Provides the number of records retrieved in all Entrez databases by a single text query   Example Queries                                                           Parameter              Value                                                  Term                   Cancer                                                 REFERENCES    DISCLAIMER        ,ncbi_eutils_egquery,,NCBI EGQuery,xml
528,fetch NCBI database metadata,, NCBI Entrez EInfo                    Provides the number of records indexed in each field of a given database  the date of the last update of the database  and the available links from the database to other Entrez databases    REFERENCES    DISCLAIMER        ,ncbi_eutils_einfo,,NCBI EInfo,xml
529,link UIDs from one database to another,, NCBI Entrez ELink                    Responds to a list of UIDs in a given database with either a list of related UIDs  and relevancy scores  in the same database or a list of linked UIDs in another Entrez database  checks for the existence of a specified link from a list of one or more UIDs  creates a hyperlink to the primary LinkOut provider for a specific UID and database  or lists LinkOut URLs and attributes for multiple UIDs   Commands           Example Queries                  Link from protein to gene                                                                    Parameter              Value                                                                                                    From NCBI Database     Protein                                                                                                  Elink Command          Neighbor                                                                                                 To NCBI Database       Gene                                                                                                     ID List                15718680 157427902                                                                                      Find related articles to PMID 20210808 with scores                                                                    Parameter              Value                                                                                                    From NCBI Database     PubMed                                                                                                   Elink Command          Scored Neighbors                                                                                         To NCBI Database       PubMed                                                                                                   ID List                20210808                                                                                                List all possible links from two protein GIs                                                                    Parameter              Value                                                                                                    From NCBI Database     Protein                                                                                                  Elink Command          ACheck                                                                                                   ID List                15718680 157427902                                                                                      List all possible links from two protein GIs to PubMed                                                                    Parameter              Value                                                                                                    From NCBI Database     Protein                                                                                                  Elink Command          ACheck                                                                                                   To NCBI Database       PubMed                                                                                                   ID List                15718680 157427902                                                                                      Check whether two nuccore sequences have  related sequences  links                                                                     Parameter              Value                                                                                                    From NCBI Database     Nuccore                                                                                                  Elink Command          NCheck                                                                                                   ID List                21614549 219152114                                                                                      List the LinkOut URLs for non library providers for two pubmed abstracts                                                                     Parameter              Value                                                                                                    From NCBI Database     Pubmed                                                                                                   Elink Command          Links                                                                                                    ID List                19880848 19822630                                                                                       Find links to full text providers for two PubMed abstracts                                                                     Parameter              Value                                                                                                    From NCBI Database     Pubmed                                                                                                   Elink Command          Provider Links                                                                                           ID List                19880848 19822630                                                                                        REFERENCES    DISCLAIMER        ,ncbi_eutils_elink,,NCBI ELink,xml
530,post UIDs to NCBI History Server,, NCBI Entrez EPost                    Accepts a list of UIDs from a given database  stores the set on the History Server  and responds with an NCBI History reference    REFERENCES    DISCLAIMER        ,ncbi_eutils_epost,,NCBI EPost,
531,search NCBI Databases by text query,, NCBI Entrez ESearch                      Responds to a text query with the list of matching UIDs in a given database  for later use in ESummary  EFetch or ELink   along with the term translations of the query   Example Queries                  Search in PubMed with the term cancer for abstracts that have an Entrez date within the last 60 days                                            Parameter              Value                                                  NCBI Database to Use   PubMed                                                 Term                   Cancer                                                 Datetype               Entrez Date                                            In past N Days         60                                                    Search PubMed Central for free full text articles containing the query stem cells                                                                     Parameter              Value                                                                                                    NCBI Database to Use   PubMedCentral                                                                                            Term                   Stem Cells AND free fulltext filter                                                                     Search in Nucleotide for all tRNAs                                                                     Parameter              Value                                                                                                    NCBI Database to Use   Nucleotide                                                                                               Term                   biomol trna prop                                                                                        Search in Protein for a molecular weight range                                                                     Parameter              Value                                                                                                    NCBI Database to Use   Protein                                                                                                  Term                   70000 90000 molecular weight                                                                              REFERENCES    DISCLAIMER        ,ncbi_eutils_esearch,json,NCBI ESearch,json
532,fetch summary of history/ids,, NCBI Entrez ESummary                       Responds to a list of UIDs from a given database with the corresponding document summaries   Example Queries                  Search against protein                                                                     Parameter              Value                                                                                                    NCBI Database to Use   Protein                                                                                                  ID List                28800982 28628843                                                                                        REFERENCES    DISCLAIMER        ,ncbi_eutils_esummary,,NCBI ESummary,xml
533,Removes reads from a BAM file based on criteria,, Removes reads from a BAM file based on criteria   Given a BAM file  this tool will discard reads that did not meet the selected filtering criteria The output is another BAM file with the reads not matching the criteria removed   Note  this does not adjust tag values reflecting any filtering   for example        if a read mapped to two locations  IH i 2   and one was removed by       filtering  the IH i tag would still read IH i 2    Currently  the available filters are                                                                                          Agument                          Description                                                                                                                               minlen val                      Remove reads that are smaller than  val                                                                                                   maxlen val                      Remove reads that are larger than  val                                                                                                    mapped                          Keep only mapped reads                                                                                                                    unmapped                        Keep only unmapped reads                                                                                                                  properpair                      Keep only properly paired reads  both mapped                                         correct orientation  flag set in BAM                                                                                                      noproperpair                    Keep only not properly paired reads                                                                                                       mask bitmask                    Remove reads that match the mask  e g  0x400                                                                                              uniq  length                    Remove reads that are have the same sequence                                         Note  BAM file should be sorted                                                       up to an optional length                                                                                                                 uniq start                      Remove reads that start at the same position                                         Note  BAM file should be sorted                                                       Use only for low coverage samples                                                                                                       mismatch num                     Number of mismatches or indels                                                       indel always counts as 1 regardless of length                                         requires NM tag in reads                                                                                                                nosecondary                      Remove reads that have the 0x100 flag set                                                                                                noqcfail                         Remove reads that have the 0x200 flag set                                                                                                nopcrdup                         Remove reads that have the 0x400 flag set                                                                                                excludebed file bed  nostrand    Remove reads that are in any of the regions                                          from the given BED file  If  nostrand  is given                                      strand information from the BED file is ignored                                                                                          includebed file bed  nostrand    Remove reads that are NOT any of the regions                                         from the given BED file  If  nostrand  is given                                      strand information from the BED file is ignored                                      Note  If this is a large dataset  use                                                 bamutils extract  instead                                                                                                                includeref refname              Exclude reads NOT mapped to a reference                                                                                                   excluderef refname              Exclude reads mapped to a particular reference                                        e g  chrM  or  dup chromosomes                                                                                                            ,ngsutils_bam_filter,"bam,bed",BAM filter,bam
534,to estimate average coverage and generate Nonpareil curves,, Nonpareil uses the redundancy of the reads in metagenomic datasets to estimate the average coverage and predict the amount of sequences that will be required to achieve  nearly complete coverage    Nonpareil outputs three files and one optional log file     Redundancy summary is a tab delimited file with six columns  The first column indicates the sequencing effort  in number of reads   and the remaining columns indicate the summary of the distribution of redundancy  from the replicates  1 024 by default  at the given sequencing effort  These five columns are  average redundancy  standard deviation  quartile 1  median  quartile 2   and quartile 3    Redundancy values is a tab delimited file with three columns  Similar to the redundancy summary file  it contains information about the redundancy at each sequencing effort  but it provides ALL the results from the replicates  not only the summary at each point  The first column indicates the sequencing effort  as a fraction of the dataset   the second column indicates the ID of the replicate  a number used only to introduce some controlled noise in plots   and the third column indicates the estimated redundancy value    Mates distribution is a raw list with the number of reads in the dataset matching a query read  A set of query reads is randomly drawn by Nonpareil  1 000 by default   and compared against all reads in the dataset  Each line on this file corresponds to a query read  the order is not important   We have seen certain correspondance between these numbers and the distribution of abundances in the community  compared  for example  as rank abundance plots   but this file is provided only for quality control purposes and comparisons with other tools    Log is a verbose log of internal Nonpareil processing  The number to the left  inside squared brackets  indicate the CPU time  in minutes   This file also provide quality assessment of the Nonpareil run  automated consistency evaluation   Ideally  the last line should read  Everything seems correct   Otherwise  it suggests alternative parameters that may improve the estimation   For more details about the tool  please check       ,nonpareil,"fastq,fasta",Nonpareil,"tabular,txt"
535,"
        mark/remove PCR duplicates based on molecular tags
    ",, Marks removes PCR introduced duplicate molecules based on the molecular tagging technology used in NuGEN products   For SINGLE END reads  duplicates are marked if they fulfill the following criteria  a  start at the same genomic coordinate b  have the same strand orientation c  have the same molecular tag sequence  The read with the highest mapping quality is kept as the non duplicate read   For PAIRED END reads  duplicates are marked if they fulfill the following criteria  a  start at the same genomic coordinate b  have the same template length c  have the same molecular tag sequence  The read pair with the highest mapping quality is kept as the non duplicate read   Author  Anand Patel  Contact  NuGEN Technologies Inc   techserv nugen com          Input        IN sam IN bam         input sorted unsorted SAM BAM containing only unique                             alignments  sorted required for case 2 detailed above       Options         2    paired end      use paired end deduping with template  SAM BAM                             alignment must contain paired end reads  Degenerate                             read pairs  alignments for one read of pair  will be                             discarded         f INDEX fq READ fq   FASTQ file containing the molecular tag sequence for                             each read name in the corresponding SAM BAM file                              required only for CASE 1 detailed above         o OUT PREFIX    out OUT PREFIX                             prefix of output file paths for sorted BAMs  default                             will create prefix sorted markdup bam                              prefix sorted dedup bam  prefix dup log txt         s START    start START                             position in index read where molecular tag sequence                             begins  This should be a 1 based value that counts in                             from the 3  END of the read   default   6         l LENGTH    length LENGTH                             length of molecular tag sequence  default   6         T TEMP DIR           directory for reading and writing to temporary files                             and named pipes  default   tmp          old samtools        required for compatibility with samtools sort style in                             samtools versions   0 1 19         rmdup only          required for only outputting duplicates removed file        v    version         show program s version number and exit        h    help            show this help message and exit         ,nugen_nudup,"sam,bam,fastq,fastq.gz,fastqsanger,fastqsanger.gz",NuDUP,"bam,txt"
536,Construct consensus reads from Illumina pair-end reads,,illuminapairedend aims at aligning the two reads of a pair end library sequenced using an Illumina platform  ,obi_illumina_pairend,fastq,Illuminapairedend - Assembling pair-end reads,fastq
537,Assigns sequence records to the corresponding experiment/sample based on DNA tags and primers,,A DNA metabarcoding experiment can be considered as a set a PCR products mixed together and sequenced using a next generation sequencer   i e   a solexa or a 454   To distinguish between this different PCR products  pairs of small DNA sequences  call tags  see the oligoTag command and its associated paper for more informations on the design of such tags  unique for each PCR products are concatenated to the PCR primers  As they are amplified during the PCR  these tags should be recognizable  together with their respective primers  at the beginning and the end of the reads  The first step in data analysis is thus to demultiplex the large resulting sequence file by identifying these DNA tags and the primers ,obi_ngsfilter,"tabular,fastq",NGSfilter,fastq
538,Adds/Edits sequence record annotations,, obiannotate  is the command that allows adding modifying removing annotation attributes attached to sequence records ,obi_annotate,"fastq,fasta,txt,tabular",obiannotate,fasta
539,tags a set of sequences for PCR/sequencing errors identification,,obijoinpairedend aims at joining the two reads of a paired end library ,obi_clean,fasta,obiclean,fasta
540,converts sequence files to different output formats,,obiconvert converts sequence files to different output formats  See the documentation for more details on the different formats ,obi_convert,"fastq,fasta,txt,tabular,txt,tabular",obiconvert,"txt,fasta"
541,Filters sequence file,,The obigrep command is in some way analog to the standard Unix grep command  It selects a subset of sequence records from a sequence file ,obi_grep,"fasta,fastq,txt,tabular",obigrep,fastq
542,"sorts sequence records according to the value of a given attribute, which can be either numeric or alphanumeric",,obisort sorts sequence records according to the value of a given attribute  which can be either numeric or alphanumeric ,obi_sort,"fastq,fasta,txt,tabular",obisort,fastq
543,computes basic statistics for attribute values,,stats computes basic statistics for attribute values of sequence records  The sequence records can be categorized or not using one or several  c options  By default  only the number of sequence records and the total count are computed for each category  Additional statistics can be computed for attribute values in each category  like ,obi_stat,"fasta,fastq",obistat,txt
544,converts sequence file to a tabular file that can be open by a spreadsheet program or R,,obitab command converts sequence file to a tabular file that can be open by a spreadsheet program or R,obi_tab,"fastq,fasta,txt,tabular,tabular",obitab,tabular
545,,,The obiuniq command is in some way analog to the standard Unix uniq  c command ,obi_uniq,"fasta,fastq",obiuniq,fasta
546,consensus caller on SAM/BAM,,     OCOCO   Online Consensus Caller    OCOCO is a online consensus caller  capable to infer SNVs dynamically as read alignments are fed in  OCOCO inputs unsorted alignments from an unsorted SAM BAM stream and decides about single nucleotide updates of the current genomic consensus using statistics stored in compact several bits counters  Updates are reported in the online fashion using unsorted VCF  OCOCO provides a fast and memory efficient alternative to the usual variant calling  particularly advantageous when reads are sequenced or mapped progressively  or when available computational resources are at a premium               ,ococo,"bam,sam,fasta",ococo,"vcf,fasta,pileup"
547,Collects the ancestor terms from a given term in the given OBO ontology,,     class   infomark  Collects the ancestor terms  list of IDs  from a given term  existing ID  in the given OBO ontology     Example    If you ask for the descendents of the Gene Ontology term with ID   GO 000800   you will get      GO 0043229 intracellular organelle   GO 0043232 intracellular non membrane bounded organelle   GO 0044446 intracellular organelle part   GO 0044424 intracellular part   GO 0005623 cell   GO 0044422 organelle part   GO 0043228 non membrane bounded organelle   GO 0044427 chromosomal part   GO 0005575 cellular component   GO 0000793 condensed chromosome   GO 0043231 intracellular membrane bounded organelle   GO 0043226 organelle   GO 0005634 nucleus   GO 0044464 cell part   GO 0005622 intracellular   GO 0044454 nuclear chromosome part   GO 0005694 chromosome   GO 0000228 nuclear chromosome   GO 0043227 membrane bounded organelle   GO 0000794 condensed nuclear chromosome   GO 0000795 synaptonemal complex   GO 0044428 nuclear part      ,onto_tk_get_ancestor_terms,text,Get the ancestor terms of a given OBO term,tabular
548,of a given OBO term,,     class   infomark  Collects the child terms  list of IDs  from a given term  existing ID  in the given OBO ontology     Example    If you ask for the children of the Gene Ontology term with ID   GO 0000079   you will get      GO 0031660      regulation of cyclin dependent protein kinase activity during G2 M   GO 0031657      regulation of cyclin dependent protein kinase activity during G1 S   GO 0045737      positive regulation of cyclin dependent protein kinase activity   GO 0045736      negative regulation of cyclin dependent protein kinase activity      ,onto_tk_get_child_terms,,Get child terms,tabular
549,of a given OBO term,,     class   infomark  Collects the descendent terms  list of IDs  from a given term  existing ID  in the given OBO ontology     Example    If you ask for the descendents of the Gene Ontology term with ID   GO 000741   you will get      GO 0048288 nuclear membrane fusion during karyogamy   GO 0000745 nuclear migration during conjugation without cellular fusion   GO 0000744 karyogamy during conjugation without cellular fusion   GO 0032871 regulation of karyogamy   GO 0007344 pronuclear fusion   GO 0000742 karyogamy during conjugation with cellular fusion   GO 0010197 polar nucleus fusion   GO 0000743 nuclear migration during conjugation with cellular fusion      ,onto_tk_get_descendent_terms,,Get the descendent terms,tabular
550,of a given OBO term,,     class   infomark  Collects the parent terms  list of IDs  from a given term  existing ID  in the given OBO ontology     Example    If you ask for the parents of the Gene Ontology term with ID   GO 0000079   you will get      GO 0045859 regulation of protein kinase activity   GO 0051726 regulation of cell cycle      ,onto_tk_get_parent_terms,,Get the parent terms,tabular
551,filtered by a relationship type,,     class   infomark  Collects the terms  list of IDs  from a given term  existing ID  through a given relationship type in the given OBO ontology    Example    id  A  name  A A part of B A part of D A participates in F   If you ask for the parent terms of   A   along part of you will get      B   D      ,onto_tk_get_parent_terms_by_relationship_type,,Get the terms,tabular
552,from the given OBO ontology,,     class   infomark  Generates a flat file with two columns  TAB separated  with the relationship id and relationship definition from the elements of the given OBO ontology       ,onto_tk_get_relationship_id_vs_relationship_def,,Get all the relationship IDs and definitions,tabular
553,from the given OBO ontology,,     class   infomark  Generates a flat file with two columns  TAB separated  with the relationship id and relationship name from the elements of the given OBO ontology       ,onto_tk_get_relationship_id_vs_relationship_name,,Get all the relationship IDs and names,tabular
554,from the given OBO ontology,,     class   infomark  Generates a flat file with two columns  TAB separated  with the relationship id and relationship namespace from the elements of the given OBO ontology       ,onto_tk_get_relationship_id_vs_relationship_namespace,,Get all the relationship IDs and namespaces,tabular
555,from the given OBO ontology,,     class   infomark   Collects all the names of the relationship types in a given ontology     Example    If you ask for the relationships of the Gene Ontology  you will get      is a   part of   regulates   has part   negatively regulates   positively regulates      ,onto_tk_get_relationship_types,,Get all the relationship types,tabular
556,of a given OBO term,,     class   infomark  Collects the root terms  list of IDs  of the given OBO ontology       ,onto_tk_get_root_terms,,Get the root terms,tabular
557,from a given OBO term,,  Extracts a subontology  in OBO format  of a given ontology having as root node the provided term ID       ,onto_tk_get_subontology_from,,Get subontology,obo
558,of a given OBO ontology,,     class   infomark  Generates a flat file with two columns  TAB separated  with the term id and term definition from the elements of the given OBO ontology      Example    If you ask for the term IDs and terms definitions of the Gene Ontology  you will get      GO 0006285 The formation of an AP site  a deoxyribose sugar with a missing base  by DNA glycosylase which recognizes an altered base in DNA and catalyzes its hydrolytic removal  This sugar phosphate is the substrate recognized by the AP endonuclease  which cuts the DNA phosphodiester backbone at the 5  side of the altered site to leave a gap which is subsequently repaired    GO 0043527 A multimeric protein complex involved in the methylation of specific nucleotides in tRNA    GO 0005593 Any collagen polymer associated with collagen fibrils and in which the collagen monomers contain two or more relatively short triple helical domains connected by non triple helical sequences  the acronym FACIT stands for fibril associated collagen with interrupted triple helix    GO 0015777 The directed movement of teichoic acid into  out of  within or between cells by means of some external agent such as a transporter or pore  Teichoic acid is any polymer occurring in the cell wall  membrane or capsule of Gram positive bacteria and containing chains of glycerol phosphate or ribitol phosphate residues    GO 0047104 Catalysis of the reaction  NAD    CoA   palmitaldehyde   NADH   palmityl CoA    GO 0018302 The incorporation of iron into a 4Fe 4S iron sulfur cluster via tris L cysteinyl L N1  histidino tetrairon tetrasulfide                   ,onto_tk_term_id_vs_term_def,,Get all the term IDs and term definitions,tabular
559,of a given OBO ontology,,     class   infomark  Generates a flat file with two columns  TAB separated  with the term id and term name from the elements of the given OBO ontology      Example    If you ask for the term IDs and terms names of the Gene Ontology  you will get      GO 0050129 N formylglutamate deformylase activity   GO 0051663 oocyte nucleus localization involved in oocyte dorsal ventral axis specification   GO 0051712 positive regulation of killing of cells of another organism   GO 0033972 proclavaminate amidinohydrolase activity   GO 0032513 negative regulation of protein phosphatase type 2B activity   GO 0008711 ADP L glycero D manno heptose synthase activity   GO 0006285 base excision repair  AP site formation   GO 0043527 tRNA methyltransferase complex                  ,onto_tk_term_id_vs_term_name,,Get all the term IDs and term names,tabular
560,of a given OBO term,,     class   infomark  Collects the terms and there corresponding synonyms  list of IDs  of the given OBO ontology       ,onto_tk_get_term_synonyms,,Get all term synonyms,tabular
561,of a given OBO term,,     class   infomark  Collects the terms  list of IDs  of the given OBO ontology       ,onto_tk_get_terms,,Get all terms,tabular
562,by a concrete relationship type,,     class   infomark  Collects the terms that are related by a concrete relationship type  e g  is a     Example    If you ask for terms related by the relationship type  participates in  you will get tab delimited records like      PR 0000001 participates in GO 0000023   PR 0000002 participates in GO 0033224   PR 0000003 participates in GO 0021109   PR 0000004 participates in GO 0034099                    ,onto_tk_get_terms_by_relationship_type,,Get the terms that are related,tabular
563,,, This tool transforms an OBO formatted ontology  such as the Gene Ontology  to OWL       ,onto_tk_obo2owl,,Convert OBO to OWL,owl
564,,, This tool transforms an OBO formatted ontology  such as the Gene Ontology  to RDF XML       ,onto_tk_obo2rdf,,Convert OBO to RDF,rdf
565,of a given OBO ontology,,     class   infomark  Generates a flat file with two columns  TAB separated  with the term id and term definition from the elements of the given OBO ontology      Example    If you ask for the term IDs and terms definitions of the Gene Ontology  you will get      GO 0006285 The formation of an AP site  a deoxyribose sugar with a missing base  by DNA glycosylase which recognizes an altered base in DNA and catalyzes its hydrolytic removal  This sugar phosphate is the substrate recognized by the AP endonuclease  which cuts the DNA phosphodiester backbone at the 5  side of the altered site to leave a gap which is subsequently repaired    GO 0043527 A multimeric protein complex involved in the methylation of specific nucleotides in tRNA    GO 0005593 Any collagen polymer associated with collagen fibrils and in which the collagen monomers contain two or more relatively short triple helical domains connected by non triple helical sequences  the acronym FACIT stands for fibril associated collagen with interrupted triple helix    GO 0015777 The directed movement of teichoic acid into  out of  within or between cells by means of some external agent such as a transporter or pore  Teichoic acid is any polymer occurring in the cell wall  membrane or capsule of Gram positive bacteria and containing chains of glycerol phosphate or ribitol phosphate residues    GO 0047104 Catalysis of the reaction  NAD    CoA   palmitaldehyde   NADH   palmityl CoA    GO 0018302 The incorporation of iron into a 4Fe 4S iron sulfur cluster via tris L cysteinyl L N1  histidino tetrairon tetrasulfide                   ,onto_tk_term_id_vs_term_def,,Get all the term IDs and term definitions,tabular
566,finds orthogroups in a set of proteomes,,                        OrthoFinder OnlyGroups                         Full readme at  Summary sketch at   OrthoFinder is a fast  accurate and comprehensive analysis tool for comparative genomics  It finds orthologues and orthogroups infers gene trees for all orthogroups and infers a rooted species tree for the species being analysed  OrthoFinder also provides comprehensive statistics for comparative genomic analyses  OrthoFinder is simple to use and all you need to run it is a set of protein sequence files  one per species  in FASTA format  Emms  D M  and Kelly  S   2015       class   infomark  This galaxy tool implements the first part of the Orthofinder program  e g  the clustering of orthogroups of genes   If you have already ran OrthoFinder  the tool allows to re run the analysis from the pre computed blast results               Input files                   When using  from fasta  option  e g Orthofinder from scratch    the input files are a set of proteomes in fasta format  on file per species   Choose this option if you have no OrthoFinder results yet        When using  from blast results  option   the input files are all the following files from of a previous OrthoFinder run  these files appear only if you have chosen to keep them while launching a previous run             A dataset collection   multiple datasets for the blast outputs           A dataset collection   multiple datasets for  fa files           The SpeciesIDs txt file           The SequencesIDs txt file      ,orthofinder_onlygroups,"fasta,txt",OrthoFinder OnlyGroups,"txt,csv"
567,of insert size frequency,,Produces an insert size histogram and basic statistics for a paired end BAM file   Two outputs are produced ,pe_histogram,bam,Paired-end histogram,"png,tabular"
568,Paired-End read merger,,PEAR  is an ultrafast  memory efficient and highly accurate pair end read merger  PEAR evaluates all possible paired end read overlaps and without requiring the target fragment size as input  In addition  it implements a statistical test for minimizing false positive results  Together with a highly optimized implementation  it can merge millions of paired end reads within a couple of minutes on a standard desktop computer ,iuc_pear,"fastqillumina,fastqsanger",Pear,input
569,add comments to BAM dataset,,     class   infomark    Purpose    Adds one or more comments   CO  to the header of a specified BAM dataset    dataset collections    description     COMMENT String   C String          Comments to add to the BAM file  This option may be specified 0 or more times    more info    ,picard_AddCommentsToBam,bam,AddCommentsToBam,bam
570,add or replaces read group information,,     class   infomark    Purpose    Add or Replace Read Groups in an input BAM or SAM file    dataset collections    RG    description     INPUT File   I File                  Input file  bam or sam    Required     OUTPUT File   O File                  Output file  bam or sam    Required     SORT ORDER SortOrder   SO SortOrder            Optional sort order to output in  If not supplied OUTPUT is in the same order as INPUT                            Default value  null  Possible values   unsorted  queryname  coordinate     RGID String   ID String               Read Group ID  Default value  1  This option can be set to  null  to clear the default                           value     RGLB String   LB String               Read Group Library  Required     RGPL String   PL String               Read Group platform  e g  illumina  solid   Required     RGPU String   PU String               Read Group platform unit  eg  run barcode   Required     RGSM String   SM String               Read Group sample name  Required     RGCN String   CN String               Read Group sequencing center name  Default value  null     RGDS String   DS String               Read Group description  Default value  null     RGDT Iso8601Date   DT Iso8601Date          Read Group run date  Default value  null     RGPI Integer   PI Integer              Read Group predicted insert size  Default value  null    more info    ,picard_AddOrReplaceReadGroups,"bam,sam",AddOrReplaceReadGroups,bam
571,convert coordinate data into picard interval list format,,     class   infomark    Purpose    Convert coordinate data  such as BED or Galaxy Interval  into Picard Interval Format    dataset collections    description     SEQUENCE DICTIONARY File   SD File                       The sequence dictionary  You can either use dictionary pre cached                                 on this instance of Galaxy  or create one on teh fly from a FASTA                                 file uploaded to history  right pane of the interface      more info    ,picard_BedToIntervalList,"fasta,bed",BedToIntervalList,picard_interval_list
572,perform SAM/BAM grooming,,     class   infomark    Purpose    Read SAM BAM and perform various fix ups  Currently  the only fix ups are    1  to soft clip an alignment that hangs off the end of its reference sequence   2  to set MAPQ to 0 if a read is unmapped    dataset collections    more info     ,picard_CleanSam,"sam,bam",CleanSam,bam
573,writes a file containing summary alignment metrics,,     class   infomark    Purpose    Reads a SAM or BAM file and writes a file containing summary alignment metrics    dataset collections    description     MAX INSERT SIZE Integer       Paired end reads above this insert size will be considered chimeric along with                                 inter chromosomal pairs   Default value  100000     ADAPTER SEQUENCE String       List of adapter sequences to use when processing the alignment metrics  This option may                                 be specified 0 or more times     METRIC ACCUMULATION LEVEL MetricAccumulationLevel   LEVEL MetricAccumulationLevel The level s  at which to accumulate metrics     Possible values   ALL READS  SAMPLE                                  LIBRARY  READ GROUP  This option may be specified 0 or more times     IS BISULFITE SEQUENCED Boolean   BS Boolean                    Whether the SAM or BAM file consists of bisulfite sequenced reads      REFERENCE SEQUENCE File   R File                        Reference sequence fasta  Default value  null     ASSUME SORTED Boolean   AS Boolean                    If true  default   then the sort order in the header file will be ignored    more info     ,picard_CASM,"sam,bam,fasta",Collect Alignment Summary Metrics,tabular
574,charts the nucleotide distribution per cycle in a SAM or BAM dataset,,     class   infomark    Purpose    Program to chart the nucleotide distribution per cycle in a SAM or BAM file    dataset collections    description     ALIGNED READS ONLY Boolean    If set to true  calculate the base distribution over aligned reads only   Default value                                  false  This option can be set to  null  to clear the default value  Possible values                                   true  false     PF READS ONLY Boolean         If set to true calculate the base distribution over PF reads only   Default value  false                                  This option can be set to  null  to clear the default value  Possible values   true                                  false     REFERENCE SEQUENCE File   R File                        Reference sequence fasta  Default value  null     ASSUME SORTED Boolean   AS Boolean                    If true  default   then the sort order in the header file will be ignored   Default   more info     ,picard_CollectBaseDistributionByCycle,"sam,bam,fasta",CollectBaseDistributionByCycle,"tabular,pdf"
575,charts the GC bias metrics,,     class   infomark    Purpose    Program to chart the nucleotide distribution per cycle in a SAM or BAM file    dataset collections    description     ALIGNED READS ONLY Boolean    If set to true  calculate the base distribution over aligned reads only   Default value                                  false  Possible values   true  false     PF READS ONLY Boolean         If set to true calculate the base distribution over PF reads only   Default value  false                                  This option can be set to  null  to clear the default value  Possible values   true                                  false     ASSUME SORTED Boolean   AS Boolean                    If true  default   then the sort order in the header file will be ignored   Default  True   more info     ,picard_CollectGcBiasMetrics,"sam,bam,fasta",CollectGcBiasMetrics,"tabular,pdf"
576,plots distribution of insert sizes,,     class   infomark    Purpose    Reads a SAM or BAM dataset and writes a file containing metrics about the statistical distribution of insert size  excluding duplicates  and generates a Histogram plot    dataset collections    description      DEVIATIONS Double             Generate mean  sd and plots by trimming the data down to MEDIAN                                   DEVIATIONS MEDIAN ABSOLUTE DEVIATION  This is done because insert size data typically                                 includes enough anomalous values from chimeras and other artifacts to make the mean and                                 sd grossly misleading regarding the real distribution   Default value  10 0     HISTOGRAM WIDTH Integer   W Integer                     Explicitly sets the Histogram width  overriding automatic truncation of Histogram tail                                  Also  when calculating mean and standard deviation  only bins    Histogram WIDTH will be                                 included   Default value  not set     MINIMUM PCT Float   M Float                       When generating the Histogram  discard any data categories  out of FR  TANDEM  RF  that                                 have fewer than this percentage of overall reads   Range  0 to 1    Default value  0 05     METRIC ACCUMULATION LEVEL MetricAccumulationLevel   LEVEL MetricAccumulationLevel The level s  at which to accumulate metrics     Possible values   ALL READS  SAMPLE                                  LIBRARY  READ GROUP  This option may be specified 0 or more times     ASSUME SORTED Boolean   AS Boolean                    If true  default   then the sort order in the header file will be ignored   Default                                 value  true  This option can be set to  null  to clear the default value  Possible                                 values   true  false    more info     ,picard_CollectInsertSizeMetrics,"sam,bam,fasta",CollectInsertSizeMetrics,"tabular,pdf"
577, collect metrics about the alignment of RNA to various functional classes of loci in the genome,,     class   infomark    Purpose    Collects metrics about the alignment of RNA to various functional classes of loci in the genome  coding  intronic  UTR  intergenic  ribosomal    dataset collections             class   warningmark    Obtaining gene annotations in refFlat format    This tool requires gene annotations in refFlat  format  These data can be obtained from UCSC table browser directly through Galaxy by following these steps      1  Click on   Get Data   in the upper part of left pane of Galaxy interface    2  Click on   UCSC Main   link    3  Set your genome and dataset of interest  It   must   be the same genome build against which you have mapped the reads contained in the BAM file you are analyzing    4  In the   output format   field choose   selected fields from primary and related tables      5  Click   get output   button    6  In the first table presented at the top of the page select  using checkboxes  first 11 fields        name       chrom       strand       txStart       txEnd       cdsStart       cdsEnd       exonCount       exonStarts       exonEnds       proteinId    7  Click   done with selection      8  Click   Send query to Galaxy      9  A new dataset will appear in the current Galaxy history    10  Use this dataset as the input for   Gene annotations in refFlat form   dropdown of this tool      refFlat   format9   description      REF FLAT File                 Gene annotations in refFlat form   Format described here                                    format9  Required      RIBOSOMAL INTERVALS File      Location of rRNA sequences in genome  in interval list format   If not specified no bases                                  will be identified as being ribosomal  Format described here                                    and can be                                  generated from BED datasetes using Galaxy s wrapper for picard BedToIntervalList tool     STRAND SPECIFICITY StrandSpecificity    STRAND StrandSpecificity      For strand specific library prep  For unpaired reads  use FIRST READ TRANSCRIPTION STRAND                                  if the reads are expected to be on the transcription strand   Required  Possible values                                    NONE  FIRST READ TRANSCRIPTION STRAND  SECOND READ TRANSCRIPTION STRAND      MINIMUM LENGTH Integer        When calculating coverage based values  e g  CV of coverage  only use transcripts of this                                  length or greater   Default value  500      IGNORE SEQUENCE String        If a read maps to a sequence specified with this option  all the bases in the read are                                  counted as ignored bases      RRNA FRAGMENT PERCENTAGE Double                                  This percentage of the length of a fragment must overlap one of the ribosomal intervals                                  for a read or read pair by this must in order to be considered rRNA   Default value  0 8      METRIC ACCUMULATION LEVEL MetricAccumulationLevel    LEVEL MetricAccumulationLevel The level s  at which to accumulate metrics     Possible values   ALL READS  SAMPLE                                   LIBRARY  READ GROUP  This option may be specified 0 or more times      ASSUME SORTED Boolean    AS Boolean                    If true  default   then the sort order in the header file will be ignored   Default                                  value  true  Possible values   true  false    more info     ,picard_CollectRnaSeqMetrics,"sam,bam,fasta,gtf,gff3,tabular,picard_interval_list",CollectRnaSeqMetrics,"pdf,tabular"
578,compute metrics for evaluating of whole genome sequencing experiments,,     class   infomark    Purpose    Computes a number of metrics that are useful for evaluating coverage and performance of whole genome sequencing experiments    dataset collections    description     MINIMUM MAPPING QUALITY Integer   MQ Integer                    Minimum mapping quality for a read to contribute coverage   Default value  20     MINIMUM BASE QUALITY Integer   Q Integer                     Minimum base quality for a base to contribute coverage   Default value  20     COVERAGE CAP Integer   CAP Integer                   Treat bases with coverage exceeding this value as if they had coverage at this value                                  Default value  250    more info     ,picard_CollectWgsMetrics,"sam,bam,fasta",CollectWgsMetrics,tabular
579,Downsample a file to retain a subset of the reads,,     class   infomark    Purpose    Randomly down sample a SAM or BAM file to retain a random subset of the reads  Mate pairs are either both kept or both discarded  Reads marked as not primary alignments are all discarded  Each read is given a probability P of being retained   results with the exact same input in the same order and with the same value for RANDOM SEED will produce the same results    dataset collections    description     INPUT File   I File              The input SAM or BAM file to downsample   Required     OUTPUT File   O File              The output  downsampled  SAM or BAM file to write   Required     RANDOM SEED Long   R Long              Random seed to use if reproducibilty is desired   Setting to null will cause multiple                       invocations to produce different results     PROBABILITY Double   P Double            The probability of keeping any individual read  between 0 and 1      more info    ,picard_DownsampleSam,"sam,bam",Downsample SAM/BAM,bam
580,assess sequence library complexity from read sequences,,    Purpose    Attempts to estimate library complexity from sequence of read pairs alone  Does so by sorting all reads by the first N bases  5 by default  of each read and then comparing reads with the first N bases identical to each other for duplicates  Reads are considered to be duplicates if they match each other with no gaps and an overall mismatch rate less than or equal to MAX DIFF RATE  0 03 by default    Reads of poor quality are filtered out so as to provide a more accurate estimate  The filtering removes reads with any no calls in the first N bases or with a mean base quality lower than MIN MEAN QUALITY across either the first or second read   Unpaired reads are ignored in this computation  The algorithm attempts to detect optical duplicates separately from PCR duplicates and excludes these in the calculation of library size   Also  since there is no alignment to screen out technical reads one further filter is applied on the data  After examining all reads a Histogram is built of   reads in duplicate set     of duplicate sets   all bins that contain exactly one duplicate set are then removed from the Histogram as outliers before library size is estimated    dataset collections    description     MIN IDENTICAL BASES Integer   The minimum number of bases at the starts of reads that must be identical for reads to be                                 grouped together for duplicate detection   In effect total reads   4 max id bases reads                                 will be compared at a time  so lower numbers will produce more accurate results but                                 consume exponentially more memory and CPU   Default value  5     MAX DIFF RATE Double          The maximum rate of differences between two reads to call them identical   Default value                                  0 03     MIN MEAN QUALITY Integer      The minimum mean quality of the bases in a read pair for the read to be analyzed  Reads                                 with lower average quality are filtered out and not considered in any calculations                                  Default value  20     MAX GROUP RATIO Integer       Do not process self similar groups that are this many times over the mean expected group                                 size  I e  if the input contains 10m read pairs and MIN IDENTICAL BASES is set to 5  then                                 the mean expected group size would be approximately 10 reads   Default value  500     READ NAME REGEX String        Regular expression that can be used to parse read names in the incoming SAM file  Read                                 names are parsed to extract three variables  tile region  x coordinate and y coordinate                                  These values are used to estimate the rate of optical duplication in order to give a more                                 accurate estimated library size  Set this option to null to disable optical duplicate                                 detection  The regular expression should contain three capture groups for the three                                 variables  in order  It must match the entire read name  Note that if the default regex                                 is specified  a regex match is not actually done  but instead the read name  is split on                                 colon character  For 5 element names  the 3rd  4th and 5th elements are assumed to be                                 tile  x and y values  For 7 element names  CASAVA 1 8   the 5th  6th  and 7th elements                                 are assumed to be tile  x and y values   Default value                                   a zA Z0 9    0 9    0 9      0 9      0 9          OPTICAL DUPLICATE PIXEL DISTANCE Integer                                 The maximum offset between two duplicte clusters in order to consider them optical                                 duplicates  This should usually be set to some fairly small number  e g  5 10 pixels                                  unless using later versions of the Illumina pipeline that multiply pixel values by 10  in                                 which case 50 100 is more normal   Default value  100     more info     ,picard_EstimateLibraryComplexity,bam,EstimateLibraryComplexity,tabular
581,convert Fastq data into unaligned BAM,,     class   infomark    Purpose    Computes a number of metrics that are useful for evaluating coverage and performance of whole genome sequencing experiments    dataset collections    RG    description     FASTQ File   F1 File                       Input fastq file for single end data  or first read in paired end                                 data   Required     FASTQ2 File   F2 File                       Input fastq file for the second read of paired end data  if used      QUALITY FORMAT FastqQualityFormat   V FastqQualityFormat          A value describing how the quality values are encoded in the fastq   Either Solexa for                                 pre pipeline 1 3 style scores  solexa scaling   66   Illumina for pipeline 1 3 and above                                  phred scaling   64  or Standard for phred scaled scores with a character shift of 33                                  If this value is not specified  the quality format will be detected automatically                                  Default value  null  Possible values   Solexa  Illumina  Standard     READ GROUP NAME String   RG String                     Read group name  Default value  A     SAMPLE NAME String   SM String                     Sample name to insert into the read group header  Required     LIBRARY NAME String   LB String                     The library name to place into the LB attribute in the read group header     PLATFORM UNIT String   PU String                     The platform unit  often run barcode lane  to insert into the read group header     PLATFORM String   PL String                     The platform type  e g  illumina  solid  to insert into the read group header     SEQUENCING CENTER String   CN String                     The sequencing center from which the data originated     PREDICTED INSERT SIZE Integer   PI Integer                    Predicted median insert size  to insert into the read group header     COMMENT String   CO String                     Comment to include in the merged output file s header     DESCRIPTION String   DS String                     Inserted into the read group header     RUN DATE Iso8601Date   DT Iso8601Date                Date the run was produced  to insert into the read group header     MIN Q Integer                 Minimum quality allowed in the input fastq   An exception will be thrown if a quality is                                 less than this value   Default value  0     MAX Q Integer                 Maximum quality allowed in the input fastq   An exception will be thrown if a quality is                                 greater than this value   Default value  93     STRIP UNPAIRED MATE NUMBER Boolean                                 If true and this is an unpaired fastq any occurance of   1  will be removed from the end                                 of a read name   Default value  false   Possible values   true  false     ALLOW AND IGNORE EMPTY LINES Boolean                                 Allow  and ignore  empty lines  Default value  false  Possible values   true  false     more info     ,picard_FastqToSam,fastq,FastqToSam,bam
582,include or exclude aligned and unaligned reads and read lists,,    Purpose    Computes a number of metrics that are useful for evaluating coverage and performance of whole genome sequencing experiments              class   warningmark    Warning on using this tool on BWA MEM output    This tool will likely fail on BAM datasets generated by BWA MEM as it generates partial read alignemnts    dataset collections    description     FILTER Filter                 Filter   Required  Possible values                                  includeAligned  OUTPUT SAM BAM will contain aligned                                 reads only   Note that  both  first and                                 second of paired reads must be aligned to be included                                 in the OUTPUT SAM or BAM                                     excludeAligned  OUTPUT SAM BAM will contain un mapped reads only                                   Note that  both  first and second of pair must be aligned to be                                 excluded from the OUTPUT SAM or BAM                                    includeReadList  OUTPUT SAM BAM will contain reads                                 that are supplied in the READ LIST FILE file                                   excludeReadList  OUTPUT bam will contain                                 reads that are  not  supplied in the READ LIST FILE file      READ LIST FILE File   RLF File                      Read List File containing reads that will be included or excluded from the OUTPUT SAM or                                 BAM file   Default value  null    more info     ,picard_FilterSamReads,"sam,bam,tabular",FilterSamReads,bam
583,ensure that all mate-pair information is in sync between each read and it's mate pair,,    Purpose    Ensure that all mate pair information is in sync between each read and it s mate pair  Reads marked with the secondary alignment flag are written to the output file unchanged              class   warningmark    Warning on using ASSUME SORTED option    Datasets imported into Galaxy are automatically coordinate sorted  So use this option  set it to True  only if you are sure that this is necessary  If you are not sure   a good rule of thumb is to assume that the BAM you are working with is coordinate sorted    dataset collections    description     ASSUME SORTED Boolean   AS Boolean                    If true  assume that the input file is queryname sorted  even if the header says                                 otherwise   Default value  false     ADD MATE CIGAR Boolean   MC Boolean                    Adds the mate CIGAR tag  MC  if true  does not if false   Default value  true    more info     ,picard_FixMateInformation,"sam,bam",FixMateInformation,bam
584,examine aligned records in BAM datasets to locate duplicate molecules,,    Purpose    Examines aligned records in the supplied SAM or BAM dataset to locate duplicate molecules  All records are then written to the output file with the duplicate records flagged    dataset collections    description     COMMENT String   CO String                     Comment s  to include in the output file s header   This option may be specified 0 or                                 more times     REMOVE DUPLICATES Boolean     If true do not write duplicates to the output file instead of writing them with                                 appropriate flags set   Default value  false     READ NAME REGEX String        This option is only needed if your read names do not follow a standard illumina convention                                 of colon separation but do contain tile  x  and y coordinates  unusual                                   A regular expression that can be used to parse read names in the incoming SAM file  Read                                 names are parsed to extract three variables  tile region  x coordinate and y coordinate                                  These values are used to estimate the rate of optical duplication in order to give a more                                 accurate estimated library size  Set this option to null to disable optical duplicate                                 detection  The regular expression should contain three capture groups for the three                                 variables  in order  It must match the entire read name  Note that if the default regex                                 is specified  a regex match is not actually done  but instead the read name  is split on                                 colon character  For 5 element names  the 3rd  4th and 5th elements are assumed to be                                 tile  x and y values  For 7 element names  CASAVA 1 8   the 5th  6th  and 7th elements                                 are assumed to be tile  x and y values   Default value                                         DUPLICATE SCORING STRATEGY ScoringStrategy   DS ScoringStrategy            The scoring strategy for choosing the non duplicate among candidates   Default value                                  SUM OF BASE QUALITIES  Possible values   SUM OF BASE QUALITIES  TOTAL MAPPED REFERENCE LENGTH     OPTICAL DUPLICATE PIXEL DISTANCE Integer                                 The maximum offset between two duplicate clusters in order to consider them optical                                 duplicates  This should be set to 100 for  circa 2011   read names and typical flowcells                                  Structured flow cells  NovaSeq  HiSeq 4000  X  should use  2500                                   For older conventions  distances could be to some fairly small number  e g  5 10 pixels                                  Default value  100     BARCODE TAG String            Barcode SAM tag  ex  BC for 10X Genomics   Default value  null    more info     ,picard_MarkDuplicates,bam,MarkDuplicates,"txt,bam"
585,examine aligned records in BAM datasets to locate duplicate molecules,,    Purpose    Examines aligned records in the supplied SAM or BAM dataset to locate duplicate molecules  All records are then written to the output file with the duplicate records flagged              class   warningmark  On the difference between   MarkDuplicates   and   picard MarkDuplicatesWithMateCigar    From Samtools Announce MailingList    This tool can replace MarkDuplicates if the input SAM BAM has Mate CIGAR  MC  optional tags pre computed  see the tools RevertOriginalBaseQualitiesAndAddMateCigar and FixMateInformation    This allows the new tool to perform a streaming duplicate marking routine  i e  a single pass    This tool cannot be used with alignments that have large gaps or reference skips  which happens frequently in RNA seq data       MailingList     dataset collections    description     MINIMUM DISTANCE Integer      The minimum distance to buffer records to account for clipping on the 5  end of the                                 records Set this number to  1 to use twice the first read s read length  or 100                                  whichever is smaller    Default value   1  This option can be set to  null  to clear the                                 default value     SKIP PAIRS WITH NO MATE CIGAR Boolean                                 Skip record pairs with no mate cigar and include them in the output   Default value                                  true  This option can be set to  null  to clear the default value  Possible values                                   true  false     COMMENT String   CO String                     Comment s  to include in the output file s header   This option may be specified 0 or                                 more times     REMOVE DUPLICATES Boolean     If true do not write duplicates to the output file instead of writing them with                                 appropriate flags set   Default value  false     READ NAME REGEX String        Regular expression that can be used to parse read names in the incoming SAM file  Read                                 names are parsed to extract three variables  tile region  x coordinate and y coordinate                                  These values are used to estimate the rate of optical duplication in order to give a more                                 accurate estimated library size  Set this option to null to disable optical duplicate                                 detection  The regular expression should contain three capture groups for the three                                 variables  in order  It must match the entire read name  Note that if the default regex                                 is specified  a regex match is not actually done  but instead the read name  is split on                                 colon character  For 5 element names  the 3rd  4th and 5th elements are assumed to be                                 tile  x and y values  For 7 element names  CASAVA 1 8   the 5th  6th  and 7th elements                                 are assumed to be tile  x and y values   Default value                                   a zA Z0 9    0 9    0 9      0 9      0 9          DUPLICATE SCORING STRATEGY ScoringStrategy   DS ScoringStrategy            The scoring strategy for choosing the non duplicate among candidates   Default value                                  TOTAL MAPPED REFERENCE LENGTH  Possible values   SUM OF BASE QUALITIES  TOTAL MAPPED REFERENCE LENGTH     OPTICAL DUPLICATE PIXEL DISTANCE Integer                                 The maximum offset between two duplicte clusters in order to consider them optical                                 duplicates  This should usually be set to some fairly small number  e g  5 10 pixels                                  unless using later versions of the Illumina pipeline that multiply pixel values by 10  in                                 which case 50 100 is more normal   Default value  100    more info     ,picard_MarkDuplicatesWithMateCigar,bam,MarkDuplicatesWithMateCigar,"txt,bam"
586,chart distribution of base qualities,,     class   infomark    Purpose    Program to chart the distribution of base qualities by cycle within reads supplied in a SAM or BAM dataset    dataset collections    description     ALIGNED READS ONLY Boolean    If set to true  calculate the base distribution over aligned reads only   Default value                                  false  Possible values   true  false     PF READS ONLY Boolean         If set to true calculate the base distribution over PF reads only   Default value  false                                  This option can be set to  null  to clear the default value  Possible values   true                                  false     ASSUME SORTED Boolean   AS Boolean                    If true  default   then the sort order in the header file will be ignored   Default  True   more info     ,picard_MeanQualityByCycle,"sam,bam,fasta",MeanQualityByCycle,"tabular,pdf"
587,merge alignment data with additional info stored in an unmapped BAM dataset,,     class   infomark    Purpose    Merges alignment data from a SAM or BAM dataset with additional data stored in an unmapped BAM dataset and produces a third SAM or BAM dataset of aligned and unaligned reads    dataset collections    description     UNMAPPED BAM File   UNMAPPED File                 Original SAM or BAM file of unmapped reads  which must be in queryname order   Required     ALIGNED BAM File   ALIGNED File                  SAM or BAM file s  with alignment data   This option may be specified 0 or more times                                  Cannot be used in conjuction with option s  READ1 ALIGNED BAM  R1 ALIGNED                                  READ2 ALIGNED BAM  R2 ALIGNED     READ1 ALIGNED BAM File   R1 ALIGNED File               SAM or BAM file s  with alignment data from the first read of a pair   This option may be                                 specified 0 or more times   Cannot be used in conjuction with option s  ALIGNED BAM                                  ALIGNED     READ2 ALIGNED BAM File   R2 ALIGNED File               SAM or BAM file s  with alignment data from the second read of a pair   This option may                                 be specified 0 or more times   Cannot be used in conjuction with option s  ALIGNED BAM                                  ALIGNED     PAIRED RUN Boolean   PE Boolean                    This argument is ignored and will be removed   Required  Possible values   true  false     JUMP SIZE Integer   JUMP Integer                  The expected jump size  required if this is a jumping library   Deprecated  Use                                 EXPECTED ORIENTATIONS instead  Default value  null   Cannot be used in conjuction with                                 option s  EXPECTED ORIENTATIONS  ORIENTATIONS     CLIP ADAPTERS Boolean         Whether to clip adapters where identified   Default value  true  Possible values   true  false     IS BISULFITE SEQUENCE Boolean Whether the lane is bisulfite sequence  used when caculating the NM tag    Default value                                  false  Possible values   true  false     ALIGNED READS ONLY Boolean    Whether to output only aligned reads  Default value  false  Possible values   true  false     MAX INSERTIONS OR DELETIONS Integer   MAX GAPS Integer              The maximum number of insertions or deletions permitted for an alignment to be included                                  Alignments with more than this many insertions or deletions will be ignored  Set to  1 to                                 allow any number of insertions or deletions   Default value  1     ATTRIBUTES TO RETAIN String   Reserved alignment attributes  tags starting with X  Y  or Z  that should be brought over                                 from the alignment data when merging   This option may be specified 0 or more times     ATTRIBUTES TO REMOVE String   Attributes from the alignment record that should be removed when merging   This overrides                                 ATTRIBUTES TO RETAIN if they share common tags   This option may be specified 0 or more                                 times     READ1 TRIM Integer   R1 TRIM Integer               The number of bases trimmed from the beginning of read 1 prior to alignment  Default                                 value  0     READ2 TRIM Integer   R2 TRIM Integer               The number of bases trimmed from the beginning of read 2 prior to alignment  Default                                 value  0     EXPECTED ORIENTATIONS PairOrientation   ORIENTATIONS PairOrientation  The expected orientation of proper read pairs  Replaces JUMP SIZE  Possible values   FR                                  RF  TANDEM  This option may be specified 0 or more times   Cannot be used in conjuction                                 with option s  JUMP SIZE  JUMP     ALIGNER PROPER PAIR FLAGS Boolean                                 Use the aligner s idea of what a proper pair is rather than computing in this program                                  Default value  false  Possible values   true  false     SORT ORDER SortOrder   SO SortOrder                  The order in which the merged reads should be output   Default value  coordinate                                  Possible values   unsorted  queryname  coordinate     PRIMARY ALIGNMENT STRATEGY PrimaryAlignmentStrategy                                 Strategy for selecting primary alignment when the aligner has provided more than one                                 alignment for a pair or fragment  and none are marked as primary  more than one is marked                                 as primary  or the primary alignment is filtered out for some reason  BestMapq expects                                 that multiple alignments will be correlated with HI tag  and prefers the pair of                                 alignments with the largest MAPQ  in the absence of a primary selected by the aligner                                  EarliestFragment prefers the alignment which maps the earliest base in the read  Note                                 that EarliestFragment may not be used for paired reads  BestEndMapq is appropriate for                                 cases in which the aligner is not pair aware  and does not output the HI tag  It simply                                 picks the alignment for each end with the highest MAPQ  and makes those alignments                                 primary  regardless of whether the two alignments make sense together MostDistant is also                                 for a non pair aware aligner  and picks the alignment pair with the largest insert size                                  If all alignments would be chimeric  it picks the alignments for each end with the best                                 MAPQ   For all algorithms  ties are resolved arbitrarily   Default value  BestMapq                                  Possible values   BestMapq  EarliestFragment  BestEndMapq  MostDistant     CLIP OVERLAPPING READS BooleanFor paired reads  soft clip the 3  end of each read if necessary so that it does not                                 extend past the 5  end of its mate   Default value  true  Possible values   true  false     INCLUDE SECONDARY ALIGNMENTS Boolean                                 If false  do not write secondary alignments to output   Default value  true                                  Possible values   true  false     ADD MATE CIGAR Boolean   MC Boolean                    Adds the mate CIGAR tag  MC  if true  does not if false  Possible values   true  false       more info    ,picard_MergeBamAlignment,"fasta,sam,bam",MergeBamAlignment,bam
588,merges multiple SAM/BAM datasets into one,,    Purpose    Merges multiple SAM BAM datasets into one    dataset collections    description     ASSUME SORTED Boolean   AS Boolean                    If true  assume that the input files are in the same sort order as the requested output                                 sort order  even if their headers say otherwise   Default value  false  This option can                                 be set to  null  to clear the default value  Possible values   true  false     MERGE SEQUENCE DICTIONARIES Boolean   MSD Boolean                   Merge the sequence dictionaries  Default value  false  This option can be set to  null                                  to clear the default value  Possible values   true  false     COMMENT String   CO String                     Comment s  to include in the merged output file s header   This option may be specified 0                                 or more times     more info     ,picard_MergeSamFiles,"sam,bam",MergeSamFiles,bam
589,normalize fasta datasets,,    Purpose    Takes any dataset that conforms to the fasta format and normalizes it so that all lines of sequence except the last line per named sequence are of the same length    dataset collections    description     LINE LENGTH Integer           The line length to be used for the output fasta file   Default value  100     TRUNCATE SEQUENCE NAMES AT WHITESPACE Boolean                                 Truncate sequence names at first whitespace   Default value  false  Possible values   true  false    more info     ,picard_NormalizeFasta,fasta,NormalizeFasta,fasta
590,chart quality score distribution,,     class   infomark    Purpose    Program to chart quality score distributions in a SAM or BAM dataset    dataset collections    description     ALIGNED READS ONLY Boolean    If set to true  calculate the base distribution over aligned reads only   Default value                                  false  Possible values   true  false     PF READS ONLY Boolean         If set to true calculate the base distribution over PF reads only   Default value  false                                  Possible values   true  false     INCLUDE NO CALLS Boolean      If set to true  include quality for no call bases in the distribution   Default value                                  false  Possible values   true  false     ASSUME SORTED Boolean   AS Boolean                    If true  default   then the sort order in the header file will be ignored   Default  True   more info     ,picard_QualityScoreDistribution,"sam,bam,fasta",QualityScoreDistribution,"tabular,pdf"
591,reorder reads to match ordering in reference sequences,,     class   infomark    Purpose    ReorderSam reorders reads in a SAM BAM file to match the contig ordering in a provided reference file  as determined by exact name matching of contigs   Reads mapped to contigs absent in the new reference are dropped    dataset collections            class   warningmark  Not to be confused with   SortSam      description     ALLOW INCOMPLETE DICT CONCORDANCE Boolean   S Boolean                     If true  then allows only a partial overlap of the BAM contigs with the new reference                                 sequence contigs   By default  this tool requires a corresponding contig in the new                                 reference for each read contig  Default value  false  Possible values   true  false     ALLOW CONTIG LENGTH DISCORDANCE Boolean   U Boolean                     If true  then permits mapping from a read contig to a new reference contig with the same                                 name but a different length   Highly dangerous  only use if you know what you are doing                                  Default value  false   Possible values   true  false    more info    ,picard_ReorderSam,"fasta,sam,bam",ReorderSam,bam
592,replace header in a SAM/BAM dataset,,    Purpose    Replace the SAMFileHeader in a SAM BAM dataset with the given header  Validation is minimal  It is up to the user to ensure that all the elements referred to in the SAMRecords are present in the new header  Sort order of the two input datasets must be the same   dataset collections    description     HEADER File                   SAM file from which SAMFileHeader will be read   Required    more info     ,picard_ReplaceSamHeader,"sam,bam",ReplaceSamHeader,bam
593,revert the original base qualities and add the mate cigar tag,,    Purpose    Reverts the original base qualities and adds the mate cigar tag to SAM or BAMs    dataset collections    description     RESTORE ORIGINAL QUALITIES Boolean   OQ Boolean                    True to restore original qualities from the OQ field to the QUAL field if available                                  Default value  true  Possible values   true  false     MAX RECORDS TO EXAMINE IntegerThe maximum number of records to examine to determine if we can exit early and not                                 output  given that there are a no original base qualities  if we are to restore  and mate                                 cigars exist  Set to 0 to never skip the file   Default value  10000    more info     ,picard_RevertOriginalBaseQualitiesAndAddMateCigar,"sam,bam",RevertOriginalBaseQualitiesAndAddMateCigar,bam
594,revert SAM/BAM datasets to a previous state,,    Purpose    Reverts SAM or BAM files to a previous state by removing certain types of information and or substituting in the original quality scores when available    dataset collections    description     SORT ORDER SortOrder   SO SortOrder                  The sort order to create the reverted output file with   Default value  queryname                                  Possible values   unsorted  queryname  coordinate     RESTORE ORIGINAL QUALITIES Boolean   OQ Boolean                    True to restore original qualities from the OQ field to the QUAL field if available                                  Default value  true  Possible values   true  false     REMOVE DUPLICATE INFORMATION Boolean                                 Remove duplicate read flags from all reads   Note that if this is true and                                 REMOVE ALIGNMENT INFORMATION  false   the output may have the unusual but sometimes                                 desirable trait of having unmapped reads that are marked as duplicates   Default value                                  true  Possible values   true  false     REMOVE ALIGNMENT INFORMATION Boolean                                 Remove all alignment information from the file   Default value  true  TPossible values   true  false     ATTRIBUTE TO CLEAR String     When removing alignment information  the set of optional tags to remove   This option may                                 be specified 0 or more times     SANITIZE Boolean              WARNING  This option is potentially destructive  If enabled will discard reads in order                                 to produce a consistent output BAM  Reads discarded include  but are not limited to                                  paired reads with missing mates  duplicated records  records with mismatches in length of                                 bases and qualities  This option can only be enabled if the output sort order is                                 queryname and will always cause sorting to occur   Possible values   true  false     MAX DISCARD FRACTION Double   If SANITIZE true and higher than MAX DISCARD FRACTION reads are discarded due to                                 sanitization thenthe program will exit with an Exception instead of exiting cleanly                                  Output BAM will still be valid   Default value  0 01     SAMPLE ALIAS String   ALIAS String                  The sample alias to use in the reverted output file   This will override the existing                                 sample alias in the file and is used only if all the read groups in the input file have                                 the same sample alias   Default value  null     LIBRARY NAME String   LIB String                    The library name to use in the reverted output file   This will override the existing                                 sample alias in the file and is used only if all the read groups in the input file have                                 the same sample alias   Default value  null    more info     ,picard_RevertSam,"sam,bam",RevertSam,bam
595,extract reads and qualities from SAM/BAM dataset and convert to fastq,,    Purpose    Extracts read sequences and qualities from the input SAM BAM dataset and outputs them in Sanger fastq format  In the RE REVERSE True mode  default behavior   if the read is aligned and the alignment is to the reverse strand on the genome  the read s sequence from input SAM BAM dataset will be reverse complemented prior to writing it to fastq in order restore correctly the original read sequence as it was generated by the sequencer             class   warningmark    DANGER  Multiple Outputs    Generating per readgroup fastq  setting   OUTPUT PER RG   to True  may produce very large numbers of outputs  Know what you are doing    dataset collections    description     FASTQ File   F File                        Output fastq file  single end fastq or  if paired  first end of the pair fastq                                   Required   Cannot be used in conjuction with option s  OUTPUT PER RG  OPRG     SECOND END FASTQ File   F2 File                       Output fastq file  if paired  second end of the pair fastq    Default value  null                                  Cannot be used in conjuction with option s  OUTPUT PER RG  OPRG     UNPAIRED FASTQ File   FU File                       Output fastq file for unpaired reads  may only be provided in paired fastq mode  Default                                 value  null   Cannot be used in conjuction with option s  OUTPUT PER RG  OPRG     OUTPUT PER RG Boolean   OPRG Boolean                  Output a fastq file per read group  two fastq files per read group if the group is                                 paired    Default value  false  Possible values   true  false   Cannot be used in                                 conjuction with option s  SECOND END FASTQ  F2  UNPAIRED FASTQ  FU  FASTQ  F     OUTPUT DIR File   ODIR File                     Directory in which to output the fastq file s    Used only when OUTPUT PER RG is true                                  Default value  null     RE REVERSE Boolean   RC Boolean                    Re reverse bases and qualities of reads with negative strand flag set before writing them                                 to fastq  Default value  true  Possible values   true  false     INTERLEAVE Boolean   INTER Boolean                 Will generate an interleaved fastq if paired  each line will have  1 or  2 to describe                                 which end it came from  Default value  false  Possible values   true  false     INCLUDE NON PF READS Boolean   NON PF Boolean                Include non PF reads from the SAM file into the output FASTQ files  PF means  passes                                 filtering   Reads whose  not passing quality controls  flag is set are non PF reads                                  Default value  false  Possible values   true  false     CLIPPING ATTRIBUTE String   CLIP ATTR String              The attribute that stores the position at which the SAM record should be clipped  Default                                 value  null     CLIPPING ACTION String   CLIP ACT String               The action that should be taken with clipped reads   X  means the reads and qualities                                 should be trimmed at the clipped position   N  means the bases should be changed to Ns in                                 the clipped region  and any integer means that the base qualities should be set to that                                 value in the clipped region   Default value  null     READ1 TRIM Integer   R1 TRIM Integer               The number of bases to trim from the beginning of read 1   Default value  0     READ1 MAX BASES TO WRITE Integer   R1 MAX BASES Integer          The maximum number of bases to write from read 1 after trimming  If there are fewer than                                 this many bases left after trimming  all will be written   If this value is null then all                                 bases left after trimming will be written   Default value  null     READ2 TRIM Integer   R2 TRIM Integer               The number of bases to trim from the beginning of read 2   Default value  0     READ2 MAX BASES TO WRITE Integer   R2 MAX BASES Integer          The maximum number of bases to write from read 2 after trimming  If there are fewer than                                 this many bases left after trimming  all will be written   If this value is null then all                                 bases left after trimming will be written   Default value  null     INCLUDE NON PRIMARY ALIGNMENTS Boolean                                 If true  include non primary alignments in the output   Support of non primary alignments                                 in SamToFastq is not comprehensive  so there may be exceptions if this is set to true and                                 there are paired reads with non primary alignments   Default value  false                                  Possible values   true  false    more info     ,picard_SamToFastq,"sam,bam",SamToFastq,txt
596,sort SAM/BAM dataset,,     class   infomark    Purpose    Sorts the input SAM or BAM    dataset collections    description     SORT ORDER SortOrder   SO SortOrder          Sort order of output file  You can either sort by queryname or by coordinate     more info     ,picard_SortSam,"sam,bam",SortSam,bam
597,assess validity of SAM/BAM dataset,,    Purpose    Reads a SAM BAM dataset and report on its validity    dataset collections    description     MODE Mode   M Mode                        Mode of output  Default value  VERBOSE  This option can be set to  null  to clear the                                 default value  Possible values   VERBOSE  SUMMARY     IGNORE Type                   List of validation error types to ignore   Possible values   INVALID QUALITY FORMAT                                  INVALID FLAG PROPER PAIR  INVALID FLAG MATE UNMAPPED  MISMATCH FLAG MATE UNMAPPED                                  INVALID FLAG MATE NEG STRAND  MISMATCH FLAG MATE NEG STRAND  INVALID FLAG FIRST OF PAIR                                  INVALID FLAG SECOND OF PAIR  PAIRED READ NOT MARKED AS FIRST OR SECOND                                  INVALID FLAG NOT PRIM ALIGNMENT  INVALID FLAG SUPPLEMENTARY ALIGNMENT                                  INVALID FLAG READ UNMAPPED  INVALID INSERT SIZE  INVALID MAPPING QUALITY  INVALID CIGAR                                  ADJACENT INDEL IN CIGAR  INVALID MATE REF INDEX  MISMATCH MATE REF INDEX                                  INVALID REFERENCE INDEX  INVALID ALIGNMENT START  MISMATCH MATE ALIGNMENT START                                  MATE FIELD MISMATCH  INVALID TAG NM  MISSING TAG NM  MISSING HEADER                                  MISSING SEQUENCE DICTIONARY  MISSING READ GROUP  RECORD OUT OF ORDER                                  READ GROUP NOT FOUND  RECORD MISSING READ GROUP  INVALID INDEXING BIN                                  MISSING VERSION NUMBER  INVALID VERSION NUMBER  TRUNCATED FILE                                  MISMATCH READ LENGTH AND QUALS LENGTH  EMPTY READ  CIGAR MAPS OFF REFERENCE                                  MISMATCH READ LENGTH AND E2 LENGTH  MISMATCH READ LENGTH AND U2 LENGTH                                  E2 BASE EQUALS PRIMARY BASE  BAM FILE MISSING TERMINATOR BLOCK  UNRECOGNIZED HEADER TYPE                                  POORLY FORMATTED HEADER TAG  HEADER TAG MULTIPLY DEFINED                                  HEADER RECORD MISSING REQUIRED TAG  INVALID DATE STRING  TAG VALUE TOO LARGE                                  INVALID INDEX FILE POINTER  INVALID PREDICTED MEDIAN INSERT SIZE                                  DUPLICATE READ GROUP ID  MISSING PLATFORM VALUE  INVALID PLATFORM VALUE                                  DUPLICATE PROGRAM GROUP ID  MATE NOT FOUND  MATES ARE SAME END                                  MISMATCH MATE CIGAR STRING  MATE CIGAR STRING INVALID PRESENCE  This option may be                                 specified 0 or more times     MAX OUTPUT Integer   MO Integer                    The maximum number of lines output in verbose mode  Default value  100  This option can                                 be set to  null  to clear the default value     REFERENCE SEQUENCE File   R File                        Reference sequence file  the NM tag check will be skipped if this is missing  Default                                 value  null     IGNORE WARNINGS Boolean       If true  only report errors and ignore warnings   Default value  false  This option can                                 be set to  null  to clear the default value  Possible values   true  false     VALIDATE INDEX Boolean        If true and input is a BAM file with an index file  also validates the index   Default                                 value  true  This option can be set to  null  to clear the default value  Possible                                 values   true  false     IS BISULFITE SEQUENCED Boolean   BISULFITE Boolean             Whether the SAM or BAM file consists of bisulfite sequenced reads  If so  C  T is not                                 counted as an error in computing the value of the NM tag   Default value  false  This                                 option can be set to  null  to clear the default value  Possible values   true  false    more info     ,picard_ValidateSamFile,"sam,bam,fasta",ValidateSamFile,txt
598,by collapsing hierarchical data to a specified functional level,,   PICRUST OVERVIEW     Command Documentation    This module collapses hierarchical data to a specified level for PICRUSt predictions  For instance  often it is useful to examine KEGG results from a higher level within the pathway hierarchy  Many genes are sometimes involved in multiple pathways  and in these circumstances  also know as a one to many relationship   the gene is counted for each pathway     Input file    Output file from the predict tool       ,picrust_categorize,"biom1,h5",Categorize,
599,Compare the accuracy of biom files (expected and observed) either by observations (default) or by samples.,,   PICRUST OVERVIEW     Command Documentation    Compare an observed table to an expected table using either relative abundance or real counts     Input files       Observed table    A table of observed relative abundances or real counts in  biom format     Expected table    The expected table of relative abundances or real counts in  biom format     Output file    Tab delimited file with various accuracy metrics     Optional Parameters      compare observations       Calculate accuracy values by comparing between observations  instead of between samples   default  False    normalize       Convert both expected and observed tables to relative abundances  instead of observations   default  False    limit to expected observations       Ignore observations that are not in the expected table default  False    limit to observed observations       Ignore observations that are not in the observed table default  False    shuffle samples       Shuffle samples ids randomly before measuring accuracy default  False    not relative abundance scores       Round numbers  instead of taking ceil   which is used for RA  before calculating TP FP FN TN  default  False        ,picrust_compare_biom,biom1,Compare BIOM tables,tabular
600,tree and trait tables,,   PICRUST OVERVIEW     Command Documenation    This module does numerous formatting and checks to the reference tree and the trait tables  The following steps are done for both the marker gene copy number table and functional trait copy number table   1  All internal nodes in the reference tree are checked for problematic characters and unlabelled internal nodes are given labels  2  A pruned tree is created that contains only tips that have copy number predictions from sequenced genomes  3  Any traits in the trait table that are not in the reference tree are removed   Optional fixes include     Add short  epsilon  branch lengths in place of 0 length branches   Filter out taxa that don t match between tree and trait table   Output tree in NEXUS format   Ensure tree is bifurcating  remove polytomies using very short branches    Convert floating point trait values to integers   Add a short branch length to the root branch  required by BayesTraits    Remove internal node names  required by BayesTraits   Three output files are produced     a reference tree Newick file   a pruned tree Newick file   a trait table file       ,picrust_format_tree_and_trait_table,"tabular,txt,csv,nhx,tabular",Format,"nhx,tabular"
601,of OTUs to user-specified functions,,   PICRUST OVERVIEW     Command Documenation    This module outputs the relative contribution of OTUs to the predicted abundances of functions in your samples  The input biom file should be the output of normalize by copy number  One output text file will be generated   Make sure that you specify an appropriate functional database for this command  usually the ko  cog  or rfam v13 5 database         ,picrust_metagenome_contributions,"biom1,h5",Metagenome Contributions,tabular
602,the relative abundance of each OTU by the predicted number of 16S copies,,   PICRUST OVERVIEW     Command Documenation    This module corrects the abundance of each OTU to better reflect the true organism abundance by normalizing by PICRUSt s prediction of 16S copy number for each OTU   Please ensure that you have properly created your OTU table to be compatible with PICRUSt by following this guide   A sample file can be downloaded here   Make sure that you specify an appropriate 16S database for this command  usually 16S 13 5        guide       here        ,picrust_normalize_by_copy_number,"biom1,h5",Normalize,
603,based on the abundance of OTUs and a functional database,,   PICRUST OVERVIEW     Command Documentation    This module produces a  virtual  metagenome of functional abundances for each sample in the given OTU table  Choose either the KEGG Ortholog  KO   Clusters of Orthologous Genes  COG   or non coding and other structured RNA  Rfam  precalculated files     Input file    This should be a normalized OTU table populated by the output of the PICRUSt Normalize by Copy Number module   Make sure that you specify an appropriate functional database for this command  usually the ko  cog  or rfam v13 5 database         ,picrust_predict_metagenomes,"biom1,h5",Predict Metagenome,tabular
604,An automated genome assembly improvement and variant detection tool,,   Pilon is a software tool which can be used to       Automatically improve draft assemblies      Find variation among strains  including large event detection    Pilon requires as input a FASTA file of the genome along with one or more BAM files of reads aligned to the input FASTA file  Pilon uses read alignment analysis to identify inconsistencies between the input genome and the evidence in the reads  It then attempts to make improvements to the input genome  including       Single base differences      Small indels      Larger indel or block substitution events      Gap filling      Identification of local misassemblies  including optional opening of new gaps    Pilon then outputs a FASTA file containing an improved representation of the genome from the read data and an optional VCF file detailing variation seen between the read data and the input genome     To aid manual inspection and improvement by an analyst  Pilon can optionally produce tracks that can be displayed in genome viewers such as IGV and GenomeView  and it reports other events  such as possible large collapsed repeat regions  in its standard output     Note on   mindepth       Variants  snps and indels  will only be called if there is coverage of good pairs   at the value set for  mindepth  depth or more  if this value is    1  it is an absolute depth  if it is a   fraction   1  then minimum depth is computed by multiplying this value by the mean   coverage for the region  with a minumum value of 5  default 0 1  min depth to call   is 10  of mean coverage or 5  whichever is greater      Note on   stray read filtering      By default a pass is made through the input BAM files to identify stray pairs  that is    those pairs in which both reads are aligned but not marked valid because they have   inconsistent orientation or separation  Identifying stray pairs can help fill gaps   and assemble larger insertions  especially of repeat content   However  doing so   sometimes consumes considerable memory      ,pilon,"fasta,bam",pilon,"vcf,txt,fasta"
605,- fast fusion detection using kallisto,,pizzly  is a program for detecting gene fusions from RNA Seq data of cancer samples ,pizzly,"tabular,fasta,gtf",pizzly,"tabular,fasta"
606,from a set of sequencing reads,,         Extract the raw nanopore events from each FAST5 file      ,poretools_events,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Extract nanopore events,tabular
607,in FASTA or FASTQ format from nanopore files,,         Extract sequences from fast5 files generated by the Oxford Nanopore sequencing technology      ,poretools_extract,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Extract reads,fastq
608,of nanopore read lengths,,         Draw a histogram of read lengths in one or more nanopore reads      ,poretools_hist,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Generate histogram,
609,distribution in nanopore sequencing reads,,         Get the nucleotide composition of a set of FAST5 files      ,poretools_nucdist,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Show nucleotide,tabular
610,per cell in nanopore reads,,         Plot the throughput performance of each pore on the flowcell during a given sequencing run      ,poretools_occupancy,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Plot performance,
611,score distribution in nanopore sequencing reads,,         Get the the quality score composition of a set of FAST5 files      ,poretools_qualdist,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Show quality,tabular
612,plot of quality score distribution over positions in nanopore reads,,         Produce a box whisker plot of quality score distribution over positions in nanopore reads     ,poretools_qualpos,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Generate box-whisker,
613,for nanopore reads,,         Plot the observed signals for FAST5 reads      ,poretools_squiggle,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Plot signals,txt
614,from a set of FAST5 files,,         Collect read size statistics from a set of FAST5 files      ,poretools_stats,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Read length statistics,tabular
615,in tabular format from a set of FAST5 files,,         Dump the length  name  sequence  and quality scores of the sequence in one or a set of FAST5 files      ,poretools_tabular,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Extract FASTQ,tabular
616,and channel information from a set of FAST5 files,,         Collect read size statistics from a set of FAST5 files      ,poretools_times,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Extract time,tabular
617,from a set of FAST5 files.,,         Report the longest read among a set of FAST5 files      ,poretools_winner,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Get longest read,tabular
618,of sequencing yield over time,,         Create a collector s curve reflecting the sequencing yield over time      ,poretools_yield_plot,"h5,fast5.tar,fast5.tar.gz,fast5.tar.bz2",Collector’s curve,
619,to process quality of sequences,,PRINSEQ is a tool for easy and rapid quality control and data processing of metagenomic and metatranscriptomic datasets  This tool allow to process the sequences with filtering and trimming  More information on  PRINSEQ manual     ,prinseq,"fastqsanger,fastqillumina,fastq",PRINSEQ,
620,constructs multiple genome alignments,,Mauve is a system for efficiently constructing multiple genome alignments in the presence of large scale evolutionary events such as rearrangement and inversion  Multiple genome alignment provides a basis for research into comparative genomics and the study of evolutionary dynamics  Aligning whole genomes is a fundamentally different problem than aligning short sequences ,progressivemauve,"fasta,xmfa,tabular,nhx",progressiveMauve,"xmfa,nhx,tabular"
621,,,XMFA Alignments are great  but now you need a way to visualize this data ,xmfa2gff3,"xmfa,fasta",Convert XMFA to gapped GFF3,gff3
622,prokaryotic genome annotation,,Prokka  is a software tool to rapidly annotate bacterial  archaeal and viral genomes  and produce output files that require only minor tweaking to submit to GenBank ENA DDBJ ,prokka,fasta,Prokka,"gff,txt,fasta,asn1"
623,Genome assembly Quality,,    Description    Galaxy tool wrapper for the QUAST tool  Quast stands for QUality ASsessment Tool  It evaluates genome assemblies by computing various metrics            Inputs and Outputs      Input        The tool accepts assemblies and references in FASTA format        The tool accepts annotation and operon files in            GFF  versions 2 and 3  note  feature type field should be either  gene  or  operon             the format used by NCBI for genes   Summary  text               four tab separated columns  sequence name  gene operon id  start position  end position    Output        An assessment summary in plain text format       An assessment summary in tabulation separated values format       An assessment summary in LateX format       An assessment summary in HTML format       An HTML view of contig sizes wit Icarus            ,quast,"fasta,txt",Quast,"txt,tsv,tex,html"
624,,,                Filter Tabular                   Filter a tabular dataset by applying line filters as it is being read    Multiple filters may be used with each filter using the result of the previous filter       Inputs      A tabular dataset      Outputs      A filtered tabular dataset     LINEFILTERS HELP    LINEFILTERS HELP EXAMPLE       ,filter_tabular,tabular,Filter Tabular,tabular
625,using sqlite sql,,               Query Tabular                  Inputs      Loads tabular datasets into a SQLite  data base       An existing SQLite  data base can be used as input  and any selected tabular datasets will be added as new tables in that data base     LINEFILTERS HELP     Table Options      Specify Name for Table         By default tables will be named  t1  t2  t3  etc            Specify Name for Table          You can provide your own name for a database table  the name should begin with a letter and only contain letters  digits  or underscores         The name should not be a SQLite key word       There are several ways to name columns in a table           By default table columns will be named  c1  c2  c3  etc         If   Use first line as column names   is selected  the first line is interpreted as column names  and not loaded into the table as a data row          Any missing column name will be assigned cn where  n  is the ordinal position of the column         e g  a blank header for the second column would be named  c2        The column names will be quoted is they are not valid identifiers         e g  if they are SQLite keywords  or start with a non letter character  or contain a character other than a letter  digit  or underscore        The precedent for quoting is to enclose the identifier in double quotes         else if it contains a double quote enclose in square brackets        else if it contains a square bracket enclose in grave accents          NOTE    that this is the first line after line filtering has been applied         If a line filter  prepend a line number column  had been used  the name of the first column would be  1         You could rename that column using   Specify Column Names            Specify Column Names    comma separated list        This will override any previously assigned column names         You can also choose to only load those columns for which you provided a name         but that is better accomplished with the line filter   select columns          Table Index        Queries on larger tables can be much faster if indexes are specified        In general  specifiy an index for table columns used in joins with other tables       or on columns used in SQL query WHERE clauses or in GROUP BY clauses      Outputs      The results of a SQL query are output to the history as a tabular file     The SQLite  data base can also be saved and output as a dataset in the history           The    SQLite to tabular    tool can run additional queries on this database       QUERY HELP    LINEFILTERS HELP EXAMPLE      Table name  pets    Table columns  Pets FirstName LastName Birthdate PetNames PetType line num entry num row num    Query  SELECT   FROM pets     Result                                                                                                             Pets   FirstName   LastName  BirthDate   PetNames   PetType   line num   entry num    row num                                                                                                          2       Paula       Brown     1978 05 24  Rex        dog              3           1         1      2       Paula       Brown     1978 05 24  Fluff      cat              3           1         2      1       Steven      Jones     1974 04 04  Allie      cat              4           2         3      0       Jane        Doe       1978 05 24                              5           3         4      1       James       Smith     1980 10 20  Spot                        6           4         5                                                                                                                    Normalizing by Line Filtering into 2 Tables      Relational database opertions work with single valued column entries    To apply relational operations to tabular files that contain fields with lists of values  we need to  normalize  those fields  duplicating lines for each item in the list    In this example we create 2 tables  one for single valued fields and a second with list valued fields normalized    Becauce we add a line number first for each table  we can join the 2 tables on the line number column           People Table                       Filter 1   by regex expression matching  include      d    include lines that start with a number           Filter 2   append a line number column          Filter 3   regex replace value in column 4      d     d     d     19 3  2  1   convert dates to sqlite format           Filter 4   select columns 7 2 3 4 1        Table  People       Columns  id FirstName LastName DOB Pets                                                         id  FirstName  LastName   DOB         Pets                                                        1     Paula      Brown    1978 05 24  2       2     Steven     Jones    1974 04 04  1       3     Jane       Doe      1978 05 24  0       4     James      Smith    1980 10 20  1                                                         Pet Table                      Filter 1   by regex expression matching  include      d    include lines that start with a number           Filter 2   append a line number column          Filter 3   by regex expression matching  exclude     0 t   exclude lines with no pets          Filter 4   normalize list columns 5 6           Filter 5   select columns 7 5 6        Table  Pet       Columns  id PetName PetType                                     id  PetName   PetType                                     1   Rex       dog            1   Fluff     cat            2   Allie     cat            4   Spot                                                  Query  SELECT FirstName LastName PetName FROM People JOIN Pet ON People id   Pet id WHERE PetType    cat             Result                                           FirstName  LastName  PetName                                          Paula      Brown     Fluff         Steven     Jones     Allie                                             ,query_tabular,"sqlite,tabular",Query Tabular,"sqlite,tabular"
626,for SQL query,,                   SQLite to Tabular                      Inputs      An existing SQLite  data base      Outputs      The results of a SQL query are output to the history as a tabular file      QUERY HELP       ,sqlite_to_tabular,sqlite,SQLite to tabular,tabular
627,- Maximum Likelihood based inference of large phylogenetic trees,, RAxML   Randomized Axelerated Maximum Likelihood  is a program for Maximum Likelihood based inference of large phylogenetic trees  The program is explicitly being developed to efficiently infer trees for extremely large datasets  either in terms of the number of taxa and or the sequence length       RAxML      Tool development     Oleksandr Moskalenko with adaptations from Tiago Antao      ,raxml,"fasta,phylip,txt,nhx",Phyogenetic reconstruction with RaXML,"txt,nhx"
628,Match paired peaks from two or more replicates,,RepMatch accepts two or more input datasets  and starts by defining peak pair midpoints in the first dataset   It then discovers all peak pair midpoints in the second dataset that are within the distance  defined by the tool s   Maximum distance between peaks in different replicates to allow merging   parameter  from the peak pair midpoint coordinate in the first dataset   When encountering multiple candidates to match  one to many   RepMatch uses the method defined by the tool s   Method of finding match   parameter so that there is at most only a one to one match across the two datasets  This method provides the following options ,repmatch_gff3,gff,RepMatch,"tabular,pdf,gff"
629,expand combinations of variables:values to columnar format,, This tool will apply the dcast function of the reshape2 R package  The input data should be in a  long  format or molten by the melt tool  The output will be in a wide format  The cast function expands each unique variable value combination on a single line to columnar format  Documantation on the reshape2 package can be found here       ,cast,tabular,cast,tabular
630,collapse combinations of variables:values to single lines,, This tool will apply the melt function of the reshape2 R package    The melt function summarizes each unique variable value combination on a single line  An example can be found here        ,melt,tabular,melt,tabular
631,of GFF data,,Modifies the start and end coordinates of GFF data such that the new start and end position is based on a specified region size that is computed either from the existing start and end coordinates or centered on the midpoint between them ,resize_coordinate_window,gff,Resize coordinate window,gff
632,Gapped-read mapper for RNA-seq data,,STAR is an ultrafast universal RNA seq aligner ,rna_star,"fastq,fasta,fastq.gz,fastqsanger.gz,fasta",RNA STAR,"txt,interval,bam,tabular"
633,assembler for RNA-Seq data,,SPAdes   St  Petersburg genome assembler   is intended for both standard isolates and single cell MDA bacteria assemblies  See  for more details on SPAdes ,rnaspades,"fastq,fasta,fastq",rnaSPAdes,fasta
634,the pangenome pipeline - Quickly generate a core gene alignment from gff3 files,,   Roary    Roary is a high speed stand alone pan genome pipeline  which takes annotated assemblies in GFF3 format  produced by Prokka  and calculates the pan genome  Using a standard desktop PC  it can analyse datasets with thousands of samples  something which is computationally infeasible with existing methods  without compromising the quality of the results  128 samples can be analysed in under 1 hour using 1 GB of RAM and a single processor  To perform this analysis using existing methods would take weeks and hundreds of GB of RAM   To use Roary  select two or more gff3 files OR a collection of gff3 files    Options                Minimum percentage identity for blastp   an integer  default is  95                    Percentage of isolates a gene must be in to be core   a float  default is  99 0                    Advanced Options                     Maximum number of clusters   integer  default is  50000                    Don t split paralogs   check box                   Translation table   which translation table to use  an integer  default is  11                    Change the MCL inflation value   a float  default is  1 5           For further info see            ,roary,gff3,Roary,"tabular,fasta,csv,nhx,dot,embl,txt"
635,"calculates raw read count, FPM, and FPKM for each gene",, FPKM count py                Given a BAM file and reference gene model  this program will calculate the raw read count  FPM  fragments per million   and FPKM  fragments per million mapped reads per kilobase exon  for each gene in a BED file  For strand specific RNA seq data  program will assign read to its parental gene according to strand rule  if you don t know the strand rule  run infer experiment py  Please note that chromosome ID  genome cooridinates should be concordant between BAM and BED files   Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Strand sequencing type  default none      See Infer Experiment tool if uncertain   Options                 Skip Multiple Hit Reads     Use Multiple hit reads or use only uniquely mapped reads   Minimum mapping quality     Minimum mapping quality  phred scaled  for an alignment to be called      uniquely mapped   default 30  Only use exonic reads     Renders program only used exonic  UTR exons and CDS exons  reads      otherwise use all reads   Single Reads     How to count read pairs that only have one end mapped  0  ignore it  0 5      treat it as half fragment  1  treat it as whole fragment  default 1  Sample Output                                                                                                                          chrom  st         end        accession  mRNA size  gene strand  Frag count  FPM           FPKM                                                                                                         chr1    100652477  100715409  NM 001918  10815 0                 5498 0      191 73788949  17 728884835 chr1    175913961  176176380  NM 022457  2789 0                  923 0       32 188809021  11 541344217 chr1    150980972  151008189  NM 021222  2977 0                  687 0       23 958517657  8 0478729115 chr1    6281252    6296044    NM 012405  4815 0                  1396 0      48 684265866  10 11095864 chr1    20959947   20978004   NM 032409  2660 0                  509 0       17 750925018  6 6732800821 chr1    32479294   32509482   NM 006559  2891 0                  2151 0      75 014223408  25 947500314                                                                                                           ABOUT        ,rseqc_FPKM_count,,FPKM Count,xls
636,"
     calculates the fragment size for each gene/transcript
    ",, RNA fragment size py                       Calculate fragment size for each gene transcript  For each transcript  it will report   1  Number of fragment that was used to estimate mean  median  std  see below   2  mean of fragment size 3  median of fragment size 4  stdev of fragment size   Inputs         Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Reference gene model in BED format  Must be strandard 12 column BED file       required   Minimum mapping quality     Minimum mapping quality for an alignment to be considered as  uniquely     mapped   default 30  Minimum number of fragments     Minimum number of fragments  default 3   ABOUT         ,rseqc_RNA_fragment_size,,RNA fragment size,tabular
637,"calculates raw count and RPKM values for transcript at exon, intron, and mRNA level",, RPKM saturation py                     The precision of any sample statitics  RPKM  is affected by sample size  sequencing depth     resampling   or   jackknifing   is a method to estimate the precision of sample statistics by using subsets of available data  This module will resample a series of subsets from total RNA reads and then calculate RPKM value using each subset  By doing this we are able to check if the current sequencing depth was saturated or not  or if the RPKM values were stable or not  in terms of genes  expression estimation  If sequencing depth was saturated  the estimated RPKM value will be stationary or reproducible  By default  this module will calculate 20 RPKM values  using 5   10         95  100  of total reads  for each transcripts   In the output figure  Y axis is  Percent Relative Error  or  Percent Error  which is used to measures how the RPKM estimated from subset of reads  i e  RPKMobs  deviates from real expression level  i e  RPKMreal   However  in practice one cannot know the RPKMreal  As a proxy  we use the RPKM estimated from total reads to approximate RPKMreal      image    PATH TO IMAGES RelativeError png     height  80 px     width  400 px     scale  100    Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Strand sequencing type  default none      See Infer Experiment tool if uncertain   Options                 Skip Multiple Hit Reads     Use Multiple hit reads or use only uniquely mapped reads   Only use exonic reads     Renders program only used exonic  UTR exons and CDS exons  reads  otherwise use all reads   Output                 1  output  eRPKM xls  RPKM values for each transcript 2  output rawCount xls  Raw count for each transcript 3  output saturation r  R script to generate plot 4  output saturation pdf      image    PATH TO IMAGES saturation png     height  600 px     width  600 px     scale  80      All transcripts were sorted in ascending order according to expression level  RPKM   Then they are divided into 4 groups      1  Q1  0 25    Transcripts with expression level ranked below 25 percentile      2  Q2  25 50    Transcripts with expression level ranked between 25 percentile and 50 percentile      3  Q3  50 75    Transcripts with expression level ranked between 50 percentile and 75 percentile      4  Q4  75 100    Transcripts with expression level ranked above 75 percentile    BAM SAM file containing more than 100 million alignments will make module very slow    Follow example below to visualize a particular transcript  using R console         pdf  xxx pdf        starts the graphics device driver for producing PDF graphics     x  lt   seq 5 100 5    resampling percentage  5 10 15     100      rpkm  lt   c 32 95 35 43 35 15 36 04 36 41 37 76 38 96 38 62 37 81 38 14 37 97 38 58 38 59 38 54 38 67  38 67 38 87 38 68   38 42   38 23    Paste RPKM values calculated from each subsets     scatter smooth x 100 abs rpkm rpkm length rpkm     rpkm length rpkm    type  p  ylab  Precent Relative Error  xlab  Resampling Percentage       dev off             close graphical device     image    PATH TO IMAGES saturation eg png     height  600 px     width  600 px     scale  80     ABOUT        ,rseqc_RPKM_saturation,,RPKM Saturation,xls
638,"
        converts all types of RNA-seq data from .bam to .wig
    ",, bam2wig py             Visualization is the most straightforward and effective way to QC your RNA seq data  For example  change of expression or new splicing can be easily checked by visually comparing two RNA seq tracks using genome browser such as UCSC   IGB  and IGV     bam2wig py  converts all types of RNA seq data from BAM  format into wiggle  format in one stop   wiggle  files can then be easily converted into bigwig    Bigwig is indexed  binary format of wiggle file  and it s particular useful to display large  continuous dataset on genome browser   Inputs                 Input BAM file     Alignment file in BAM format  SAM is not supported   BAM file will be sorted and indexed using samTools   Chromosome size file     Tab or space separated text file with 2 columns  first column is chromosome name  second column is size of the chromosome  Chromosome names  such as  chr1   should be consistent between this file and BAM file   Specified wigsum  default none      Specified wigsum  Wigsum of 100000000 equals to coverage achieved by 1 million 100nt reads  Ignore this option to disable normalization   Skip multiple Hit reads     skips multiple hit reads or only use uniquely mapped reads  Strand specific  default none      How read s  were stranded during sequencing  If you are not sure about the strand rule  run infer experiment py  Outputs                 If RNA seq is not strand specific  one wig file will be generated  if RNA seq is strand specific  two wig files corresponding to Forward and Reverse will be generated    ABOUT       UCSC       IGB       IGV       BAM       wiggle       bigwig   format6 1      ,rseqc_bam2wig,"txt,tabular",BAM to Wiggle,wig
639,"
        reads mapping statistics for a provided BAM or SAM file.
    ",, bam stat py              This program is used to calculate reads mapping statistics from provided BAM file   This script determines  uniquely mapped reads  from  mapping quality      which quality the probability that a read is misplaced  Do NOT confused with sequence quality  sequence quality measures the probability that a base calling was wrong     Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Minimum mapping quality     Minimum mapping quality for an alignment to be called  uniquely mapped   default 30   Output                   Total Reads  Total records     Multiple mapped reads     Uniquely mapped    Uniquely mapped Reads    read 1     read 2   if paired end    Uniquely mapped Reads    Reads map to         Reads map to        Uniquely mapped Reads    Splice reads     Non splice reads    ABOUT        ,rseqc_bam_stat,,BAM/SAM Mapping Stats,txt
640,"
     estimates clipping profile of RNA-seq reads from BAM or SAM file
    ",, clipping profile py                      This program is used to estimate clipping profile of RNA seq reads from BAM or SAM file  Note that to use this funciton  CIGAR strings within SAM BAM file should have  S  operation  This means your reads aligner should support clipped mapping    Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Minimum mapping quality     Minimum mapping quality for an alignment to be considered as  uniquely     mapped   default 30  Sequencing layout     Denotes whether the sequecing was single end  SE  or paired end  PE    Sample Output                    image    PATH TO IMAGES clipping good png     height  600 px     width  600 px     scale  80     ABOUT        ,rseqc_clipping_profile,,Clipping Profile,
641,"
     calculates the distributions of deleted nucleotides across reads
    ",, deletion profile py                      Calculate the distributions of deleted nucleotides across reads   Inputs         Input BAM SAM file     Alignment file in BAM SAM format   Alignment length of read     It is usually set to the orignial read length  For example  all these cigar     strings   101M    68M140N33M    53M1D48M   suggest the read alignment     length is 101   required   Number of aligned reads used     Number of aligned reads with deletions used to calculate the deletion     profile  default 1000000  Minimum mapping quality     Minimum mapping quality for an alignment to be considered as  uniquely     mapped   default 30  Sample Output                    image    PATH TO IMAGES out deletion profile png     height  600 px     width  600 px     scale  80     ABOUT         ,rseqc_deletion_profile,,Deletion Profile,
642,"
    Read coverage over gene body.
  ",,    geneBody coverage py  Read coverage over gene body  This module is used to check if read coverage is uniform and if there is any 5   3   bias  This module scales all transcripts to 100 nt and calculates the number of reads covering each nucleotide position  Finally  it generates plots illustrating the coverage profile along the gene body   If 3 or more BAM files were provided  This program generates a lineGraph and a heatmap  If fewer than 3 BAM files were provided  only lineGraph is generated  See below for examples   When heatmap is generated  samples are ranked by the  skewness  of the coverage  Sample with best  worst  coverage will be displayed at the top  bottom  of the heatmap  Coverage skewness was measured by  Pearson s skewness coefficients   Pearson 27s skewness coefficients        image    PATH TO IMAGES geneBody workflow png      width  800 px      scale  80        Inputs  Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene Model in BED format   Minimum mRNA length     Minimum mRNA length  bp   mRNA that are shorter than this value will be skipped  default is 100       Outputs  Text     Table that includes the data used to generate the plots  R Script     R script file that reads the data and generates the plot  PDF     The final plot  in PDF format  Example plots     image    PATH TO IMAGES Aug 26 geneBodyCoverage curves png  height  600 px  width  600 px  scale  80       image    PATH TO IMAGES Aug 26 geneBodyCoverage heatMap png      height  600 px      width  600 px      scale  80     ABOUT          ,rseqc_geneBody_coverage,bam,Gene Body Converage (BAM),"pdf,txt"
643,"
        Read coverage over gene body
    ",, geneBody coverage2 py                        Similar to geneBody coverage py  This module takes bigwig instead of BAM as input  and thus requires much less memory  The BigWig file could be arbitrarily large    Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene Model in BED format    Outputs                 Read coverage over gene body  This module is used to check if reads coverage is uniform and if there is any 5  3  bias  This module scales all transcripts to 100 nt and calculates the number of reads covering each nucleotide position  Finally  it generates a plot illustrating the coverage profile along the gene body  NOTE  this module requires lots of memory for large BAM files  because it load the entire BAM file into memory  We add another script  geneBody coverage2 py  into v2 3 1 which takes bigwig  instead of BAM  as input  It only use 200M RAM  but users need to convert BAM into WIG  and then WIG into BigWig   Example output         image    PATH TO IMAGES geneBody coverage png          height  600 px          width  600 px          scale  80     ABOUT        ,rseqc_geneBody_coverage2,bigwig,Gene Body Converage (Bigwig),txt
644,speculates how RNA-seq were configured,, infer experiment py                      This program is used to speculate how RNA seq sequencing were configured  especially how reads were stranded for strand specific RNA seq data  through comparing reads  mapping information to the underneath gene model    Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Number of usable sampled reads  default 200000      Number of usable reads sampled from SAM BAM file  More reads will give more accurate estimation  but make program little slower   Outputs          For pair end RNA seq  there are two different ways to strand reads  such as Illumina ScriptSeq protocol    1  1   1   2   2      read1 mapped to     strand indicates parental gene on     strand   read1 mapped to     strand indicates parental gene on     strand   read2 mapped to     strand indicates parental gene on     strand   read2 mapped to     strand indicates parental gene on     strand  2  1   1   2   2      read1 mapped to     strand indicates parental gene on     strand   read1 mapped to     strand indicates parental gene on     strand   read2 mapped to     strand indicates parental gene on     strand   read2 mapped to     strand indicates parental gene on     strand  For single end RNA seq  there are also two different ways to strand reads   1           read mapped to     strand indicates parental gene on     strand   read mapped to     strand indicates parental gene on     strand  2           read mapped to     strand indicates parental gene on     strand   read mapped to     strand indicates parental gene on     strand   Example Output                   Example1                                                                         This is PairEnd Data         Fraction of reads explained by  1   1   2   2     0 4992     Fraction of reads explained by  1   1   2   2     0 5008     Fraction of reads explained by other combinations  0 0000                                                                 Conclusion   We can infer that this is NOT a strand specific because 50  of reads can be explained by  1   1   2   2     while the other 50  can be explained by  1   1   2   2        Example2                                                                            This is PairEnd Data      Fraction of reads explained by  1   1   2   2     0 9644        Fraction of reads explained by  1   1   2   2     0 0356     Fraction of reads explained by other combinations  0 0000                                                                    Conclusion   We can infer that this is a strand specific RNA seq data  strandness of read1 is consistent with that of gene model  while strandness of read2 is opposite to the strand of reference gene model     Example3                                                                         This is SingleEnd Data         Fraction of reads explained by          0 9840        Fraction of reads explained by          0 0160     Fraction of reads explained by other combinations  0 0000                                                                 Conclusion   This is single end  strand specific RNA seq data  Strandness of reads are concordant with strandness of reference gene    ABOUT        ,rseqc_infer_experiment,,Infer Experiment,txt
645,calculate the inner distance (or insert size) between two paired RNA reads,, inner distance py                    This module is used to calculate the inner distance  or insert size  between two paired RNA reads  The distance is the mRNA length between two paired fragments  We first determine the genomic  DNA  size between two paired reads  D size   read2 start   read1 end  then    if two paired reads map to the same exon  inner distance   D size   if two paired reads map to different exons inner distance   D size   intron size   if two paired reads map non exonic region  such as intron and intergenic region   inner distance   D size   The inner distance might be a negative value if two fragments were overlapped   NOTE  Not all read pairs were used to estimate the inner distance distribution  Those low quality  PCR duplication  multiple mapped reads were skipped   Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Estimated Upper Lower Bounds  defaults 250 and  250      Estimated upper lower bounds of inner distance  bp    Step size  default 5      Step size of histogram   Output                 1  output inner distance txt        first column is read ID      second column is inner distance  Could be negative value if PE reads were overlapped or mapping error  e g  Read1 start  lt  Read2 start  while Read1 end    Read2 end due to spliced mapping of read1        third column indicates how paired reads were mapped  PE within same exon  PE within diff exon PE reads overlap 2  output  inner distance freq txt        inner distance starts       inner distance ends       number of read pairs       note the first 2 columns are left side half open interval 3  output inner distance plot r  R script to generate histogram 4  output inner distance plot pdf  histogram plot     image    PATH TO IMAGES inner distance png     height  600 px     width  600 px     scale  80     ABOUT        ,rseqc_inner_distance,,Inner Distance,txt
646,"
     calculates the distribution of inserted nucleotides across reads
    ",, insertion profile py                       Calculate the distributions of inserted nucleotides across reads  Note that to use this funciton  CIGAR strings within SAM BAM file should have  I  operation   Inputs         Input BAM SAM file     Alignment file in BAM SAM format   Minimum mapping quality     Minimum mapping quality for an alignment to be considered as  uniquely     mapped   default 30  Sequencing layout     Denotes whether the sequecing was single end  SE  or paired end  PE    Sample Output                 Read 1 insertion profile      image    PATH TO IMAGES out insertion profile R1 png     height  600 px     width  600 px     scale  80    Read 2 insertion profile      image    PATH TO IMAGES out insertion profile R2 png    height  600 px    width  600 px    scale  80     ABOUT        ,rseqc_insertion_profile,,Insertion Profile,
647,compares detected splice junctions to reference gene model,, junction annotation py                         For a given alignment file   i  in BAM or SAM format and a reference gene model   r  in BED format  this program will compare detected splice junctions to reference gene model  splicing annotation is performed in two levels  splice event level and splice junction level     splice event  An RNA read  especially long read  can be spliced 2 or more times  each time is called a splicing event  In this sense  100 spliced reads can produce    100 splicing events    splice junction  multiple splicing events spanning the same intron can be consolidated into one splicing junction   All detected junctions can be grouped to 3 exclusive categories   1  Annotated  The junction is part of the gene model  Both splice sites  5  splice site     5 SS  and 3 splice site  3 SS  can be annotated by reference gene model  2  complete novel  Complete new junction  Neither of the two splice sites cannot be annotated by gene model 3  partial novel  One of the splice site  5 SS or 3 SS  is new  while the other splice site is annotated  known   Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Minimum intron length  default 50      Minimum intron length  bp     Output                 1  output junc anno junction xls        chrom ID       start position of junction  coordinate is 0 based        end position of junction  coordinate is 1 based        number of splice events supporting this junction        annotated    complete novel  or  partial novel   2  output anno junction plot r  R script to generate pie chart 3  output splice junction pdf  plot of splice junctions 4  output splice events pdf  plot of splice events     image    PATH TO IMAGES junction png     height  400 px     width  850 px     scale  80     ABOUT        ,rseqc_junction_annotation,,Junction Annotation,pdf
648,detects splice junctions from each subset and compares them to reference gene model,, junction saturation py                         It s very important to check if current sequencing depth is deep enough to perform alternative splicing analyses  For a well annotated organism  the number of expressed genes in particular tissue is almost fixed so the number of splice junctions is also fixed  The fixed splice junctions can be predetermined from reference gene model  All  annotated  splice junctions should be rediscovered from a saturated RNA seq data  otherwise  downstream alternative splicing analysis is problematic because low abundance splice junctions are missing  This module checks for saturation by resampling 5   10   15        95  of total alignments from BAM or SAM file  and then detects splice junctions from each subset and compares them to reference gene model   Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Sampling Percentiles   Upper Bound  Lower Bound  Sampling Increment  defaults  100  5  and 5      Sampling starts from the Lower Bound and increments to the Upper Bound at the rate of the Sampling Increment   Minimum intron length  default 50      Minimum intron length  bp    Minimum coverage  default 1      Minimum number of supportting reads to call a junction   Output                 1  output junctionSaturation plot r  R script to generate plot 2  output junctionSaturation plot pdf     image    PATH TO IMAGES junction saturation png     height  600 px     width  600 px     scale  80    In this example  current sequencing depth is almost saturated for  known junction   red line  detection because the number of  known junction  reaches a plateau  In other words  nearly all  known junctions   expressed in this particular tissue  have already been detected  and continue sequencing will not detect additional  known junction  and will only increase junction coverage  i e  junction covered by more reads   While current sequencing depth is not saturated for novel junctions  green     ABOUT        ,rseqc_junction_saturation,,Junction Saturation,
649,"
     calculates the distribution of mismatches across reads
    ",, mismatch profile py                      Calculate the distribution of mismatches across reads   Note that the  MD  tag must exist in BAM file   Inputs         Input BAM SAM file     Alignment file in BAM SAM format   Alignment length of read     It is usually set to the orignial read length  For example  all these cigar     strings   101M    68M140N33M    53M1D48M   suggest the read alignment     length is 101   required   Number of aligned reads used     Number of aligned reads with deletions used to calculate the deletion     profile  default 1000000  Minimum mapping quality     Minimum mapping quality for an alignment to be considered as  uniquely     mapped   default 30  Sample Output                    image    PATH TO IMAGES mismatch profile png     height  600 px     width  600 px     scale  80     ABOUT         ,rseqc_mismatch_profile,,Mismatch Profile,
650,determines GC% and read count,, read GC py              Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Output                 1  output GC xls  Two column  plain text file  first column is GC   second column is read count 2  output GC plot r  R script to generate pdf file  3  output GC plot pdf  graphical output generated from R script      image    PATH TO IMAGES read gc png     height  600 px     width  600 px     scale  80     ABOUT        ,rseqc_read_GC,,Read GC,
651,to check the nucleotide composition bias,, read NVC py              This module is used to check the nucleotide composition bias  Due to random priming  certain patterns are over represented at the beginning  5 end  of reads  This bias could be easily examined by NVC  Nucleotide versus cycle  plot  NVC plot is generated by overlaying all reads together  then calculating nucleotide composition for each position of read  or each sequencing cycle   In ideal condition  genome is random and RNA seq reads is randomly sampled from genome   we expect A  C  G  T  25  at each position of reads   NOTE  this program expect a fixed read length  Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Include N X in NVC plot     Plots N and X alongside A  T  C  and G in plot   Output                 This module is used to check the nucleotide composition bias  Due to random priming  certain patterns are over represented at the beginning  5 end  of reads  This bias could be easily examined by NVC  Nucleotide versus cycle  plot  NVC plot is generated by overlaying all reads together  then calculating nucleotide composition for each position of read  or each sequencing cycle   In ideal condition  genome is random and RNA seq reads is randomly sampled from genome   we expect A  C  G  T  25  at each position of reads    1  output NVC xls  plain text file  each row is position of read  or sequencing cycle   each column is nucleotide  A C G T N X  2  output NVC plot r  R script to generate NVC plot  3  output NVC plot pdf  NVC plot       image    PATH TO IMAGES NVC plot png     height  600 px     width  600 px     scale  80     ABOUT        ,rseqc_read_NVC,,Read NVC,
652,calculates how mapped reads were distributed over genome feature,, read distribution py                       Provided a BAM SAM file and reference gene model  this module will calculate how mapped reads were distributed over genome feature  like CDS exon  5 UTR exon  3  UTR exon  Intron  Intergenic regions   When genome features are overlapped  e g  a region could be annotated as both exon and intron by two different transcripts    they are prioritize as  CDS exons   UTR exons   Introns   Intergenic regions  for example  if a read was mapped to both CDS exon and intron  it will be assigned to CDS exons      Total Reads   This does NOT include those QC fail duplicate and non primary hit reads    Total Tags   reads spliced once will be counted as 2 tags  reads spliced twice will be counted as 3 tags  etc  And because of this   Total Tags      Total Reads     Total Assigned Tags   number of tags that can be unambiguously assigned the 10 groups  see below table     Tags assigned to  TSS up 1kb  were also assigned to  TSS up 5kb  and  TSS up 10kb   tags assigned to  TSS up 5kb  were also assigned to  TSS up 10kb   Therefore   Total Assigned Tags    CDS Exons   5 UTR Exons   3 UTR Exons   Introns   TSS up 10kb   TES down 10kb    When assign tags to genome features  each tag is represented by its middle point   RSeQC cannot assign those reads that     hit to intergenic regions that beyond region starting from TSS upstream 10Kb to TES downstream 10Kb    hit to regions covered by both 5 UTR and 3  UTR  This is possible when two head to tail transcripts are overlapped in UTR regions    hit to regions covered by both TSS upstream 10Kb and TES downstream 10Kb    Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene model in BED format   Sample Output                 Output                                                                           Group               Total bases         Tag count           Tags Kb                                                                         CDS Exons           33302033            20002271            600 63 5 UTR Exons         21717577            4408991             203 01 3 UTR Exons         15347845            3643326             237 38 Introns             1132597354          6325392             5 58 TSS up 1kb          17957047            215331              11 99 TSS up 5kb          81621382            392296              4 81 TSS up 10kb         149730983           769231              5 14 TES down 1kb        18298543            266161              14 55 TES down 5kb        78900674            729997              9 25 TES down 10kb       140361190           896882              6 39                                                                           ABOUT        ,rseqc_read_distribution,,Read Distribution,txt
653,determines reads duplication rate with sequence-based and mapping-based strategies,, read duplication py                      Two strategies were used to determine reads duplication rate     Sequence based  reads with exactly the same sequence content are regarded as duplicated reads    Mapping based  reads mapped to the same genomic location are regarded as duplicated reads  For splice reads  reads mapped to the same starting position and splice the same way are regarded as duplicated reads   Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Upper Limit of Plotted Duplicated Times  default 500      Only used for plotting   Output                 1  output dup pos DupRate xls  Read duplication rate determined from mapping position of read  First column is  occurrence  or duplication times  second column is number of uniquely mapped reads  2  output dup seq DupRate xls  Read duplication rate determined from sequence of read  First column is  occurrence  or duplication times  second column is number of uniquely mapped reads  3  output DupRate plot r  R script to generate pdf file 4  output DupRate plot pdf  graphical output generated from R script     image    PATH TO IMAGES duplicate png     height  600 px     width  600 px     scale  80     ABOUT        ,rseqc_read_duplication,,Read Duplication,xls
654,"
        calculates hexamer (6mer) frequency for reads, genomes, and mRNA sequences
    ",, read hexamer py                        Calculate hexamer  6mer  frequency  If   r  was specified  hexamer frequency is also calculated for the reference genome  If   g  was provided  hexamer frequency is also calculated for the mRNA sequences   Inputs                 Input reads file     Read sequences in fasta or fastq format   Reference Genome     Reference genome sequence in fasta format   Reference Gene     Reference mRNA sequences in fasta format    Outputs                 Tabular file of hexamer frequences in for each input    ABOUT        ,rseqc_read_hexamer,"fasta,fastq,fastqsanger,fastq.gz,fastqsanger.gz,fasta",Hexamer frequency,tabular
655,determines Phred quality score,, read quality py                  According to SAM specification  if Q is the character to represent  base calling quality  in SAM file  then Phred Quality Score   ord Q    33  Here ord   is python function that returns an integer representing the Unicode code point of the character when the argument is a unicode object  for example  ord  a   returns 97  Phred quality score is widely used to measure  reliability  of base calling  for example  phred quality score of 20 means there is 1 100 chance that the base calling is wrong  phred quality score of 30 means there is 1 1000 chance that the base calling is wrong  In general  Phred quality score    10xlog 10 P  here P is probability that base calling is wrong   Inputs                 Input BAM SAM file     Alignment file in BAM SAM format   Ignore phred scores less than this number  default 1000      To avoid making huge vector in R  nucleotide with certain phred score represented less than this number will be ignored  Increase this number save more memory while reduce precision  This option only applies to the  boxplot    Output                 1  output qual r 2  output qual boxplot pdf        image    PATH TO IMAGES 36mer qual plot png          height  600 px          width  600 px          scale  80   3  output qual heatmap pdf        image    PATH TO IMAGES 36mer qual heatmap png          height  600 px          width  600 px          scale  80    Heatmap  use different color to represent nucleotide density   blue  low density  orange  median density  red  high density     ABOUT        ,rseqc_read_quality,,Read Quality,pdf
656,"
        evaluates RNA integrity at a transcript level
    ",,    tin py  This program is designed to evaluate RNA integrity at transcript level  TIN  transcript integrity number  is named in analogous to RIN  RNA integrity number   RIN  RNA integrity number  is the most widely used metric to evaluate RNA integrity at sample  or transcriptome  level  It is a very useful preventive measure to ensure good RNA quality and robust  reproducible RNA sequencing  However  it has several weaknesses     RIN score  1    RIN    10  is not a direct measurement of mRNA quality    RIN score heavily relies on the amount of 18S and 28S ribosome RNAs  which   was demonstrated by the four features used by the RIN algorithm  the    total RNA ratio   i e  the fraction of the area in the region of 18S and   28S compared to the total area under the curve   28S region height  28S   area ratio and the 18S 28S ratio24  To a large extent  RIN score was a   measure of ribosome RNA integrity  However  in most RNA seq experiments    ribosome RNAs were depleted from the library to enrich mRNA through either   ribo minus or polyA selection procedure     RIN only measures the overall RNA quality of an RNA sample  However  in  real   situation  the degradation rate may differs significantly among   transcripts  depending on factors such as  AU rich sequence    transcript   length    GC content    secondary structure  and the  RNA protein   complex   Therefore  RIN is practically not very useful in downstream   analysis such as adjusting the gene expression count     RIN has very limited sensitivity to measure substantially degraded RNA   samples such as preserved clinical tissues   ref      To overcome these limitations  we developed TIN  an algorithm that is able to measure RNA integrity at transcript level  TIN calculates a score  0    TIN    100  for each expressed transcript  however  the medTIN  i e  meidan TIN score across all the transcripts  can also be used to measure the RNA integrity at sample level  Below plots demonstrated TIN is a useful metric to measure RNA integrity in both transcriptome wise and transcript wise  as demonstrated by the high concordance with both RIN and RNA fragment size  estimated from RNA seq read pairs        Inputs  Input BAM SAM file     Alignment file in BAM SAM format   Reference gene model     Gene Model in BED format  Must be standard 12 column BED file   Minimum coverage     Minimum number of reads mapped to a tracript  default is 10    Sample size     Number of equal spaced nucleotide positions picked from mRNA  Note  if     this number is larger than the length of mRNA  L   it will be halved until     it s smaller than L  default is 100    Subtract background     Subtract background noise  estimated from intronic reads   Only use this     option if there are substantial intronic reads       Outputs  Text     Table that includes the gene identifier  geneID   chromosome  chrom       transcript start  tx start   transcript end  tx end   and transcript     integrity number  TIN    Example output                                                       geneID  chrom  tx start    tx end     TIN                                                     ABCC2   chr10   101542354  101611949  67 6446525761 IPMK    chr10   59951277   60027694   86 383618429 RUFY2   chr10   70100863   70167051   43 8967503948                                                       ABOUT        ,rseqc_tin,,Transcript Integrity Number,"tabular,xls"
657,"marks duplicates, outputs split reads, discordant read pairs and unmapped reads",,   samblaster                Summary           samblaster  is a fast and flexible program for marking duplicates in   read id grouped   paired end SAM files  It can also optionally output discordant read pairs and or split read mappings to separate SAM files  and or unmapped clipped reads to a separate FASTQ file  When marking duplicates   samblaster  will require approximately 20MB of memory per 1M read pairs   Usage        See the  SAM File Format Specification      for details about the SAM alignment format   By default  samblaster marks duplicates with SAM FLAG 0x400  The     removeDups   option will instead remove duplicate alignments from the output file     ALIGNMENT TYPE DEFINITIONS    Below  we will use the following definitions for alignment types  Starting with  samblaster  release 0 1 22  these definitions are affected by the use of the    M   option  By default   samblaster  will use the current definitions of alignment types as specified in the  SAM Specification       Namely  alignments marked with FLAG 0x100 are considered  secondary   while those marked with FLAG 0x800 are considered  supplemental   If the    M   option is specified  alignments marked with either FLAG 0x100 or 0x800 are considered  supplemental   and no alignments are considered  secondary   A  primary  alignment is always one that is neither  secondary  nor  supplemental   Only  primary  and  supplemental  alignments are used to find chimeric  split read  mappings  The    M   flag is used for backward compatibility with older SAM BAM files in which  chimeric  alignments were marked with FLAG 0x100  and should also be used with output from more recent runs of  bwa mem  using its    M   option     DISCORDANT READ PAIR IDENTIFICATION    A   discordant   read pair is one which meets all of the following criteria   1  Both side of the read pair are mapped  neither FLAG 0x4 or 0x8 is    set   2  The  properly paired  FLAG  0x2  is not set  3   Secondary  or  supplemental  alignments are never output as    discordant  although a discordant read pair can have such alignments    associated with them  4  Duplicate read pairs that meet the above criteria will be output as    discordant unless the    e   option is used     UNMAPPED CLIPPED READ IDENTIFICATION    An   unmapped   or   clipped   read is a  primary  alignment that is unaligned over all or part of its length respectively  The lack of a full alignment may be caused by a SV breakpoint that falls within the read  Therefore   samblaster  will optionally output such reads to a FASTQ file for re alignment by a tool  such as  YAHA       geared toward finding split read mappings   samblaster  applies the following strategy to identify and output unmapped clipped reads   1  An   unmapped   read has the  unmapped read  FLAG set  0x4   2  A   clipped   read is a mapped read with a CIGAR string that begins    or ends with at least     minClipSize   unaligned bases  CIGAR code S    and or H   and is not from a read that has one or more  supplemental     alignments  3  In order for  samblaster  to output the entire sequence for clipped    reads  the input SAM file must have soft clipped primary alignments  4   samblaster  will output unmapped clipped reads into a FASTQ file if    QUAL information is available in the input file  and a FASTA file if    not  5  Unmapped clipped reads that are part of a duplicate read pair will be    output unless the    e   option is used      Written by    Greg Faust  gf4ea virginia edu   Ira Hall Lab  University of Virginia         Please cite     Faust  G G  and Hall  I M       SAMBLASTER   fast duplicate marking and structural variant read extraction    Bioinformatics  Sept  2014    30     17   2503 2505          Also see     SAMBLASTER  Supplemental pdf      for additonal discussion and statistics about the duplicates marked by  samblaster  vs   Picard  using the NA12878 sample dataset  Click the preceeding link or download the file from this repository    Written by    Greg Faust  gf4ea virginia edu   Ira Hall Lab  University of Virginia         Please cite     Faust  G G  and Hall  I M       SAMBLASTER   fast duplicate marking and structural variant read extraction    Bioinformatics  Sept  2014    30     17   2503 2505          Also see     SAMBLASTER  Supplemental pdf      for additonal discussion and statistics about the duplicates marked by  samblaster  vs   Picard  using the NA12878 sample dataset  Click the preceeding link or download the file from this repository      ,samblaster,"bam,sam",samblaster,"bam,fastqsanger"
658,"
        using scikit-bio
    ",,                   Calculates beta diversity using the selected metric                ,scikit_bio_diversity_beta_diversity,tabular,Beta Diversity,tabular
659,get the nucleotide composition of FASTA/Q,,Reports composition of fasta fastq sequences  For an example sequence like,seqtk_comp,bed,seqtk_comp,tabular
660,cut sequence at long N,,Splits long sequences with runs of Ns,seqtk_cutN,,seqtk_cutN,
661,drop unpaired from interleaved Paired End FASTA/Q,,Remove unpaired reads in an interleaved paired end FASTA Q file  Given a fastq file with unpaired reads ,seqtk_dropse,,seqtk_dropse,
662,fastq QC (base/quality summary),,Returns quality score information base by base ,seqtk_fqchk,,seqtk_fqchk,tabular
663,regional heterozygosity,,Reports on heterozygosity over a region,seqtk_hety,,seqtk_hety,tabular
664,extract the position of each het,,Lists regions of heterozygosity ,seqtk_listhet,,seqtk_listhet,tabular
665,merge two FASTA/Q files,,Merges two fasta files  using ambiguity codes,seqtk_mergefa,"fasta,fastq",seqtk_mergefa,
666,interleave two unpaired FASTA/Q files for a paired-end file,,Merge two files which constitute a paired end file into a single  interleaved  paired end FASTA Q file,seqtk_mergepe,"fasta,fastq",seqtk_mergepe,
667,point mutate FASTA at specified positions,,the SNP inputs consist of 4 columns  chromosome  1 based pos  any  base changed to ,seqtk_mutfa,tabular,seqtk_mutfa,
668,choose a random base from hets,,Randomly resolves ambiguous bases,seqtk_randbase,,seqtk_randbase,
669,random subsample of fasta or fastq sequences,,Takes a random subsample of FASTA or FASTQ sequences  The RNG is seedable to allow for reproducible results  and defaults to  4      ,seqtk_sample,,seqtk_sample,
670,common transformation of FASTA/Q,,Various utilities for transforming FASTA Q data,seqtk_seq,"bed,txt",seqtk_seq,
671,extract subsequences from FASTA/Q files,,Given a list of newline separated IDs from a fasta file  this will extract those named fasta sequences from the input file ,seqtk_subseq,"bed,txt",seqtk_subseq,
672,trim FASTQ using the Phred algorithm,,Trim a fastq file based on Phred scores  or by length,seqtk_trimfq,,seqtk_trimfq,
673,Faster SPAdes assembly of Illumina reads,, Synopsis    Faster de novo assembly pipeline for Illumina paired end reads based around Spades  Details and options        Takes paired end Illumina fastq reads       Trim reads    Use Trimmomatic to remove common adaptors first  default  OFF        Output log file   If set to  Yes   tool will return Shovill s log file as part of the output      Advanced options            Name format           Format of output contig FASTA IDs in  printf  style  default   contig 05d         Depth                 Sub sample the reads to this depth  Disable with  Depth  0   default  100        Estimated genomesize  An estimate of the final genome size  it will autodetect if this is blank   default            List of kmers to use  List of K mer sizes to use in SPAdes  Blank is AUTO   default            Extra SPAdes options  Extra SPAdes options eg    plasmid   sc      default            Disable post assembly correction  Disable post assembly correction with pilon  default  ON        Minimum contig length     Minimum length of contig to be output  0 is AUTO  default  0        Minimum contig coverage   Minimum coverage to call part of a contig  0 is AUTO  default  2        Spades result to correct  Spades result to correct  before rr  contigs or scaffolds  default   contigs    Documentation can be found at Torsten Seemann  site          ,shovill,"fastqsanger,fastqsanger.gz,fastqsanger.bz2",Shovill,"txt,fasta"
674,windowed adaptive trimming of FASTQ data,,Most modern sequencing technologies produce reads that have deteriorating quality towards the 3  end and some towards the 5  end as well  Incorrectly called bases in both regions negatively impact assembles  mapping  and downstream bioinformatics analyses ,sickle,"fastq,fastq.gz",Sickle,
675,gene prediction,,      SNAP is a general purpose gene finding program suitable for both eukaryotic and prokaryotic genomes       ,snap,"fasta,snaphmm",SNAP,"gff,fasta"
676,ab-initio gene predictor,,         This tool allows to train SNAP  an ab initio gene predictor  based on a previous prediction made with Maker      ,snap_training,"fasta,gff",Train SNAP,snaphmm
677,from a multi-FASTA alignment file,,           SNP sites    This tool can rapidly extract SNPs from a multi FASTA alignment using modest resources and can output results in multiple formats for downstream analysis  SNPs can be extracted from a 8 3 GB alignment file  1 842 taxa  22 618 sites  in 267 seconds using 59 MB of RAM and 1 CPU core  making it feasible to run on modest computers  SNP sites is implemented in C and is available under the open source license GNU GPL version 3     Input FASTA format     The first sequence will be taken as a reference      code block       sample1   AGACACAGTCAC     sample1   AGACAC    AC     sample1   AAACGCATTCAN    Output files     The output of the tool are three different files in following format     a multi fasta alignment    relaxed phylip format and    VCF   The VCF file for the above specified input is  The output of the tool are three different files in following format     a multi fasta alignment    relaxed phylip format and    VCF   The VCF file for the above specified input is                                                                                     CHROM   POS ID  REF ALT    QUAL    FILTER  INFO    FORMAT  sample1 sample1 sample1                                                                                    1       2       G   A                              GT      0       0       1                                                                                    1       5       A   G                              GT      0       0       1                                                                                    1       8       G     T                            GT      0       1       2                                                                                     Thus the tool identified three variations  SNPs   in 2nd  5th  and 8th positions  A instead of G  G instead of A  and unknown nucleotide or T instead of G  respectively           ,snp_sites,fasta,Finds SNP sites,"fasta,vcf,phylip"
678,genome assembler for regular and single-cell projects,,SPAdes   St  Petersburg genome assembler   is intended for both standard isolates and single cell MDA bacteria assemblies  See  for more details on SPAdes ,spades,"fastq,fasta,fastq",SPAdes,"tabular,fasta,txt"
679,format from NCBI SRA,,This tool extracts data  in fastq  format  from the Short Read Archive  SRA  at the National Center for Biotechnology Information  NCBI   It is based on the fastq dump  utility of the SRA Toolkit ,fastq_dump,,Download and Extract Reads in FASTA/Q,fastqsanger
680,format from NCBI SRA,,This tool extracts data  in BAM  format  from the Short Read Archive  SRA  at the National Center for Biotechnology Information  NCBI   It is based on the sam dump  utility of the SRA Toolkit ,sam_dump,,Download and Extract Reads in BAM,bam
681,from NCBI SRA,,    This tool produces pileup format from sra archives using sra pileup  The sra pileup program is developed at NCBI  and is available at   SRATOOLS ATTRRIBUTION        ,sra_pileup,"sra,txt",Download and Generate Pileup Format,pileup
682,run the STACKS sort_read_pairs.pl and exec_velvet.pl wrappers,,This program will run each of the Stacks sort read pairs pl and exec velvet pl utilities to assemble pair end reads from STACKS pipeline results,stacks_assembleperead,"fastqsanger,txt,tabular",Stacks: assemble read pairs by locus,fasta
683,Identify PCR clones,,     class   infomark   The clone filter program is designed to identify PCR clones    STACKS INFOS       ,stacks_clonefilter,"fastqsanger,fastqsanger.gz",Stacks: clone filter,fastqsanger.gz
684,build a catalogue of loci,,A catalog can be built from any set of samples processed by the ustacks or pstacks programs  It will create a set of consensus loci  merging alleles together  In the case of a genetic cross  a catalog would be constructed from the parents of the cross to create a set of all possible alleles expected in the progeny of the cross ,stacks_cstacks,"tabular,txt",Stacks: cstacks,"txt,html,tabular"
685,the Stacks pipeline without a reference genome (denovo_map.pl),,This program will run each of the Stacks components  first  running ustacks on each of the samples specified  building loci and calling SNPs in each  Second  cstacks will be run to create a catalog of all loci that were marked as  parents  or  samples  on the command line  and finally  sstacks will be executed to match each sample against the catalog  A bit more detail on this process can be found in the FAQ  The denovo map pl program will also load the results of each stage of the analysis  individual loci  the catalog  and matches against the catalog into the database  although this can be disabled   After matching  the program will build a database index to speed up access  index radtags pl  and enable web based filtering ,stacks_denovomap,"fastqsanger,fastqsanger.gz,fasta,tabular,txt",Stacks: de novo map,"txt,html,tabular"
686,analyse haplotypes or genotypes in a genetic cross ('genotypes' program),,This program exports a Stacks data set either as a set of observed haplotypes at each locus in the population  or with the haplotypes encoded into genotypes  The  r option allows only loci that exist in a certain number of population individuals to be exported  In a mapping context  raising or lowering this limit is an effective way to control the quality level of markers exported as genuine markers will be found in a large number of progeny  If exporting a set of observed haplotypes in a population  the  min stack depth  option can be used to restict exported loci to those that have a minimum depth of reads ,stacks_genotypes,"txt,tabular,tabular,txt",Stacks: genotypes,html
687,analyze a population of individual samples ('populations' program),,This program will be executed in place of the genotypes program when a population is being processed through the pipeline  A map specifiying which individuals belong to which population is submitted to the program and the program will then calculate population genetics statistics  expected observed heterzygosity     and FIS at each nucleotide position  The populations program will compare all populations pairwise to compute FST  If a set of data is reference aligned  then a kernel smoothed FST will also be calculated ,stacks_populations,"tabular,txt,vcf,txt,tabular",Stacks: populations,html
688,the Stacks demultiplexing script,,This program examines raw reads from an Illumina sequencing run and first  checks that the barcode and the RAD cutsite are intact  and demultiplexes the data  If there are errors in the barcode or the RAD site within a certain allowance process radtags can correct them  Second  it slides a window down the length of the read and checks the average quality score within the window  If the score drops below 90  probability of being correct  a raw phred score of 10   the read is discarded  This allows for some seqeuncing errors while elimating reads where the sequence is degrading as it is being sequenced  By default the sliding window is 15  of the length of the read  but can be specified on the command line  the threshold and window size can be adjusted  ,stacks_procrad,"fastqsanger,fastqsanger.gz,tabular,txt",Stacks: process radtags,txt
689,find stacks from short reads mapped to a reference genome,,Similar to ustacks  except this program will extract stacks that have been aligned to a reference genome by a program such as Bowtie and identify SNPs  These stacks can then be processed with cstacks or sstacks ,stacks_pstacks,"sam,bam",Stacks: pstacks,"txt,html"
690,the Stacks pipeline with a reference genome (ref_map.pl),,This program expects data that have been aligned to a reference genome  and can accept data directly from Bowtie  or from any aligner that can produce SAM format  To avoid datasets names problems  we recommand the use of the  Map with BWA for STACKS tool   This program will execute each of the Stacks components  first  running pstacks on each of the samples specified  building loci  based on the reference alignment  and calling SNPs in each  Second  cstacks will be run to create a catalog of all loci specified as  parents  or  samples  on the command line  again using alignment to match loci in the catalog  Finally  sstacks will be executed to match each sample against the catalog  The ref map pl program will also load the results of each stage of the analysis  individual loci  the catalog  and matches against the catalog into the database  although this can be disabled   After matching the program will build a database index to speed up access  index radtags pl  and enable web based filtering ,stacks_refmap,"sam,bam,tabular,txt",Stacks: reference map,"txt,html,tabular"
691,make corrections to genotype and haplotype calls,,This program will run each of the Stacks components  first  running ustacks on each of the samples specified  building loci and calling SNPs in each  Second  cstacks will be run to create a catalog of all loci that were marked as  parents  or  samples  on the command line  and finally  sstacks will be executed to match each sample against the catalog  A bit more detail on this process can be found in the FAQ  The denovo map pl program will also load the results of each stage of the analysis  individual loci  the catalog  and matches against the catalog into the database  although this can be disabled   After matching  the program will build a database index to speed up access  index radtags pl  and enable web based filtering ,stacks_rxstacks,,Stacks: rxstacks,txt
692,match stacks to a catalog,,Sets of stacks constructed by the ustacks or pstacks programs can be searched against a catalog produced by cstacks  In the case of a genetic map  stacks from the progeny would be matched against the catalog to determine which progeny contain which parental alleles ,stacks_sstacks,"tabular,txt",Stacks: sstacks,"txt,html"
693,on stacks found for multiple samples,,When given the output of ustacks or pstacks  this will generate a report containing various statistics about the detected stacks in a set of samples ,stacks_stats,txt,Stacks: statistics,html
694,align short reads into stacks,,The unique stacks program will take as input a set of short read sequences and align them into exactly matching stacks  Comparing the stacks it will form a set of loci and detect SNPs at each locus using a maximum likelihood framework,stacks_ustacks,"fastqsanger,fastqsanger.gz,fasta",Stacks: ustacks,"txt,html"
695,detect fusion genes in RNA-Seq data,,STAR Fusion is a component of the Trinity Cancer Transcriptome Analysis Toolkit  CTAT   STAR Fusion uses the STAR aligner to identify candidate fusion transcripts supported by Illumina reads  STAR Fusion further processes the output generated by the STAR aligner to map junction reads and spanning reads to a reference annotation set ,star_fusion,"interval,fastqsanger,fastqsanger.gz,fasta,gff3,gtf,tabular",STAR-Fusion,tabular
696,transcript assembly and quantification,,StringTie  is a fast and highly efficient assembler of RNA Seq alignments into potential transcripts  It uses a novel network flow algorithm as well as an optional  de novo  assembly step to assemble and quantitate full length transcripts representing multiple splice variants for each gene locus  Its input can include not only the alignments of raw reads used by other transcript assemblers  but also alignments of longer sequences that have been assembled from those reads  In order to identify differentially expressed genes between experiments  StringTie s output can be processed by specialized software like Ballgown   Cuffdiff  or other programs  DESeq2   edgeR   etc   ,stringtie,"sam,bam,gtf,gff3",StringTie,"gtf,tabular"
697,transcripts,,This is a special usage mode of StringTie   distinct from the assembly usage mode  In the merge mode  StringTie takes as input a list of GTF GFF files and merges assembles these transcripts into a non redundant set of transcripts  This mode is used in the new differential analysis pipeline to generate a global  unified set of transcripts  isoforms  across multiple RNA Seq samples ,stringtie_merge,"gtf,gff3",StringTie merge,gtf
698,using multi-locus genotype data to investigate population structure,,   Introduction    The program structure  implements a model based clustering method for inferring population structure using genotype data consisting of unlinked markers  The method was introduced in a paper by Pritchard  Stephens and Donnelly  2000a  and extended in sequels by Falush  Stephens and Pritchard  2003a  2007   Applications of our method include demonstrating the presence of population structure  identifying distinct genetic populations  assigning individuals to populations  and identifying migrants and admixed individuals   Briefly  we assume a model in which there are K populations  where K may be unknown   each of which is characterized by a set of allele frequencies at each locus  Individuals in the sample are assigned  probabilistically  to populations  or jointly to two or more populations if their genotypes indicate that they are admixed  It is assumed that within populations  the loci are at Hardy Weinberg equilibrium  and linkage equilibrium  Loosely speaking  individuals are assigned to populations in such a way as to achieve this   Our model does not assume a particular mutation process  and it can be applied to most of the commonly used genetic markers including microsatellites  SNPs and RFLPs  The model assumes that markers are not in linkage disequilibrium  LD  within subpopulations  so we can t handle markers that are extremely close together  Starting with version 2 0  we can now deal with weakly linked markers   While the computational approaches implemented here are fairly powerful  some care is needed in running the program in order to ensure sensible answers  For example  it is not possible to determine suitable run lengths theoretically  and this requires some experimentation on the part of the user  This document describes the use and interpretation of the software and supplements the published papers  which provide more formal descriptions and evaluations of the methods       structure      Documentation    Please see the full Sructure documentation       documentation      Upstream    Inputs can be produced from     Microsatellite analysis   RADSeq analysis  eg  using populations  from Stacks suite       populations   export    Input                                                                  loc a  loc b  loc c  loc d  loc e                                                 George   1     9     145    66     0      92 George   1     9      9     64     0      94 Paula    1    106    142    68     1      92 Paula    1    106    148    64     0      94 Matthew  2    110    145     9     0      92 Matthew  2    110    148    66     1       9 Bob      2    108    142    64     1      94 Bob      2     9     142     9     0      94 Anja     1    112    142     9     1       9 Anja     1    114    142    66     1      94 Peter    1     9     145    66     0       9 Peter    1    110    145     9     1       9 Carsten  2    108    145    62     0       9 Carsten  2    110    145    64     1      92                                                  You will find other sample data sets  here       here      Downstream      Clumpp    Distruct    Structure harvester       Clumpp       Distruct       Structure harvester        ,structure,tabular,Structure,txt
699,for parsing STRUCTURE outputs and for performing the Evanno method,,  Structure Harvester  is a program for parsing the output of Pritchard s STRUCTURE  and for performing the Evanno method       Structure Harvester       STRUCTURE        ,structureharvester,txt,structureHarvester,txt
700,Parallel MCMC Linkage Analysis,, SwiftLink performs multipoint parametric linkage analysis on large consanguineous pedigrees and is primarily targeted at pedigrees that cannot be analysed by a Lander Green algorithm based program  i e  many markers  but larger pedigrees  The current version of SwiftLink only supports SNP markers      ,swiftlink,"linkage_pedin,linkage_recomb,linkage_map,txt",Swiftlink,"allegro_fparam,txt"
701,,,Generates a frequency pileup of the 5  ends of aligned reads in a BAM file relative to reference points in a BED file ,tag_pileup_frequency,"bam,bed",Tag pileup frequency,tabular
702,from taxonomic profile,,This tool renders results of a metagenomic profiling as a zoomable pie chart using Krona  ,taxonomy_krona_chart,"taxonomy,tabular",Krona pie chart,html
703,Find coding regions within transcripts,,TransDecoder identifies candidate coding regions within transcript sequences  such as those generated by de novo RNA Seq transcript assembly using Trinity  or constructed based on RNA Seq alignments to the genome using Tophat and Cufflinks ,transdecoder,fasta,TransDecoder,"fasta,bed,gff3"
704,finds rho-independent transcription terminators in bacterial genomes,,Finds rho independent transcription terminators in bacterial genomes  ,transtermhp,"fasta,gff3",TransTermHP,gff3
705,for a de novo assembly of RNA-Seq data by Trinity,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool will combine abundance estimations  produced by  Align reads and estimate abundance on a de novo assembly of RNA Seq data  tool  from multiple samples into a single tabular file  This matrix can then be used by  RNASeq samples quality check for transcript quantification  and  Differential Expression Analysis using a Trinity assembly  tools     Inputs    It takes as input multiple results from  Align reads and estimate abundance on a de novo assembly of RNA Seq data  tool  Each sample must have a name  that should be used in subsequent tools     Output    This tool will produce a single matrix file  More details on this page       Trinity manual         Trinity        ,trinity_abundance_estimates_to_matrix,tabular,Build expression matrix,tabular
706,on a de novo assembly of RNA-Seq data,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool estimates the abundance of isoforms and genes of a transcriptome assembled with Trinity  using FastQ of a specific sample     Inputs    It takes as input a transcriptome assembled with Trinity and the reads from a RNASeq sample  You have to choose between several counting methods   If you dont align on a Trinity assembly  you need to provide a file of the following  tabular  format to map gene ids to transcript ids                                gene1       transcript1                              gene2       transcript2                                 Output    This tool will produce 2 tabular files  with counts for isoforms and genes respectively  More details on this page       Trinity manual         Trinity        ,trinity_align_and_estimate_abundance,"fasta,fasta,fastqsanger,tabular",Align reads and estimate abundance,tabular
707,from a Trinity assembly,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool extracts the transcripts that are most differentially expressed  most significant FDR and fold changes   once differential expression analyses have been runned     Inputs    This tool uses the raw counts matrix produced by  Build expression matrix for a de novo assembly of RNA Seq data by Trinity  tool   You must describe your samples and replicates with a tabular file looking like this                                ConditionA  CondA replicate1                              ConditionA  CondA replicate2                              ConditionB  CondB replicate1                              ConditionB  CondB replicate2                              ConditionC  CondC replicate1                              ConditionC  CondC replicate2                              ConditionC  CondC replicate3                               This file can be generated with the  Describe samples and replicates  tool  It will probably be the same file as used in the tool  RNASeq samples quality check for transcript quantification  or in the tool  Differential expression analysis   The names in column 2 must match the names given in the tool  Build expression matrix for a de novo assembly of RNA Seq data by Trinity    You must also provide as a data collection the files resulting from the differential expression analysis  outputs of tool  Differential expression analysis         Trinity        ,trinity_analyze_diff_expr,tabular,Extract and cluster differentially expressed transcripts,RData
708,from a Trinity assembly,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool computes the N50 statistic limited to the top most highly expressed transcripts that represent x  of the total normalized expression data  This requires that you have first performed transcript abundance estimation with  Align reads and estimate abundance for a de novo assembly of RNA Seq data by Trinity  tool and that you have built the expression matrix with  Build expression matrix for a de novo assembly of RNA Seq data by Trinity  tool      Inputs    It takes as input a transcriptome assembled with Trinity and the matrix of normalized expression values produced by  Build expression matrix for a de novo assembly of RNA Seq data by Trinity  tool       Trinity        ,trinity_contig_exn50_statistic,"tabular,fasta",Compute contig Ex90N50 statistic and Ex90 transcript count,tabular
709,after differential expression analysis using a Trinity assembly,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool partitions the differentially expressed genes into gene clusters with similar expression patterns by one of several available methods  once differential expression analyses have been runned  It is a companion tool for the tool  Extract and cluster differentially expressed transcripts from a Trinity assembly      Inputs    This tool uses the RData file produced by  Extract and cluster differentially expressed transcripts from a Trinity assembly  tool       Trinity        ,trinity_define_clusters_by_cutting_tree,RData,Partition genes into expression clusters,pdf
710,and replicates,,         This tools allows to describe your samples and replicates  producing a tabular file looking like this                                                ConditionA  CondA replicate1                                              ConditionA  CondA replicate2                                              ConditionB  CondB replicate1                                              ConditionB  CondB replicate2                                              ConditionC  CondC replicate1                                              ConditionC  CondC replicate2                                              ConditionC  CondC replicate3                                               IThe output file can be used in the tools  RNASeq samples quality check for transcript quantification  and  Differential expression analysis           The names in column 2 must match the names given to the datasets in your history      ,describe_samples,,Describe samples,tabular
711,from a Trinity assembly,,         Trinity  assembles transcript sequences from Illumina RNA Seq data          This tool filters a Trinity assembly using an expression matrix built         with  Build expression matrix for a de novo assembly of RNA Seq data by Trinity  tool          It discards transcripts isoforms having a low expression level               Trinity       ,trinity_filter_low_expr_transcripts,"fasta,tabular",Filter low expression transcripts,fasta
712,for Trinity assembly,,         Trinity  assembles transcript sequences from Illumina RNA Seq data          This tool produces a file containing correspondance between gene ids and transcript ids based on the name of transcripts assembled by Trinity          The output file is intended to be used by the  Align reads and estimate abundance  tool               Trinity       ,trinity_gene_to_trans_map,fasta,Generate gene to transcript map,tabular
713,using a Trinity assembly,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool performs differential expression analyses on a transcriptome assembled with Trinity     Inputs    This tool uses the matrix produced by  Build expression matrix for a de novo assembly of RNA Seq data by Trinity  tool   You must describe your samples and replicates with a tabular file looking like this                                ConditionA  CondA replicate1                              ConditionA  CondA replicate2                              ConditionB  CondB replicate1                              ConditionB  CondB replicate2                              ConditionC  CondC replicate1                              ConditionC  CondC replicate2                              ConditionC  CondC replicate3                                This file can be generated with the  Describe samples and replicates  tool  It will probably be the same file as used in the tool  RNASeq samples quality check for transcript quantification   The names in column 2 must match the names given in the tool  Build expression matrix for a de novo assembly of RNA Seq data by Trinity         Trinity        ,trinity_run_de_analysis,tabular,Differential expression analysis,
714,for transcript quantification,,  Trinity  assembles transcript sequences from Illumina RNA Seq data  This tool performs some Quality Checks on a RNASeq experiment  analysing the abundance estimation for different samples using a transcriptome assembled with Trinity     Inputs    This tool uses the matrix produced by  Build expression matrix for a de novo assembly of RNA Seq data by Trinity  tool   You must describe your samples and replicates with a tabular file looking like this                                ConditionA  CondA replicate1                              ConditionA  CondA replicate2                              ConditionB  CondB replicate1                              ConditionB  CondB replicate2                              ConditionC  CondC replicate1                              ConditionC  CondC replicate2                              ConditionC  CondC replicate3                               This file can be generated with the  Describe samples and replicates  tool  The names in column 2 must match the names given in the tool  Build expression matrix for a de novo assembly of RNA Seq data by Trinity      Output    This tool will produce several PDF files  see the following page for more information       Trinity manual         Trinity        ,trinity_samples_qccheck,tabular,RNASeq samples quality check,
715,de novo assembly of RNA-Seq data,, Trinity  assembles transcript sequences from Illumina RNA Seq data       Trinity       ,trinity,"fasta,fastqsanger,bam,fasta",Trinity,fasta
716,,,Trinotate  is a comprehensive annotation suite designed for automatic functional annotation of transcriptomes  particularly de novo assembled transcriptomes  from model or non model organisms  Trinotate makes use of a number of different well referenced methods for functional annotation including homology search to known sequence data  BLAST  SwissProt   protein domain identification  HMMER PFAM   protein signal peptide and transmembrane domain prediction  signalP tmHMM   and leveraging various annotation databases  eggNOG GO Kegg databases   All functional annotation data derived from the analysis of transcripts is integrated into a SQLite database which allows fast efficient searching for terms with specific qualities related to a desired scientific hypothesis or a means to create a whole annotation report for a transcriptome ,trinotate,"fasta,tabular,txt,sqlite",Trinotate,"tabular,sqlite"
717,,, T distributed Stochastic Neighbor Embedding implementation by Van der Maaten  see   for more information on the original implementation    Your data should be in tabular format  Objects in rows will be clustered according to the observations in columns  Labels for objects can be assigned in the tool form by providing the column number of the identifier you wish to use  Additionaly  the first column containing numeric data should be provided to the tool form        ,tsne,tabular,rtsne,pdf
718,BLAST-like sequence alignment tool,,          BLAT      BLAT is a bioinformatics software a tool which performs rapid mRNA DNA and cross species protein alignments    blat  version  v340   Standalone blat sequence search command line tool                                                                              usage              blat database query   ooc 11 ooc  output psl  where     database and query are each either a  fa   nib or  2bit file     or a list of these files with one file name per line      ooc 11 ooc tells the program to load over occurring 11 mers from    an external file   This will increase the speed    by a factor of 40 in many cases  but is not required     output psl is the name of the output file     documentation                  See Blat documentation     Source code                  ,ucsc_blat,"fasta, twobit,txt",UCSC BLAT Alignment Tool,psl
719,Extract UMI from fastq files,, umi tools dedup   Deduplicate reads based on their UMI                                                         Purpose          The purpose of this command is to deduplicate BAM files based on the first mapping co ordinate and the UMI attached to the read  It is assumed that the FASTQ files were processed with extract umi py before mapping and thus the UMI is the last word of the read name  e g    HISEQ 87 00000000 AATT  where AATT is the UMI sequeuence   If you have used an alternative method which does not separate the read id and UMI with a      such as bcl2fastq which uses      you can specify the separator with the option    umi separator  sep    replacing  sep  with e g       Alternatively  if your UMIs are encoded in a tag  you can specify this by setting the option   extract umi method tag and set the tag name with the   umi tag option  For example  if your UMIs are encoded in the  UM  tag  provide the following options     extract umi method tag   umi tag UM   The start postion of a read is considered to be the start of its alignment minus any soft clipped bases  A read aligned at position 500 with cigar 2S98M will be assumed to start at postion 498    Methods          dedup can be run with multiple methods to identify groups of reads with the same  or similar  UMI s   All methods start by identifying the reads with the same mapping position   The simpliest method   unique   groups reads with the exact same UMI  The network based methods   cluster    adjacency  and  directional   build networks where nodes are UMIs and edges connect UMIs with an edit distance    threshold  usually 1   The groups of reads are then defined from the network in a method specific manner      unique        Reads group share the exact same UMI     percentile        Reads group share the exact same UMI  UMIs with counts   1  of the       median counts for UMIs at the same position are ignored      cluster        Identify clusters of connected UMIs  based on hamming distance       threshold   Each network is a read group     adjacency        Cluster UMIs as above  For each cluster  select the node UMI        with the highest counts  Visit all nodes one edge away  If all       nodes have been visted  stop  Otherise  repeat with remaining       nodes until all nodes have been visted  Each step       defines a read group      directional   default        Identify clusters of connected UMIs  based on hamming distance       threshold  and umi A counts     2  umi B counts    1  Each       network is a read group   Options            extract umi method  choice        How are the UMIs encoded in the read         Options are            read id   default              UMIs contained at the end of the read separated as             specified with   umi separator option           tag              UMIs contained in a tag  see   umi tag option    umi separator  string        Separator between read id and UMI  See   extract umi method above    umi tag  string        Tag which contains UMI  See   extract umi method above    edit distance threshold  int         For the adjacency and cluster methods the threshold for the        edit distance to connect two UMIs in the network can be        increased  The default value of 1 works best unless the UMI is        very long   14bp     paired        BAM is paired end   output both read pairs  This will also        force the use of the template length to determine reads with        the same mapping coordinates     spliced is unique        Causes two reads that start in the same position on the same        strand and having the same UMI to be considered unique if one is        spliced and the other is not   Uses the  N  cigar operation to test        for splicing     soft clip threshold  int         Mappers that soft clip  will sometimes do so rather than mapping a        spliced read if there is only a small overhang over the exon        junction  By setting this option  you can treat reads with at least        this many bases soft clipped at the 3  end as spliced     multimapping detection method  string  choice         If the sam bam contains tags to identify multimapping reads  you can        specify for use when selecting the best read at a given loci         Supported tags are  NH    X0  and  XT   If not specified  the read        with the highest mapping quality will be selected    read length       Use the read length as as a criteria when deduping  for e g sRNA Seq    whole contig       Consider all alignments to a single contig together  This is useful if       you have aligned to a transcriptome multi fasta    subset  float   0 1         Only consider a fraction of the reads  chosen at random  This is useful       for doing saturation analyses     chrom       Only consider a single chromosome  This is useful for debugging purposes    per contig  string        Deduplicate per contig  field 3 in BAM  RNAME         All reads with the same contig will be       considered to have the same alignment position  This is useful       if your library prep generates PCR duplicates with non identical       alignment positions such as CEL Seq  In this case  you would       align to a reference transcriptome with one transcript per gene    per gene  string        Deduplicate per gene  As above except with this option you can       align to a reference transcriptome with more than one transcript       per gene  You need to also provide   gene transcript map option        This will also add a metacontig   MC   tag to the reads if used       in conjunction with   output bam    gene transcript map  string        File mapping genes to transripts  tab separated   e g         gene1   transcript1       gene1   transcript2       gene2   transcript3    gene tag  string        Deduplicate per gene  As per   per gene except here the gene       information is encoded in the bam read tag specified so you do       not need to supply   gene transcript map    output bam  string  filename        Output a tagged bam file to stdout or  S  filename    i    in sam  o    out sam       By default  inputs are assumed to be in BAM format and output are output       in BAM format  Use these options to specify the use of SAM format for       inputs or outputs    I     string  filename  input file name       The input file must be sorted and indexed    S     string  filename  output file name   L     string  filename  log file name  Usage           umi tools dedup  I infile bam  S grouped bam         ,umi_tools_dedup,"sam,bam,tabular",UMI-tools deduplicate,bam
720,Extract UMI from fastq files,,   UMI tools extract py   Extract UMI from fastq                                                Purpose          Extract UMI barcode from a read and add it to the read name  leaving any sample barcode in place  Can deal with paired end reads and UMIs split across the paired ends  Options            split barcode        By default the UMI is assumed to be on the first read  Use this        option if the UMI is contained on both reads and specify the        pattern of the barcode UMI on the second read using the option            bc pattern2      bc pattern        Use this option to specify the format of the UMI barcode  Use Ns to        represent the random positions and Xs to indicate the bc positions         Bases with Ns will be extracted and added to the read name  Remaining        bases  marked with an X will be reattached to the read          E g  If the pattern is NNXXNN         Then the read           HISEQ 87 00000000 read1        AAGGTTGCTGATTGGATGGGCTAG        DA1AEBFGGCG01DFH00B1FF0B                  will become          HISEQ 87 00000000 AATT read1        GGGCTGATTGGATGGGCTAG        1AFGGCG01DFH00B1FF0B             bc pattern2        Use this option to specify the format of the UMI barcode for        the second read pair if required  If   bc pattern2 is not        supplied  this defaults to the same pattern as   bc pattern    3prime        By default the barcode is assumed to be on the 5  end of the read  but        use this option to sepecify that it is on the 3  end instead   L        Specify a log file to retain logging information and final statistics    split barcode        barcode is split across read pair    quality filter threshold QUALITY FILTER THRESHOLD        Remove reads where any UMI base quality score falls        below this threshold   quality encoding QUALITY ENCODING        Quality score encoding  Choose from phred33 33 77         phred64  64 106  or solexa  59 106   Usage          For single ended reads          umi tools extract   bc pattern  PATTERN   L extract log  OPTIONS   reads from stdin and outputs to stdout   For paired end reads          umi tools extract   bc pattern  PATTERN    read2 in  FASTQIN    read2 out  FASTQOUT   L extract log  OPTIONS   reads end one from stdin and end two from FASTQIN and outputs end one to stdin and end two to FASTQOUT       ,umi_tools_extract,"fastq,fastq.gz",UMI-tools extract,txt
721,Extract UMI from fastq files,, umi tools group   Group reads based on their UMI                                                   Purpose          The purpose of this command is to identify groups of reads based on their genomic coordinate and UMI  It is assumed that the FASTQ files were processed with umi tools extract before mapping and thus the UMI is the last word of the read name  e g    HISEQ 87 00000000 AATT  where AATT is the UMI sequeuence   If you have used an alternative method which does not separate the read id and UMI with a      such as bcl2fastq which uses      you can specify the separator with the option    umi separator  sep    replacing  sep  with e g       Alternatively  if your UMIs are encoded in a tag  you can specify this by setting the option   extract umi method tag and set the tag name with the   umi tag option  For example  if your UMIs are encoded in the  UM  tag  provide the following options     extract umi method tag   umi tag UM   By default  reads are considered identical if they have the same start coordinate  are on the same strand  and have the same UMI  Optionally  splicing status can be considered  see below    The start postion of a read is considered to be the start of its alignment minus any soft clipped bases  A read aligned at position 500 with cigar 2S98M will be assumed to start at postion 498   Methods          group can be run with multiple methods to identify group of reads with the same  or similar  UMI s   All methods start by identifying the reads with the same mapping position   The simpliest method   unique   groups reads with the exact same UMI  The network based methods   cluster    adjacency  and  directional   build networks where nodes are UMIs and edges connect UMIs with an edit distance    threshold  usually 1   The groups of reads are then defined from the network in a method specific manner   Note that the  percentile  method used with the dedup command is not available with group  This is because this method does not group similar UMIs as per the network methods  Instead it applies a threshold for inclusion of the UMI in the output and excluded UMIs are not assigned to a  true  UMI      unique        Reads group share the exact same UMI     cluster        Identify clusters of connected UMIs  based on hamming distance       threshold   Each network is a read group     directional        Identify clusters of connected UMIs  based on hamming distance       threshold  and umi A counts     2  umi B counts    1  Each       network is a read group   The group command can be used to create two types of outfile  a tagged BAM or a flatfile describing the read groups  To generate the tagged BAM file  use the option   output bam and provide a filename with the  S option  Alternatively  if you do not provide a filename  the bam file will be outputted to the stdout  If you have provided the   log  L option to send the logging output elsewhere  you can pipe the output from the group command directly to e g samtools sort like so     umi tools group  I inf bam   group out grouped tsv   output bam   log group log   paired   samtools sort    o grouped sorted bam    The tagged BAM file will have two tagged per read      UG   Unique id      0 indexed unique id number for each group of reads with the same genomic position and UMI or UMIs inferred to be from the same true UMI   errors     BX   Final UMI       The inferred true UMI for the group  To generate the flatfile describing the read groups  include the   group out  filename  option  The columns of the read groups file are below  The first five columns relate to the read  The final 3 columns relate to the group       read id       read identifier      contig       alignment contig      position       Alignment position  Note that this position is not the start position of the read in the BAM file but the start of the read taking into account the read strand and cigar      umi       The read UMI      umi count       The number of times this UMI is observed for reads at the same position      final umi       The inferred true UMI for the group      final umi count       The total number of reads within the group      unique id       The unique id for the group   Options            extract umi method  choice        How are the UMIs encoded in the read         Options are            read id   default              UMIs contained at the end of the read separated as             specified with   umi separator option           tag              UMIs contained in a tag  see   umi tag option    umi separator  string        Separator between read id and UMI  See   extract umi method above    umi tag  string        Tag which contains UMI  See   extract umi method above    method  choice  string        Method used to identify PCR duplicates within reads  All methods       start by identifying the reads with the same mapping position        Options are            unique            Reads group share the exact same UMI           cluster            Identify clusters of connected UMIs  based on edit distance           threshold   Each network is a read group           directional            Identify clusters of connected UMIs  based on edit distance           threshold  and umi A counts     2  umi B counts    1  Each           network is a read group     edit distance threshold  int         For the adjacency and cluster methods the threshold for the        edit distance to connect two UMIs in the network can be        increased  The default value of 1 works best unless the UMI is        very long   14bp     paired        BAM is paired end   output both read pairs  This will also        force the use of the template length to determine reads with        the same mapping coordinates     spliced is unique        Causes two reads that start in the same position on the same        strand and having the same UMI to be considered unique if one is        spliced and the other is not   Uses the  N  cigar operation to test        for splicing     soft clip threshold  int         Mappers that soft clip  will sometimes do so rather than mapping a        spliced read if there is only a small overhang over the exon        junction  By setting this option  you can treat reads with at least        this many bases soft clipped at the 3  end as spliced     multimapping detection method  string  choice         If the sam bam contains tags to identify multimapping reads  you can        specify for use when selecting the best read at a given loci         Supported tags are  NH    X0  and  XT   If not specified  the read        with the highest mapping quality will be selected    read length       Use the read length as as a criteria when deduping  for e g sRNA Seq    whole contig       Consider all alignments to a single contig together  This is useful if       you have aligned to a transcriptome multi fasta    subset  float   0 1         Only consider a fraction of the reads  chosen at random  This is useful       for doing saturation analyses     chrom       Only consider a single chromosome  This is useful for debugging purposes    per contig  string        Deduplicate per contig  field 3 in BAM  RNAME         All reads with the same contig will be       considered to have the same alignment position  This is useful       if your library prep generates PCR duplicates with non identical       alignment positions such as CEL Seq  In this case  you would       align to a reference transcriptome with one transcript per gene    per gene  string        Deduplicate per gene  As above except with this option you can       align to a reference transcriptome with more than one transcript       per gene  You need to also provide   gene transcript map option        This will also add a metacontig   MC   tag to the reads if used       in conjunction with   output bam    gene transcript map  string        File mapping genes to transripts  tab separated   e g         gene1   transcript1       gene1   transcript2       gene2   transcript3    gene tag  string        Deduplicate per gene  As per   per gene except here the gene       information is encoded in the bam read tag specified so you do       not need to supply   gene transcript map    group out  string  filename        Output a flatfile describing the read groups    output bam  string  filename        Output a tagged bam file to stdout or  S  filename    i    in sam  o    out sam       By default  inputs are assumed to be in BAM format and output are output       in BAM format  Use these options to specify the use of SAM format for       inputs or outputs    I     string  filename  input file name       The input file must be sorted and indexed    S     string  filename  output file name   L     string  filename  log file name  Usage           umi tools group  I infile bam   output bam  S grouped bam  L group log         ,umi_tools_group,"sam,bam,tabular",UMI-tools group,"bam,tabular"
722,,,    Unicycler    Unicycler is a hybrid assembly pipeline for bacterial genomes  It uses both Illumina reads and long reads  PacBio or Nanopore  to produce complete and accurate assemblies  It is written by  Ryan Wick   at the University of Melbourne s Centre for Systems Genomics  Much of the description below is lifted from Unicycler s  github page          Ryan Wick         github page    Unicycler           Input data    Unicycler accepts inputs short  Illumina  reads in FASTQ format  Galaxy places additional requirement of having these in FASTQ format with  Sanger encoding   of quality scores  Long reads  from Oxford Nanopore or PacBio  can be either in FASTQ of FASTA form        Sanger encoding    Quality  The input options are         1 SHORT1    short1 SHORT1         FASTQ file of short reads  first reads in each pair       2 SHORT2    short2 SHORT2         FASTQ file of short reads  second reads in each pair       s SHORT UNPAIRED    short unpaired SHORT UNPAIRED         FASTQ file of unpaired short reads      l LONG    long LONG         FASTQ or FASTA file of long reads  if all reads are available at start            Bridging mode    Unicycler can be run in three modes  conservative  normal  the default  and bold  set with the   mode option  Conservative mode is least likely to produce a complete assembly but has a very low risk of misassembly  Bold mode is most likely to produce a complete assembly but carries greater risk of misassembly  Normal mode is intermediate regarding both completeness and misassembly risk  See  description of modes   for more information        description of modes    Unicycler conservative normal and bold  The available modes are          mode  conservative normal bold          Bridging mode  default  normal          conservative   smaller contigs  lowest misassembly rate         normal   moderate contig size and misassembly rate         bold   longest contigs  higher misassembly rate          Skip SPAdes error correction step    Sequencing data contains a substantial number of sequencing errors that manifest themselves as deviations  bulges and non connected components  within the assembly graph  One of the ways to improve the graph even constructing it is to minimize the amount sequencing errors by performing error correction  SPAdes  which is used by Unicycler for error correction and assembly  uses  BayesHammer   to correct the reads  Here is a brief summary of what it does    1  SPAdes  or rather BayesHammer  counts  k  mers in reads and computed  k  mer statistics that takes into account base quality values   2   Hamming graph   is constructed for  k  mers is which  k  mers are nodes  In this graph edges connect nodes   k  mers  is they differ from each other by a number of nucleotides up to a certain threshold  the  Hamming distance     The graph is central to the error correction algorithm   3  At this step Bayesian subclustering of the graph produced in the previous step  For each  k  mer we now know the center of its subcluster   4  Solid  k  mers are derived from cluster centers and are assumed to be  error free    5  Solid  k  mers are mapped back to the reads and used to correct them   This step takes considerable time  so if one need to quickly evaluate assemblies this step can be skipped  However  this is not recommended if one if trying to produce a final high quality assembly        BayesHammer         Hamming graph         Hamming distance     This following option turns error correction on and off          no correct         Skip SPAdes error correction step          default  conduct SPAdes error correction            Do not rotate completed replicons to start at a standard gene    Unicycler uses TBLASTN to search for dnaA or repA alleles in each completed replicon  If one is found  the sequence is rotated and or flipped so that it begins with that gene encoded on the forward strand  This provides consistently oriented assemblies and reduces the risk that a gene will be split across the start and end of the sequence   The following option turns rotation on and off          no rotate         Do not rotate completed replicons         to start at a standard gene          default  completed replicons are rotated     Do not use Pilon to polish the final assembly     Pilon   is a tool for improving overall quality of draft assemblies and finding variation among strains  Unicycler uses it for assembly  polishing    The following option turns pilon part of Unicycler pipeline on and off          no pilon         Do not use Pilon to polish the         final assembly  default  Pilon is used        Pilon               Expected number of linear sequences    If you expect your sample to contain linear  non circular  sequences  set this option          linear seqs EXPECTED LINEAR SEQS         The expected number of linear  i e  non circular          sequences in the underlying sequence          SPAdes options    This section provides control of SPAdes options          min kmer frac MIN KMER FRAC         Lowest k mer size for SPAdes assembly          expressed as a fraction of the read length          default  0 2        max kmer frac MAX KMER FRAC         Highest k mer size for SPAdes assembly          expressed as a fraction of the read length          default  0 95        kmer count KMER COUNT         Number of k mer steps to use in         SPAdes assembly  default  10        depth filter DEPTH FILTER         Filter out contigs lower than this fraction          of the chromosomal depth  if doing so does          not result in graph dead ends  default  0 25           Rotation options    Unicycler attempts to rotate circular assemblies to make sure that they begin at a consistent starting gene  The following parameters control assembly rotation          start genes START GENES         FASTA file of genes for start point         of rotated replicons          default  start genes fasta        start gene id START GENE ID         The minimum required BLAST percent identity         for a start gene search          default  90 0        start gene cov START GENE COV         The minimum required BLAST percent coverage         for a start gene search          default  95 0            Graph cleaning options    These options control the removal of small leftover sequences after bridging is complete          min component size MIN COMPONENT SIZE         Unbridged graph components smaller         than this size  bp  will be removed         from the final graph  default  1000        min dead end size MIN DEAD END SIZE         Graph dead ends smaller than this size  bp          will be removed from the final graph          default  1000            Long read alignment options    These options control the alignment of long reads to the assembly graph          contamination CONTAMINATION         FASTA file of known contamination in long reads       scores SCORES         Comma delimited string of alignment scores          match  mismatch  gap open  gap extend          default  3  6  5  2        low score LOW SCORE         Score threshold   alignments below this         are considered poor          default  set threshold automatically            Outputs    Galaxy s wrapped for Unicycler produces two outputs      final assembly in FASTA format    final assembly grapth in graph format   While most will likely be interested in the FASTA dataset  the graph dataset is also quite useful and can be visualized using tools such as  Bandage           Bandage    Bandage       ,unicycler,"fastqsanger,fastqsanger.gz,fastqsanger,fastqsanger.gz,fasta,fasta",Create assemblies with Unicycler,"txt,fasta"
723,to detect mis-assemblies in metagenomic assemblies,,VALET is a de novo pipeline for detecting all types of mis assemblies in metagenomic data sets ,valet,"fasta,fastq,tabular,txt,gff,gtf",VALET,pdf
724,Automatically optimize Velvet assemblies,,   Velvet Optimiser Overview          Velvet  is a de novo genomic assembler specially designed for short read sequencing technologies  such as Solexa or 454  developed by Daniel Zerbino and Ewan Birney at the European Bioinformatics Institute  EMBL EBI   near Cambridge  in the United Kingdom         Velvet currently takes in short read sequences  removes errors then produces high quality unique contigs  It then uses paired end read and long read information  when available  to retrieve the repeated areas between contigs         Read the Velvet  documentation    for details on using the Vevlet Assembler             Velvet   zerbino velvet                 zerbino velvet Manual pdf          VelvetOptimiser          VelvetOptimiser  was written by Simon Gladman of CSIRO Melbourne University         VelvetOptimiser performs a number of velveth and velvetg steps to try and optimise an assembly based on the metrics provided below             VelvetOptimiser          Galaxy tool wrapper for newer versions  2 5 5  of Velvet Optimiser  Written by Simon Gladman of Melbourne University     Outputs             Contigs          The  contigs fa  file        This fasta file contains the sequences of the contigs longer than 2k  where k is the word length used in velveth  If you have specified a min contig lgth threshold  then the contigs shorter than that value are omitted        Note that the length and coverage information provided in the header of each contig should therefore be understood in k mers and in k mer coverage  cf  5 1  respectively        The N s in the sequence correspond to gaps between scaffolded contigs  The number of N s corresponds to the estimated length of the gap  For reasons of compatibility with the archives  any gap shorter than 10bp is represented by a sequence of 10 N s           Stats          The  stats txt  file        This file is a simple tabbed delimited description of the nodes  The column names are pretty much self explanatory  Note however that node lengths are given in k mers  To obtain the length in nucleotides of each node you simply need to add k   1  where k is the word length used in velveth        The in and out columns correspond to the number of arcs on the 5  and 3  ends of the contig respectively        The coverages in columns short1 cov  short1 Ocov  short2 cov  and short2 Ocov are provided in k mer coverage  5 1         Also  the difference between   cov and   Ocov is the way these values are computed  In the first count  slightly divergent sequences are added to the coverage tally  However  in the second  stricter count  only the sequences which map perfectly onto the consensus sequence are taken into account           LastGraph          The  LastGraph  file        This file describes in its entirety the graph produced by Velvet  This file is hidden by default           Logfile          The Velvet Optimiser s logfile  This file is hidden by default          STDERR          The Standard Error output of the Optimiser for error messages etc  This file is hidden by default           Advanced options          Verbose                                   Include verbose velvet output in log file  Good for debugging when things don t work         Other Velvetg Options                     Extra velvetg options to pass through   eg   long mult cutoff  max coverage etc  default     See below for details         Minimum coverage cutoff                   The minimum cov cutoff to be used   default  0           Maximum coverage cutoff                   The maximum coverage cutoff to consider as a multiplier of the expected coverage   default  0 8           K mer optimisation function               The optimisation function used for k mer choice   default  n50           Coverage cutoff optimisation function     The optimisation function used for cov cutoff optimisation   default  Lbp           Velvet optimiser   assembly optimisation functions   can be built from the following variables              LNbp    The total number of Ns in large contigs             Lbp    The total number of base pairs in large contigs             Lcon    The number of large contigs             max    The length of the longest contig             n50    The n50             ncon    The total number of contigs             tbp    The total number of basepairs in contigs          Examples are              Lbp    Just the total basepairs in contigs longer than 1kb             n50 Lcon    The n50 times the number of long contigs              n50 Lcon tbp log Lbp     The n50 times the number of long contigs divided by the total bases in all contigs plus the log of the number of bases in long contigs  as an example only            Defaults are                n50  for k mer length optimisation                 Lbp  for coverage cutoff          Hash Length          The hash length  also known as k mer length  corresponds to the length  in base pairs  of the words being hashed         The hash length is the length of the k mers being entered in the hash table  Firstly  you must observe three technical constraints             it must be an odd number  to avoid palindromes  If you put in an even number  Velvet will just decrement it and proceed            it must be below or equal to MAXKMERHASH length  cf  2 3 3  by default 31bp   because it is stored on 64 bits           it must be strictly inferior to read length  otherwise you simply will not observe any overlaps between reads  for obvious reasons         Now you still have quite a lot of possibilities  As is often the case  it s a trade off between specificity and sensitivity  Longer kmers bring you more specificity  i e  less spurious overlaps  but lowers coverage  cf  below     so there s a sweet spot to be found with time and experience        We like to think in terms of  k mer coverage   i e  how many times has a k mer been seen among the reads  The relation between k mer coverage Ck and standard  nucleotide wise  coverage C is Ck   C    L   k   1  L where k is your hash length  and L you read length        Experience shows that this kmer coverage should be above 10 to start getting decent results  If Ck is above 20  you might be  wasting  coverage  Experience also shows that empirical tests with different values for k are not that costly to run  VelvetOptimiser automates these tests for you            Velvetg options           scaffolding yes no                  scaffolding of contigs used paired end information  default  on          max branch length integer          maximum length in base pair of bubble  default  100          max divergence floating point    maximum divergence rate between two branches in a bubble  default  0 2          max gap count integer              maximum number of gaps allowed in the alignment of the two branches of a bubble  default  3          min pair count integer           minimum number of paired end connections to justify the scaffolding of two long contigs  default  5          max coverage floating point      removal of high coverage nodes AFTER tour bus  default  no removal          coverage mask integer              minimum coverage required for confident regions of contigs  default  1          long mult cutoff integer          minimum number of long reads required to merge contigs  default  2          paired exp fraction double       remove all the paired end connections which less than the specified fraction of the expected count  default  0 1          conserveLong yes no              preserve sequences with long reads in them  default no            Input Files          Velvet works mainly with fasta and fastq formats  For paired end reads  the assumption is that each read is next to its mate       read  In other words  if the reads are indexed from 0  then reads 0 and 1 are paired  2 and 3  4 and 5  etc         Supported file formats are              fasta           fastq           bam        Read categories are              short  default            shortPaired           long  for Sanger  454 or even reference sequences            longPaired           reference  for pre mapped sam or bam files   see Velvet manual for details on how to use this option        ,velvetoptimiser,"fastqsanger,fasta,bam",VelvetOptimiser,"fasta,tabular"
725,,,Pairwise alignments of all sequences ,vsearch_alignment,fasta,VSearch alignment,fasta
726,,,Sequence chimera detection based on a different scoring functions ,vsearch_chimera_detection,fasta,VSearch chimera detection,"fasta,tabular"
727,,,vsearch implements a single pass  greedy star clustering algorithm  similar to the algorithms implemented in usearch  DNAclust and sumaclust for example ,vsearch_clustering,fasta,VSearch clustering,"fasta,tabular"
728,,,Merge strictly identical sequences contained in filename  Identical sequences are defined as having the same length and the same string of nucleotides  case insensitive  T and U are considered the same  ,vsearch_dereplication,fasta,VSearch dereplication,fasta
729,,,An input sequence can be composed of lower  or uppercase nucleotides  Lowercase nucleotides are silently set to uppercase before masking  unless the   qmask soft option is used  Here are the results of combined masking options   qmask  or   dbmask for database sequences  and   hardmask  assuming each input sequences contains both lower and uppercase nucleotides ,vsearch_masking,fasta,VSearch masking,fasta
730,,,Sequence search based on vsearch ,vsearch_search,fasta,VSearch search,"fasta,tabular"
731,,,Sequence shuffling to obtain new random sequences ,vsearch_shuffling,fasta,VSearch shuffling,fasta
732,,,Fasta entries are sorted by decreasing abundance    sortbysize  or sequence length    sort  bylength   To obtain a stable sorting order  ties are sorted by decreasing abundance and label increasing alpha numerical order    sortbylength   or just by label increasing alpha numerical order    sortbysize   Label sorting assumes that all sequences have unique labels  The same applies to the automatic sorting performed during chimera checking    uchime denovo   derepli  cation    derep fulllength   and clustering    cluster fast and   cluster size  ,vsearch_sorting,fasta,VSearch sorting,fasta
733,,, HELP        Supported location types                                                               current location  ip adress      paris                     city name     muc                       airport code  3 letters       stackoverflow com        domain name     94107                     area codes  us only    Special locations                               moon                      Moon phase  add   US or   France for these cities      moon 1999 Oct 02          Moon phase on a particular date          wrapped by Aarif Mohamed Nazeer Batcha and Jochen Bick           ,simple_weather,,SimpleWeather,html
734,generator for fasta (eg Clustal alignments),,   Note    This tool uses Weblogo3  in Galaxy to generate a sequence logo  The input file must be a fasta file in your current history   It is recommended for  eg  viewing multiple sequence alignments output from the clustalw tool   set the output to fasta and feed it in to this tool   A typical output looks like this     image     static path  images rgWebLogo3 test jpg          Warning about input Fasta format files    The Weblogo3 program used by this tool will fail if your fasta sequences are not all EXACTLY the same length  The tool will provide a warning and refuse to call the weblogo3 executable if irregular length sequences are detected   Fasta alignments from the companion ClustalW Galaxy tool will work but many other fasta files may cause this tool to fail   please do not file a Galaxy bug report   this is a feature of the tool and a problem with your source data   not a tool error   please make certain all your fasta sequences are the same length           Attribution    Weblogo attribution and associated documentation are available at Weblogo3   This Galaxy wrapper was written by Ross Lazarus for the rgenetics project and the source code is licensed under the LGPL  like other rgenetics artefacts      Weblogo3        LGPL        ,rgweblogo3,fasta,Sequence Logo,pdf
735,compute xpath expressions on XML data,,Query XML files with XPath expressions ,xpath,xml,XPath,xml
736,BAM datasets and perform other transformations,,    What is does    BAMTools is a collection of utilities for manipulation on BAM files  It is based on BAMtools suite of tools by Derek Barnett   This Galaxy implementation of BAMTools utilities includes seven utilities   Convert  Count  Coverage  Header  Merge  Random  and Revert   decsribed in detail below            Convert    Converts BAM dataset s  into BED  FASTA  FASTQ  JSON  Pileup  SAM  or YAML formats  Note that the conversion to the pileup format requires providing a reference sequence either cashed at this Galaxy instance  or provided by you as a FASTA dataset from History            Count    Counts a number of alignments in a BAM dataset s             Coverage    Prints per base coverage for a BAM dataset            Header    Prints header from a BAM dataset s              Merge    Merges multiple BAM datasets into a single one  Obviously  you need to select multiple BAMs as input  which is done by pressing the    Add new BAM dataset s  to filter    button             Random    Grabs a specified number of random lines from BAM dataset s              Revert    Removes duplicate marks and restores original  non recalibrated  base qualities             class   infomark    More information    Additional information about BAMtools can be found at       ,bamtools,"bam,fasta","Convert, Merge, Randomize",txt
737,BAM datasets on a variety of attributes,,    What is does    BAMTools filter is a very powerful utility to perform complex filtering of BAM files  It is based on BAMtools suite of tools by Derek Barnett             How it works    The tool use logic relies on the three concepts   1  input BAM   2  groups  and  3  filters    Input BAM s    The input BAM is self explanatory  This is the dataset you will be filtering  The tool can accept just one or multiple BAM files  To filter on multiple BAMs just add them by clicking   Add new BAM dataset s  to filter     Conditions and Filters   Conditions for filtering BAM files can be arranged in   Groups and Filters    While it can be confusing at first this is what gives ultimate power to this tools  So try to look at the examples we are supplying below            Example 1  Using a single filter    When filtering on a single condition there is no need to worry about filters and conditions  Just choose a filter from the   Select BAM property to filter on    dropdown and enter a value  or click a checkbox for binary filters   For example  for retaining reads with mapping quality of at least 20 one would set the tool interface as shown below      image   single filter png           Example 2  Using multiple filters    Now suppose one needs to extract reads that  1  have mapping quality of at least 20   2  contain at least 1 mismatch  and  3  are mapping onto forward strand only  To do so we will use three filters as shown below  multiple filters are added to the interface by clicking on the   Add new Filter   button       image   multiple filters png  In this case  you can see that the three filters are grouped within a single Condition     Condition 1    the filter too use logical   AND   to perform filtering  In other words only reads that  1  have mapping quality of at least 20   AND    2  contain at least 1 mismatch   AND   are mapping onto forward strand will be returned in this example            Example 3  Complex filtering with multiple conditions    Suppose now you would like to select   either   reads that    1    have   1 1   no mismatches and   1 2   are on the forward strand   OR      2    reads that have   2 1   at least one mismatch and   2 2   are on the reverse strand  In this scenario we have to set up two conditions     1    and    2    each with two filters   1 1  and  1 2  as well as  2 1  and  2 2   The following screenshot expalins how this can be done      image   complex filters png           Example 4  Even more complex filtering with Rules    In the above example we have used two conditions  Condition 1 and Condition 2   Using multiple conditions allows to combine them and a variety of ways to enable even more powerful filtering  For example  suppose get all reads that    1    do NOT map to mitochondria and either    2    have mapping quality over 20  or    3    are in properly mapped pairs  The logical rule to enable such filtering will look like this       1     2   3   Here  numbers 1  2  and 3 represent conditions  The following screenshot illustrates how to do this in Galaxy      image   rule png  There are three conditions here  each with a single filter  A text entry area that can be opened by clicking on the   Would you like to set rules    checkbox enables you to enter a rule  Here numbers correspond to numbers of conditions as they are shown in the interface  E g   1 corresponds to condition 1  2 to condition 2 and so on    In human language this means     NOT condition 1 AND  condition 2 OR condition 3            JSON script file    This tool produces two outputs  One of the them is a BAM file containing filtered reads  The other is a JSONified script  It can help you to see how your instructions are sent to BAMTools  For instance  the example 4 looks like this in the JSON form                      filters                          id    1                tag   NM  0                isReverseStrand   false                            id    2                tag   NM  0                isReverseStrand   true                                           More information       class   infomark  Additional information about BAMtools can be found at       ,bamFilter,bam,Filter,"txt,bam"
738,BAM datasets on variety of attributes,,   What is does    BAMTools split is a utility for splitting BAM files  It is based on BAMtools suite of tools by Derek Barnett              class   warningmark    DANGER  Multiple Outputs    As described below  splitting a BAM dataset s  on reference name or a tag value can produce very large numbers of outputs  Read below and know what you are doing            How it works    The following options can be specified via    Split BAM dataset s  by    dropdown      Mapping status   mapped           split mapped unmapped and generate two output files                                     named  MAPPED  and  UNMAPPED  containing mapped and unmapped                                     reads  respectively     Pairing status   paired           split single end paired end alignments and generate two output files                                     named  SINGLE END  and  PAIRED END  containing paired and unpaired                                     reads  respectively     Reference name   reference        split alignments by reference name  In cases of unfinished genomes with                                     very large number of reference sequences  scaffolds  it can generate                                     thousands  if not millions  of output datasets     Specific tag   tag                split alignments based on all values of TAG encountered  Choosing this                                     option from the menu will allow you to enter the tag name  As was the                                     case with the reference splitting above  this option can produce very                                     large number of outputs if a tag has a large number of unique values             class   infomark    More information    Additional information about BAMtools can be found at       ,bamtools_split,bam,Split,txt
739,,,   What is does    BAMTools split is a utility for splitting BAM files  It is based on BAMtools suite of tools by Derek Barnett              class   warningmark     How it works    Splits the input BAM file into 2 output files named  MAPPED  and  UNMAPPED  containing mapped and unmapped reads  respectively             class   infomark    More information    Additional information about BAMtools can be found at       ,bamtools_split_mapped,bam,Split BAM by Mapped,bam
740,,,   What is does    BAMTools split is a utility for splitting BAM files  It is based on BAMtools suite of tools by Derek Barnett              class   warningmark     How it works     Splits the input BAM file into 2 output files named  SINGLE END  and  PAIRED END  containing single end and paired end reads  respectively             class   infomark    More information    Additional information about BAMtools can be found at       ,bamtools_split_paired,bam,Split BAM by Paired/Single End,bam
741,into dataset list collection,,   What is does    BAMTools split is a utility for splitting BAM files  It is based on BAMtools suite of tools by Derek Barnett              class   warningmark    DANGER  Multiple Outputs    As described below  splitting a BAM dataset s  on reference name or a tag value can produce very large numbers of outputs  Read below and know what you are doing            How it works    Split alignments by reference name into a dataset list collection   The collection will be in the same order as the input BAM references   In cases of unfinished genomes with very large number of reference sequences  scaffolds  it can generate thousands  if not millions  of output datasets              class   infomark    More information    Additional information about BAMtools can be found at       ,bamtools_split_ref,bam,Split BAM by Reference,
742,into dataset list collection,,   What is does    BAMTools split is a utility for splitting BAM files  It is based on BAMtools suite of tools by Derek Barnett              class   warningmark    DANGER  Multiple Outputs    As described below  splitting a BAM dataset s  on tag value can produce very large numbers of outputs  Read below and know what you are doing            How it works    Split alignments by tag name into a dataset list collection   This can generate a huge number of output datasets depending on the number of distinct values of the TAG              class   infomark    More information    Additional information about BAMtools can be found at       ,bamtools_split_tag,bam,Split BAM by Tag,
743,"
        assign taxonomic labels to sequencing reads
    ",,Kraken is a taxonomic sequence classifier that assigns taxonomic labels to short DNA reads  It does this by examining the k mers within a read and querying a database with those k mers  This database contains a mapping of every k mer in Kraken s genomic library to the lowest common ancestor  LCA  in a taxonomic tree of all genomes that contain that k mer  The set of LCA taxa that correspond to the k mers in a read are then analyzed to create a single taxonomic label for the read  this label can be any of the nodes in the taxonomic tree  Kraken is designed to be rapid  sensitive  and highly precise ,kraken,"fasta,fastq",Kraken,tabular
744,filter classification by confidence score,,At present  we have not yet developed a confidence score with a solid probabilistic interpretation for Kraken  However  we have developed a simple scoring scheme that has yielded good results for us  and we ve made that available in the kraken filter script  The approach we use allows a user to specify a threshold score in the  0 1  interval  the   kraken filter   script then will adjust labels up the tree until the label s score  described below  meets or exceeds that threshold  If a label at the root of the taxonomic tree would not have a score exceeding the threshold  the sequence is called unclassified by   kraken filter   ,kraken-filter,tabular,Kraken-filter,tabular
745,view report of classification for multiple samples,,      class   warningmark    Note    the database used must be the same as the one used in the original Kraken run           What is Does    Kraken mpa report summarizes read counts across taxonomic ranks for multiple samples  This is convenient for comparing results across multiple experiments  conditions  locations  etc            Output    The output of kraken mpa report is a tab delimited table  with one line per taxon        ,kraken-mpa-report,tabular,Kraken-mpa-report,tabular
746,view sample report of a classification,,     class   warningmark    Note    the database used must be the same as the one used in the original Kraken run           Output    The output of kraken report is tab delimited  with one line per taxon  The fields of the output  from left to right  are as follows     1  Percentage of reads covered by the clade rooted at this taxon  2  Number of reads covered by the clade rooted at this taxon  3  Number of reads assigned directly to this taxon  4  A rank code  indicating  U nclassified   D omain   K ingdom   P hylum   C lass   O rder   F amily   G enus  or  S pecies  All other ranks are simply filled with a dash   5  NCBI taxonomy ID  6  Indented scientific name  The scientific names are indented using spaces  according to the tree structure specified by the taxonomy      ,kraken-report,tabular,Kraken-report,tabular
747,convert taxonomy IDs to names,,The file sequences labels generated by the above example is a text file with two tab delimited columns  and one line for each classified sequence in sequences fa  unclassified sequences are not reported by kraken translate  The first column of kraken translate s output are the sequence IDs of the classified sequences  and the second column contains the taxonomy of the sequence  For example  an output line from kraken  ,kraken-translate,tabular,Kraken-translate,tabular
748,convert BAM alignments to CRAM format,,   What this tool does    Converts alignments from the BAM format to the CRAM format using the   samtools view   command  The CRAM format does additional compression relative to the reference genome which makes the compression in terms of file size more efficient      ,samtools_bam_to_cram,"bam,sam,fasta,bed",samtools BAM to CRAM,cram
749,convert BAM to SAM,,Converts BAM dataset to SAM using the   samtools view   command      ,bam_to_sam,bam,BAM-to-SAM,sam
750,convert CRAM alignments to BAM format,,   What this tool does    Converts alignments from the CRAM format to the BAM format using the   samtools view   command      ,samtools_cram_to_bam,"cram,fasta,bed",samtools CRAM to BAM,bam
751,convert SAM to BAM,,Converts SAM dataset into its binary  BAM  representation using the   samtools view   and   sort   commands      ,sam_to_bam,"sam,fasta",SAM-to-BAM,bam
752,calculate read depth for a set of genomic intervals,,Calculates read depth for regions listed in a BED dataset using   samtools bedcov   command  ,samtools_bedcov,"bed,bam",BedCov,tabular
753,recalculate MD/NM tags,,Generates the MD tag using the   samtools calmd   command  If the MD tag  see SAM format reference below for explanation of SAM BAM tags  is already present  this command will give a warning if the MD tag generated is different from the existing tag  Outputs a BAM file ,samtools_calmd,"bam,fasta",CalMD,bam
754,tabulate descriptive stats for BAM datset,,Uses   samtools flagstat   command to print descriptive information for a BAM dataset  Here is an example of such information  ,samtools_flagstat,bam,Flagstat,txt
755,reports stats of the BAM index file,,Runs the   samtools idxstats   command  It retrieves and prints stats in the index file ,samtools_idxstats,bam,IdxStats,tabular
756,multi-way pileup of variants,,Report variants for one or multiple BAM files  Alignment records are grouped by sample identifiers in  RG header lines  If sample identifiers are absent  each input file is regarded as one sample ,samtools_mpileup,"bam,fasta,bed,txt",MPileup,pileup
757,heterozygous SNPs,,Call and phase heterozygous SNPs      ,samtools_phase,bam,Call and phase,"txt,bam"
758,copy SAM/BAM header between datasets,,Copies header from  source  dataset into  target  dataset using   samtools reheader   command      ,samtools_reheader,"sam,bam,bam",Reheader,bam
759,remove PCR duplicates,,Remove potential PCR duplicates  if multiple read pairs have identical external coordinates  only retain the pair with highest mapping quality  In the paired end mode  this command ONLY works with FR orientation and requires ISIZE is correctly set  It does not work for unpaired reads  e g  two ends mapped to different chromosomes or orphan reads       ,samtools_rmdup,bam,RmDup,bam
760,BAM by genomic regions,,Allows to restrict  slice  input BAM dataset to a list of intervals defined in a BED file  individual chromosomes  or manually set list of coordinates  BED datasets can be obtained from   Get Data    UCSC Main   ,samtools_slice_bam,"bam,bed",Slice,bam
761,order of storing aligned sequences,,This tool uses   samtools sort   command to sort BAM datasets in coordinate or read name order      ,samtools_sort,bam,Sort,bam
762,BAM dataset on readgroups,,Splits BAM files on readgroups ,samtools_split,"bam,bam,sam",Split,bam
763,generate statistics for BAM dataset,,This tool runs the   samtools stats   command      ,samtools_stats,"sam,bam,fasta",Stats,tabular
764,Variant effect and annotation,, This tool calculate the effect of variants  SNPs MNPs Insertions  and deletions    EXTERNAL DOCUMENTATION       ,snpEff,"vcf,tabular,pileup,bed,snpeffdb,bed,tabular",SnpEff,"vcf,html"
765,,,  EXTERNAL DOCUMENTATION      ,snpEff_databases,,SnpEff available databases,tabular
766,Download a new database,,  EXTERNAL DOCUMENTATION      ,snpEff_download,,SnpEff Download,snpeffdb
767,SNPs from dbSnp,, This is typically used to annotate IDs from dbSnp   Annotatating only the ID field from dbSnp137 vcf         Input VCF      CHROM  POS         ID           REF  ALT  QUAL   FILTER  INFO     22      16157571                 T    G    0 0    FAIL    NS 53     22      16346045                 T    C    0 0    FAIL    NS 244     22      16350245                 C    A    0 0    FAIL    NS 192      Annotated Output VCF       CHROM  POS         ID           REF  ALT  QUAL   FILTER  INFO     22      16157571                 T    G    0 0    FAIL    NS 53     22      16346045    rs56234788   T    C    0 0    FAIL    NS 244     22      16350245    rs2905295    C    A    0 0    FAIL    NS 192  Annotatating both the ID and INFO fields from dbSnp137 vcf         Input VCF       CHROM  POS         ID           REF  ALT  QUAL   FILTER  INFO     22      16157571                 T    G    0 0    FAIL    NS 53     22      16346045                 T    C    0 0    FAIL    NS 244     22      16350245                 C    A    0 0    FAIL    NS 192      Annotated Output VCF       CHROM  POS         ID           REF  ALT  QUAL   FILTER  INFO     22      16157571                 T    G    0 0    FAIL    NS 53     22      16346045    rs56234788   T    C    0 0    FAIL    NS 244 RSPOS 16346045 GMAF 0 162248628884826 dbSNPBuildID 129 SSR 0 SAO 0 VP 050100000000000100000100 WGT 0 VC SNV SLO GNO     22      16350245    rs2905295    C    A    0 0    FAIL    NS 192 RSPOS 16350245 GMAF 0 230804387568556 dbSNPBuildID 101 SSR 1 SAO 0 VP 050000000000000100000140 WGT 0 VC SNV GNO   EXTERNAL DOCUMENTATION     annotate     ,snpSift_annotate,vcf,SnpSift Annotate,vcf
768,Count samples are in 'case' and 'control' groups.,,   SnpSift CaseControl    Allows you to count how many samples are in  case  group and a  control  group  You can count  homozygous    heterozygous  or  any  variants   Case and control are defined by a string containing plus and minus symbols             0   where     is case      is control and  0  is neutral   This command adds two annotations to the VCF file       CaseControl    Two comma separated numbers numbers representing the number of samples that have the variant in the case and the control group  Example           CaseControl 3 4   the variant is present in 3 cases and 4 controls         CaseControlP    A p value  Fisher exact test  that the number of cases is N or more  Example           CaseControl 4 0 CaseControlP 3 030303e 02   in this case the pValue of having 4 or more cases and zero controls is 0 03   For example  if we have ten samples  which means ten genotype columns in the VCF file   the first four are  case  and the last six are  control   so the description string would be                Let s say we want to distinguish genotypes that are homozygous in  case  and either homozygous or heterozygous in  control    We would set     Hom Het case    hom    Hom Het control    any    Case   Control column designation                   EXTERNAL DOCUMENTATION     casecontrol     ,snpSift_caseControl,"vcf,tabular",SnpSift CaseControl,vcf
769,from a VCF file into a tabular file,,   SnpSift Extract Fields    Extract fields from a VCF file to a TXT  tab separated format  that you can easily load in R  XLS  etc    Extract  You can also use sub fields and genotype fields   sub fields such as        Standard VCF fields          CHROM         POS         ID         REF         ALT         FILTER     INFO fields          AF         AC         DP         MQ         etc   any info field available      SnpEff  ANN  fields           ANN    ALLELE   alias GENOTYPE           ANN    EFFECT   alias ANNOTATION   Effect in Sequence ontology terms  e g   missense variant    synonymous variant    stop gained   etc            ANN    IMPACT    HIGH  MODERATE  LOW  MODIFIER            ANN    GENE  Gene name  e g   PSD3            ANN    GENEID  Gene ID          ANN    FEATURE           ANN    FEATUREID   alias TRID  Transcript ID           ANN    BIOTYPE  Biotype  as described by the annotations  e g   protein coding            ANN    RANK  Exon or Intron rank  i e  exon number in a transcript           ANN    HGVS C   alias HGVS DNA  CODON   Variant in HGVS  DNA  notation          ANN    HGVS P   alias HGVS  HGVS PROT  AA   Variant in HGVS  protein  notation          ANN    CDNA POS   alias POS CDNA           ANN    CDNA LEN   alias LEN CDNA           ANN    CDS POS   alias POS CDS           ANN    CDS LEN   alias LEN CDS           ANN    AA POS   alias POS AA           ANN    AA LEN   alias LEN AA           ANN    DISTANCE           ANN    ERRORS   alias WARNING  INFOS      SnpEff  EFF  fields  this is for older SnpEff SnpSift versions  new version use  ANN  field            EFF    EFFECT           EFF    IMPACT           EFF    FUNCLASS           EFF    CODON           EFF    AA           EFF    AA LEN           EFF    GENE           EFF    BIOTYPE           EFF    CODING           EFF    TRID           EFF    RANK      SnpEff  LOF  fields           LOF    GENE           LOF    GENEID           LOF    NUMTR           LOF    PERC      SnpEff  NMD  fields           NMD    GENE           NMD    GENEID           NMD    NUMTR           NMD    PERC   Some examples      Extracting chromosome  position  ID and allele frequency from a VCF file        CHROM POS ID AF      The result will look something like           CHROM        POS        ID            AF       1             69134                    0 086       1             69496      rs150690004   0 001     Extracting genotype fields        CHROM POS ID THETA GEN 0  GL 1  GEN 1  GL GEN 3  GL    GEN    GT      This means to extract       CHROM POS ID  regular fields  as in the previous example      THETA   This one is from INFO     GEN 0  GL 1    Second likelihood from first genotype     GEN 1  GL   The whole GL fiels  all entries without separating them      GEN 3  GL      All likelihoods form genotype 3  this time they will be tab separated  as opposed to the previous one       GEN    GT   Genotype subfields  GT  from ALL samples  tab separated      The result will look something like           CHROM  POS     ID              THETA   GEN 0  GL 1     GEN 1  GL               GEN 3  GL               GEN    GT       1       10583   rs58108140      0 0046   0 47            0 24  0 44  1 16        0 48    0 48    0 48   0 0     0 0     0 0     0 1     0 0     0 1     0 0     0 0     0 1       1       10611   rs189107123     0 0077   0 48            0 24  0 44  1 16        0 48    0 48    0 48   0 0     0 1     0 0     0 0     0 0     0 0     0 0     0 0     0 0       1       13302   rs180734498     0 0048   0 58            2 45  0 00  5 00        0 48    0 48    0 48   0 0     0 1     0 0     0 0     0 0     1 0     0 0     0 1     0 0     Extracting fields with multiple values      notice that there are multiple effect columns per line because there are mutiple effects per variant       CHROM POS REF ALT ANN    EFFECT      The result will look something like           CHROM POS REF ALT ANN    EFFECT       22 17071756 T C 3 prime UTR variant downstream gene variant       22 17072035 C T missense variant downstream gene variant       22 17072258 C A missense variant downstream gene variant     Extracting fields with multiple values using a comma as a multipe field separator        CHROM POS REF ALT ANN    EFFECT ANN    HGVS P      The result will look something like           CHROM POS REF ALT ANN    EFFECT ANN    HGVS P       22 17071756 T C 3 prime UTR variant downstream gene variant           22 17072035 C T missense variant downstream gene variant p Gly469Glu         22 17072258 C A missense variant downstream gene variant p Gly395Cys       Extracting fields with multiple values  one effect per line        CHROM POS REF ALT ANN    EFFECT      The result will look something like           CHROM POS REF ALT ANN    EFFECT       22 17071756 T C 3 prime UTR variant       22 17071756 T C downstream gene variant       22 17072035 C T missense variant       22 17072035 C T downstream gene variant       22 17072258 C A missense variant       22 17072258 C A downstream gene variant   EXTERNAL DOCUMENTATION     Extract     ,snpSift_extractFields,vcf,SnpSift Extract Fields,tabular
770,Filter variants using arbitrary expressions,,   SnpSift filter    You can filter a VCF file using arbitrary expressions  for instance   QUAL   30     exists INDEL      countHet     2     The actual expressions can be quite complex  so it allows for a lot of flexibility   Some examples      I want just the variants from the second million bases of chr1             CHROM    chr1        POS   1000000       POS   2000000       Filter value is either  PASS  or it is missing            FILTER    PASS       na FILTER       I want to filter lines with an ANN annotation EFFECT of  frameshift variant    for vcf files using Sequence Ontology terms               ANN    EFFECT has  frameshift variant         Important   According to the specification  there can be more than one EFFECT separated by    e g   missense variant splice region variant   thus using has operator is better than using equality operator      For instance  missense variant splice region variant     missense variant  is false  whereas  missense variant splice region variant  has  missense variant  is true      I want to filter lines with an EFF of  FRAME SHIFT    for vcf files using Classic Effect names               EFF    EFFECT    FRAME SHIFT        I want to filter out samples with quality less than 30             QUAL   30          but we also want InDels that have quality 20 or more              exists INDEL      QUAL    20      QUAL    30          or any homozygous variant present in more than 3 samples            countHom     3       exists INDEL      QUAL    20      QUAL    30          or any heterozygous sample with coverage 25 or more             countHet     0     DP    25      countHom     3       exists INDEL      QUAL    20      QUAL    30       I want to keep samples where the genotype for the first sample is homozygous variant and the genotype for the second sample is reference            isHom  GEN 0      isVariant  GEN 0      isRef  GEN 1        For information regarding HGVS and Sequence Ontology terms versus classic names        cmdline for the options   classic   hgvs  and  sequenceOntology    input for the table containing the classic name and sequence onology term for each effect   EXTERNAL DOCUMENTATION     filter     ,snpSift_filter,vcf,SnpSift Filter,vcf
771,Filter variants using intervals,, You can filter using intervals  BED file     EXTERNAL DOCUMENTATION     intervals     ,snpSift_int,"vcf,bed",SnpSift Intervals,vcf
772,remove INFO field annotations,, This command removes INFO fields from a VCF file  i e  removes annotations   Removing INFO fields is usually done because you want to re annotate the VCF file  thus removing old INFO fields in order to add new ones later   SnpEff   SnpSift only add annotations and do not change current ones  So  in order to re annotate a file  you should first remove the old annotations and then re annotate  The reason for this behavior is simply because replacing annotation values is considered a bad practice  Imagine that you have a VCF entry  in your re annotated file having the value  AA 1   How do you know if this is from the old annotations or from the new ones  This confusion often leads to problems in downstream steps of your pipelines  so it s better to avoid the problem by first removing all the previous annotations and then adding the new ones    EXTERNAL DOCUMENTATION     rmInfo     ,snpSift_rmInfo,vcf,SnpSift rmInfo,vcf
773,Annotate with variant type,,This tool uses  SnpSift Variant type   to add the variant type  SNP MNP INS DEL MIXED  in the INFO field  It also adds  HOM HET   but this last one works if there is only one sample  otherwise it doesn t make any sense  ,snpsift_vartype,vcf,SnpSift Variant Type,"vcf,txt"
774,basic checks for VCF specification compliance,, Perform some basic check ups on VCF files to spot common problems   SnpSift vcfCheck checks for some common problems where VCF files are not following the specification  Given that many common VCF problems cause analysis tools and pipelines to behave unexpectedly  this command is intended as a simple debugging tool     EXTERNAL DOCUMENTATION     vcfCheck     ,snpSift_vcfCheck,vcf,SnpSift vcfCheck,vcf
775,Add annotations from dbNSFP or similar annotation DBs,, The dbNSFP is an integrated database of functional predictions from multiple algorithms  SIFT  Polyphen2  LRT and MutationTaster  PhyloP and GERP    etc    It contains variant annotations such as   1000Gp1 AC     Alternative allele counts in the whole 1000 genomes phase 1  1000Gp1  data 1000Gp1 AF     Alternative allele frequency in the whole 1000Gp1 data 1000Gp1 AFR AC     Alternative allele counts in the 1000Gp1 African descendent samples 1000Gp1 AFR AF     Alternative allele frequency in the 1000Gp1 African descendent samples 1000Gp1 AMR AC     Alternative allele counts in the 1000Gp1 American descendent samples 1000Gp1 AMR AF     Alternative allele frequency in the 1000Gp1 American descendent samples 1000Gp1 ASN AC     Alternative allele counts in the 1000Gp1 Asian descendent samples 1000Gp1 ASN AF     Alternative allele frequency in the 1000Gp1 Asian descendent samples 1000Gp1 EUR AC     Alternative allele counts in the 1000Gp1 European descendent samples 1000Gp1 EUR AF     Alternative allele frequency in the 1000Gp1 European descendent samples aaalt     Alternative amino acid      if the variant is a splicing site SNP  2bp on each end of an intron  aapos     Amino acid position as to the protein    1  if the variant is a splicing site SNP  2bp on each end of an intron  aapos SIFT     ENSP id and amino acid positions corresponding to SIFT scores  Multiple entries separated by     aapos FATHMM     ENSP id and amino acid positions corresponding to FATHMM scores  Multiple entries separated by     aaref     Reference amino acid      if the variant is a splicing site SNP  2bp on each end of an intron  alt     Alternative nucleotide allele  as on the   strand  Ancestral allele     Ancestral allele  based on 1000 genomes reference data  cds strand     Coding sequence  CDS  strand    or    chr     Chromosome number codonpos     Position on the codon  1  2 or 3  Ensembl geneid     Ensembl gene ID Ensembl transcriptid     Ensembl transcript IDs  separated by      ESP6500 AA AF     Alternative allele frequency in the African American samples of the NHLBI GO Exome Sequencing Project  ESP6500 data set  ESP6500 EA AF     Alternative allele frequency in the European American samples of the NHLBI GO Exome Sequencing Project  ESP6500 data set  FATHMM pred     If a FATHMM score is    1 5  or rankscore   0 81415  the corresponding non synonymous SNP is predicted as  D AMAGING    otherwise it is predicted as  T OLERATED    Multiple predictions separated by     FATHMM rankscore     FATHMMori scores were ranked among all FATHMMori scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of FATHMMori scores in dbNSFP  If there are multiple scores  only the most damaging  largest  rankscore is presented  The scores range from 0 to 1 FATHMM score     FATHMM default score  FATHMMori  fold degenerate     Degenerate type  0  2 or 3  genename     Gene name  if the non synonymous SNP can be assigned to multiple genes  gene names are separated by     GERP   NR     GERP   neutral rate GERP   RS     GERP   RS score  the larger the score  the more conserved the site GERP   RS rankscore     GERP   RS scores were ranked among all GERP   RS scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of GERP   RS scores in dbNSFP hg18 pos 1 coor      Physical position on the chromosome as to hg18  1 based coordinate  Interpro domain     Domain or conserved site on which the variant locates LR pred     Prediction of our LR based ensemble prediction score   T olerated   or  D amaging    The score cutoff between  D  and  T  is 0 5  The rankscore cutoff between  D  and  T  is 0 82268 LR rankscore     LR scores were ranked among all LR scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of LR scores in dbNSFP  The scores range from 0 to 1 LR score     Our logistic regression  LR  based ensemble prediction score  which incorporated 10 scores  SIFT  PolyPhen 2 HDIV  PolyPhen 2 HVAR  GERP    MutationTaster  Mutation Assessor  FATHMM  LRT  SiPhy  PhyloP  and the maximum frequency observed in the 1000 genomes populations  Larger value means the SNV is more likely to be damaging  Scores range from 0 to 1 LRT Omega     Estimated nonsynonymous to synonymous rate ratio  Omega  reported by LRT  LRT converted rankscore     LRTori scores were first converted as LRTnew 1 LRTori 0 5 if Omega 1  or LRTnew LRTori 0 5 if Omega  1  Then LRTnew scores were ranked among all LRTnew scores in dbNSFP  The rankscore is the ratio of the rank over the total number of the scores in dbNSFP  The scores range from 0 00166 to 0 85682 LRT pred     LRT prediction  D eleterious   N eutral  or U nknown   which is not solely determined by the score LRT score     The original LRT two sided p value  LRTori   ranges from 0 to 1 MutationAssessor pred     MutationAssessor s functional impact of a variant MutationAssessor rankscore     MAori scores were ranked among all MAori scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of MAori scores in dbNSFP  The scores range from 0 to 1 MutationAssessor score     MutationAssessor functional impact combined score  MAori  MutationTaster converted rankscore     The MTori scores were first converted  if the prediction is  A  or  D  MTnew MTori  if the prediction is  N  or  P   MTnew 1 MTori  Then MTnew scores were ranked among all MTnew scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of MTnew scores in dbNSFP  The scores range from 0 0931 to 0 80722 MutationTaster pred     MutationTaster prediction MutationTaster score     MutationTaster p value  MTori   ranges from 0 to 1 phastCons46way placental     phastCons conservation score based on the multiple alignments of 33 placental mammal genomes  including human   The larger the score  the more conserved the site phastCons46way placental rankscore     phastCons46way placental scores were ranked among all phastCons46way placental scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of phastCons46way placental scores in dbNSFP phastCons46way primate     phastCons conservation score based on the multiple alignments of 10 primate genomes  including human   The larger the score  the more conserved the site phastCons46way primate rankscore     phastCons46way primate scores were ranked among all phastCons46way primate scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of phastCons46way primate scores in dbNSFP phastCons100way vertebrate     phastCons conservation score based on the multiple alignments of 100 vertebrate genomes  including human   The larger the score  the more conserved the site phastCons100way vertebrate rankscore     phastCons100way vertebrate scores were ranked among all phastCons100way vertebrate scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of phastCons100way vertebrate scores in dbNSFP phyloP46way placental     phyloP  phylogenetic p values  conservation score based on the multiple alignments of 33 placental mammal genomes  including human   The larger the score  the more conserved the site phyloP46way placental rankscore     phyloP46way placental scores were ranked among all phyloP46way placental scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of phyloP46way placental scores in dbNSFP phyloP46way primate     phyloP  phylogenetic p values  conservation score based on the multiple alignments of 10 primate genomes  including human   The larger the score  the more conserved the site phyloP46way primate rankscore     phyloP46way primate scores were ranked among all phyloP46way primate scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of phyloP46way primate scores in dbNSFP phyloP100way vertebrate     phyloP  phylogenetic p values  conservation score based on the multiple alignments of 100 vertebrate genomes  including human   The larger the score  the more conserved the site phyloP100way vertebrate rankscore     phyloP100way vertebrate scores were ranked among all phyloP100way vertebrate scores in dbNSFP  The rankscore is the ratio of the rank of the score over the total number of phyloP100way vertebrate scores in dbNSFP Polyphen2 HDIV pred     Polyphen2 prediction based on HumDiv Polyphen2 HDIV rankscore     Polyphen2 HDIV scores were first ranked among all HDIV scores in dbNSFP  The rankscore is the ratio of the rank the score over the total number of the scores in dbNSFP  If there are multiple scores  only the most damaging  largest  rankscore is presented  The scores range from 0 02656 to 0 89917 Polyphen2 HDIV score     Polyphen2 score based on HumDiv  i e  hdiv prob  The score ranges from 0 to 1  Multiple entries separated by     Polyphen2 HVAR pred     Polyphen2 prediction based on HumVar Polyphen2 HVAR rankscore     Polyphen2 HVAR scores were first ranked among all HVAR scores in dbNSFP  The rankscore is the ratio of the rank the score over the total number of the scores in dbNSFP  If there are multiple scores  only the most damaging  largest  rankscore is presented  The scores range from 0 01281 to 0 9711 Polyphen2 HVAR score     Polyphen2 score based on HumVar  i e  hvar prob  The score ranges from 0 to 1  Multiple entries separated by     pos 1 coor      Physical position on the chromosome as to hg19  1 based coordinate  RadialSVM pred     Prediction of our SVM based ensemble prediction score   T olerated   or  D amaging    The score cutoff between  D  and  T  is 0  The rankscore cutoff between  D  and  T  is 0 83357 RadialSVM rankscore     RadialSVM scores were ranked among all RadialSVM scores in dbNSFP  The rankscore is the ratio of the rank of the screo over the total number of RadialSVM scores in dbNSFP  The scores range from 0 to 1 RadialSVM score     Our support vector machine  SVM  based ensemble prediction score  which incorporated 10 scores  SIFT  PolyPhen 2 HDIV  PolyPhen 2 HVAR  GERP    MutationTaster  Mutation Assessor  FATHMM  LRT  SiPhy  PhyloP  and the maximum frequency observed in the 1000 genomes populations  Larger value means the SNV is more likely to be damaging  Scores range from  2 to 3 in dbNSFP ref     Reference nucleotide allele  as on the   strand  refcodon     Reference codon Reliability index     Number of observed component scores  except the maximum frequency in the 1000 genomes populations  for RadialSVM and LR  Ranges from 1 to 10  As RadialSVM and LR scores are calculated based on imputed data  the less missing component scores  the higher the reliability of the scores and predictions SIFT converted rankscore     SIFTori scores were first converted to SIFTnew 1 SIFTori  then ranked among all SIFTnew scores in dbNSFP  The rankscore is the ratio of the rank the SIFTnew score over the total number of SIFTnew scores in dbNSFP  If there are multiple scores  only the most damaging  largest  rankscore is presented  The rankscores range from 0 02654 to 0 87932 SIFT pred     If SIFTori is smaller than 0 05  rankscore 0 55  the corresponding non synonymous SNP is predicted as  D amaging    otherwise it is predicted as  T olerated    Multiple predictions separated by     SIFT score     SIFT score  SIFTori   Scores range from 0 to 1  The smaller the score the more likely the SNP has damaging effect  Multiple scores separated by     SiPhy 29way logOdds     SiPhy score based on 29 mammals genomes  The larger the score  the more conserved the site SiPhy 29way pi     The estimated stationary distribution of A  C  G and T at the site  using SiPhy algorithm based on 29 mammals genomes SLR test statistic     SLR test statistic for testing natural selection on codons  A negative value indicates negative selection  and a positive value indicates positive selection  Larger magnitude of the value suggests stronger evidence Uniprot aapos     Amino acid position as to Uniprot  Multiple entries separated by     Uniprot acc     Uniprot accession number  Multiple entries separated by     Uniprot id     Uniprot ID number  Multiple entries separated by     UniSNP ids     rs numbers from UniSNP  which is a cleaned version of dbSNP build 129  in format  rs number1 rs number2      The dbNSFP database is available from  and there is only annotation for human genome builds   The procedure for preparing the dbNSFP data for use in SnpSift dbnsfp and a couple of prebuilt dbNSFP databases are available at   dbNSFP  However  any dbNSFP like tabular file that be can used with SnpSift dbnsfp if it has     The first line of the file must be column headers that name the annotations    The first 4 columns are required and must be     1  chr  chromosome   2  pos 1 coor   position in chromosome   3  ref  reference base   4  alt  alternate base  For example         chr pos 1 coor  ref alt aaref aaalt genename SIFT score     1 69134 A C E A OR4F5 0 03     1 69134 A G E G OR4F5 0 09     1 69134 A T E V OR4F5 0 03     4 100239319 T A H L ADH1B 0     4 100239319 T C H R ADH1B 0 15     4 100239319 T G H P ADH1B 0  The Galaxy datatypes for dbNSFP can automatically convert the specially formatted tabular file for use by SnpSift dbNSFP   1  Upload the tabular file  set the datatype as     dbnsfp tabular    2  Edit the history dataset attributes  pencil icon   Use  Convert Format  to convert the    dbnsfp tabular    to the correct format for SnpSift dbnsfp     snpsiftdbnsfp       EXTERNAL DOCUMENTATION     dbNSFP     ,snpSift_dbnsfp,"vcf,snpsiftdbnsfp",SnpSift dbNSFP,vcf
776,"Annotating GeneSets, such as Gene Ontology, KEGG, Reactome",, This tool uses  SnpSift GeneSets   to add annotations from  MSigDB    a collection of annotated gene sets from different sources including Gene Ontology  GO   KEGG  Reactome       SnpSift GeneSets   geneSets     class   warningmark  The input VCF file must be annotated using SnpEff before performing GeneSets annotations  This is because the tool must know which gene the variant affects    EXTERNAL DOCUMENTATION       MSigDB       ,snpSift_geneSets,"vcf,txt",SnpSift GeneSets,"vcf,txt"
777,Convert VCF data into TAB-delimited format,, Converts VCF dataset to tab delimited format  using null string to replace empty values in the table  Specifying    Report data per sample      g  will output one line per sample with genotype information         Vcf2Tsv  IS PART OF VCFLIB    ,vcf2tsv,vcf,VCFtoTab-delimited:,tabular
778,Adds info fields from the second dataset which are not present in the first dataset,,  Adds info fields from the second dataset which are not present in the first dataset          Vcfaddinfo  IS PART OF VCFLIB  ,vcfaddinfo,vcf,VCFaddinfo:,vcf
779,Split alleleic primitives (gaps or mismatches) into multiple VCF lines,,  If multiple alleleic primitives  gaps or mismatches  are specified in a single VCF record  this tools splits the record into multiple lines  but drops all INFO fields     Pure  MNPs are split into multiple SNPs unless the  m flag is provided   Genotypes are phased where complex alleles have been decomposed  provided genotypes in the input   The options are         m    use mnps          Retain MNPs as separate events  default  false        t    tag parsed FLAG   Tag records which are split apart of a complex allele with this flag       L    max length LEN    Do not manipulate records in which either the ALT or                             REF is longer than LEN  default  200        k    keep info         Maintain site and allele level annotations when decomposing                              Note that in many cases  such as multisample VCFs  these won t                             be valid post decomposition   For biallelic loci in single sample                             VCFs  they should be usable with caution       g    keep geno         Maintain genotype level annotations when decomposing   Similar                             caution should be used for this as for   keep info         Vcfallelicprimitives  IS PART OF VCFLIB      ,vcfallelicprimitives,vcf,VcfAllelicPrimitives:,vcf
780,Intersect VCF records with BED annotations,,  Intersect the records in the VCF file with intervals  features  provided in a BED file  Intersections are done on the reference sequences in the VCF file              class   infomark     Example     The following VCF line      CHROM POS     ID        REF ALT QUAL FILTER INFO                              FORMAT      NA00001        NA00002      NA00003  20     1110696 rs6040355 A   G T 67   PASS   NS 2 DP 10 AF 0 333 0 667 AA T DB GT GQ DP HQ 1 2 21 6 23 27 2 1 2 0 18 2 2 2 35 4      will appear as the follwing after intersectuion with BED records uc010zpo 2  uc002wel 4  uc010zpp 2  and uc002wen      CHROM POS     ID        REF ALT QUAL FILTER INFO                                                                                       FORMAT      NA00001        NA00002      NA00003                                                    20     1110696 rs6040355 A   G T 67   PASS   AA T AF 0 333 0 667 BED features uc010zpo 2 uc002wel 4 uc010zpp 2 uc002wen 4 DP 10 NS 2 DB GT GQ DP HQ 1 2 21 6 23 27 2 1 2 0 18 2 2 2 35 4            Vcfannotate  IS PART OF VCFLIB      ,vcfannotate,"vcf,bed",VCFannotate:,vcf
781,Annotate genotypes in a VCF dataset using genotypes from another VCF dataset,,  Annotates genotypes in the   First   dataset with genotypes from the   Second   adding the genotype as another flag to each sample filled in the first file    Annotation tag   is the name of the sample flag which is added to store the annotation   Also adds a  has  variant  flag for sites where the second file has a variant          Vcfannotate  IS PART OF VCFLIB  ,vcfannotategenotypes,vcf,VCFannotateGenotypes:,vcf
782,Intersect VCF and BED datasets,, Computes intersection between a VCF dataset and a set of genomic intervals defined as either a BED dataset   format1  or a manually typed interval  in the form of chr start end          VCFBEDintersect is based on vcfintersect utility of VCFlib toolkit developed by Erik Garrison       ,vcfbedintersect,"vcf,bed",VCF-BEDintersect:,vcf
783,"Break multiple alleles into multiple records, or combine overallpoing alleles into a single record",, This tool breaks or creates multiallelic VCF records based on user selection    Break   or   Create    respectively         Break     If multiple alleles are specified in a single record  break the record into multiple lines  preserving allele specific INFO fields       Create     If overlapping alleles are represented across multiple records  merge them into a single record         This tools is based on vcfbreakmulti and vcfcreatemulti utilities from the VCFlib toolkit developed by Erik Garrison       ,vcfbreakcreatemulti,vcf,VCFbreakCreateMulti:,vcf
784,Verify that the reference allele matches the reference genome,,  Verifies that the VCF REF field matches the reference as described     The options are         x    exclude failures If a record fails  don t print it   Otherwise do       k    keep failures    Print if the record fails  otherwise not         Vcfcheck  IS PART OF VCFLIB      ,vcfcheck,"vcf,fasta",VCFcheck:,vcf
785,Combine multiple VCF datasets,,  Combines VCF files positionally  combining samples when sites and alleles are identical  Any number of VCF files may be combined  The INFO field and other columns are taken from one of the files  which are combined when records in multiple files match  Alleles must have identical ordering to be combined into one record  If they do not  multiple records will be emitted          Vcfcombine  IS PART OF VCFLIB      ,vcfcombine,vcf,VCFcombine:,vcf
786,Output records belonging to samples common between two datasets,,  Outputs each record in the first file  removing samples not present in the second         Vcfcommonsamples  IS PART OF VCFLIB  ,vcfcommonsamples,vcf,VCFcommonSamples:,vcf
787,Calculate distance to the nearest variant,,  Adds a value to each VCF record indicating the distance to the nearest variant in the file      class   infomark  The dataset used as input to this tool must be coordinate sorted  This can be achieved by either using the VCFsort utility or Galaxy s general purpose sort tool  in this case sort on the first and the second column in ascending order          Vcfdistance  IS PART OF VCFLIB  ,vcfdistance,vcf,VCFdistance:,vcf
788,filter VCF data in a variety of attributes,, You can specify the following options within the   Specify filtering expression   box in any combination         f    info filter     specifies a filter to apply to the info fields of records  removes alleles which do not pass the filter      g    genotype filter specifies a filter to apply to the genotype fields of records      s    filter sites    filter entire records  not just alleles      t    tag pass        tag vcf records as positively filtered with this tag  print all records      F    tag fail        tag vcf records as negatively filtered with this tag  print all records      A    append filter   append the existing filter tag  don t just replace it      a    allele tag      apply  t on a per allele basis   adds or sets the corresponding INFO field tag      v    invert          inverts the filter  e g  grep  v      o    or              use logical OR instead of AND to combine filters      r    region          specify a region on which to target the filtering  must be used in conjunction with  f or  g   Filters are specified in the form  ID   operator   value       f  DP   10             for info fields   g  GT   1 1            for genotype fields   f  CpG                 for  flag  fields  Any number of filters may be specified   They are combined via logical AND unless the   or option is specified  For convenience  you can specify  QUAL  to refer to the quality of the site  even though it does not appear in the INFO fields   Operators can be any of              pipe      To restrict output to a specific location use the  r option  must be used in conjunction with  g or  f       r chr20 14000 15000    only output calls between positions 14 000 and 15 000 on chromosome 20   r chrX                 only output call on chromosome X         Vcffilter  IS PART OF VCFLIB      ,vcffilter2,vcf,VCFfilter:,vcf
789,Count the allele frequencies across alleles present in each record in the VCF file,,  Uses genotypes from the selected VCF dataset to correct AC  alternate allele count   AF  alternate allele frequency   NS  number of called   in the VCF records         Vcffixup  IS PART OF VCFLIB  ,vcffixup,vcf,VCFfixup:,vcf
790,Removes multi-allelic sites by picking the most common alternate,,  Removes multi allelic sites by picking the most common alternate   Requires allele frequency specification  AF  and use of  G  and  A  to specify the fields which vary according to the Allele or Genotype         Vcfflatten  IS PART OF VCFLIB  ,vcfflatten2,vcf,VCFflatten:,vcf
791,Convert genotype-based phased alleles into haplotype alleles,,  Convert genotype based phased alleles within a window size specified by  w option into haplotype alleles  Will break haplotype construction when encountering non phased genotypes on input   The options are         w    window size N     Merge variants at most this many bp apart  default 30       o    only variants     Don t output the entire haplotype  just concatenate                             REF ALT strings  delimited by             Vcfgeno2haplo  IS PART OF VCFLIB  ,vcfgeno2haplo,"vcf,fasta",VCFgenotype-to-haplotype:,vcf
792,Convert numerical representation of genotypes to allelic,,  Converts numerical representation of genotypes  standard in GT field  to the alleles provided in the call s ALT REF fields         Vcfgenotypes  IS PART OF VCFLIB  ,vcfgenotypes,vcf,VCFgenotypes:,tabular
793,"Count the number of heterozygotes and alleles, compute het/hom ratio",,  This tool performs three basic calculations     1  Computes the number of heterozygotes  2  Computes the ratio between heterozygotes and homozygotes  3  Computes the total number of alleles in the input dataset        This tools is based on vcfhetcount  vcfhethomratio and vcfcountalleles utilities from the VCFlib toolkit developed by Erik Garrison                                                                                                                                     ,vcfhethom,vcf,VCFhetHomAlleles:,tabular
794,Left-align indels and complex variants in VCF dataset,,  Left aligns variants in VCF dataset   Window size is determined dynamically according to the entropy of the regions flanking the indel   These must have entropy   1 bit bp  or be shorter than  5kb         Vcfleftalign  IS PART OF VCFLIB  ,vcfleftalign,"vcf,fasta",VCFleftAlign:,vcf
795,Extract flanking sequences for each VCF record,,  For each VCF record  extract the flanking sequences  and write them as FASTA records suitable for alignment   This tool is intended for use in designing validation experiments   Primers extracted which would flank all of the alleles at multi allelic sites   The name of the FASTA  reads  indicates the VCF record which they apply to  The form is  CHROM POS LEFT for the 3  primer and  CHROM POS RIGHT for the 5  primer  for example      20 233255 LEFT  CCATTGTATATATAGACCATAATTTCTTTATCCAATCATCTGTTGATGGA   20 233255 RIGHT  ACTCAGTTGATTCCATACCTTTGCCATCATGAATCATGTTGTAATAAACA        Vcfprimers  IS PART OF VCFLIB  ,vcfprimers,"vcf,fasta",VCFprimers:,fasta
796,Randomly sample sites from VCF dataset,, Randomly sample sites from an input VCF dataset  Scale the sampling probability by the field specified by   scale by  see advanced controls    This may be used to provide uniform sampling across allele frequencies  for instance  AF field in this case          Vcfrandomsample  IS PART OF VCFLIB      ,vcfrandomsample,vcf,VCFrandomSample:,vcf
797,Select samples from a VCF dataset,,  Allows to keep or remove samples from a VCF file             class   infomark     Example     Selecting  NA00001  and  NA00003  from the following VCF line      CHROM POS     ID        REF ALT QUAL FILTER INFO                              FORMAT      NA00001        NA00002      NA00003  20     1110696 rs6040355 A   G T 67   PASS   NS 2 DP 10 AF 0 333 0 667 AA T DB GT GQ DP HQ 1 2 21 6 23 27 2 1 2 0 18 2 2 2 35 4      will  obviously  remove  NA00002       CHROM POS     ID        REF ALT QUAL FILTER INFO                              FORMAT      NA00001        NA00003                                                    20     1110696 rs6040355 A   G T 67   PASS   NS 2 DP 10 AF 0 333 0 667 AA T DB GT GQ DP HQ 1 2 21 6 23 27 2 2 35 4            Vcfselectsamples is based on vcfkeepsamples vcfremovesamples utilities from   VCFlib   toolkit developed by Erik Garrison   ,vcfselectsamples,vcf,VCFselectsamples:,vcf
798,Sort VCF dataset by coordinate,, This tool uses native UNIX sort command to order VCF dataset in coordinate order  For technically inclined the command is      grep      INPUT file   grep  v      INPUT file   LC ALL C sort  k1 1  k2 2n  V    OUTPUT file     class   infomark  The same result can be achieved with the Galaxy s general purpose sort tool  in this case sort on the first and the second column in ascending order       ,vcfsort,vcf,VCFsort:,vcf
799,Intersect two VCF datasets,, Computes intersections and unions for two VCF datasets  Unifies equivalent alleles within window size bp   The options are         v    invert              invert the selection  printing only records which would      i    intersect vcf FILE  use this VCF for set intersection generation      u    union vcf FILE      use this VCF for set union generation      w    window size N       compare records up to this many bp away  default 30       l    loci                output whole loci when one alternate allele matches      m    ref match           intersect on the basis of record REF string      t    tag TAG             attach TAG to each record s info field if it would intersect      V    tag value VAL       use this value to indicate that the allele is passing                                   will be used otherwise   default   PASS       M    merge from FROM TAG      T    merge to   TO TAG   merge from FROM TAG used in the  i file  setting TO TAG                               in the current file         VCFVCFintersect is based on vcfintersect utility of VCFlib toolkit developed by Erik Garrison       ,vcfvcfintersect,"vcf,fasta",VCF-VCFintersect:,vcf
800,to an existing dataset,,You can enter any value and it will be added as a new column to your dataset,addValue,tabular,Add column,input
801,for a set of genomic intervals,,Takes an input set of intervals and for each interval determines the base coverage of the interval by a set of features  tables  available from UCSC  Genomic regions from the input feature data have been merged by overlap   direct adjacency  e g  a table having ranges of  1 10  6 12  12 20 and 25 28 results in two merged ranges of  1 20 and 25 28  ,Annotation_Profiler_0,interval,Profile Annotations,input
802, ,,This tool uses the  regsubsets  function from R statistical package for regression subset selection  It outputs two files  one containing a table with the best subsets and the corresponding summary statistics  and the other containing the graphical representation of the results   ,BestSubsetsRegression1,tabular,Perform Best-subsets Regression,"input,pdf"
803,the percentage of reads supporting each nucleotide at each location,,  2nd column  chromosome location ,generate_coverage_report,tabular,Polymorphism of the Reads,tabular
804,in wiggle format,,     ,blat2wig,tabular,Coverage of the Reads,wig
805,,,Bowtie  is a short read aligner designed to be ultrafast and memory efficient  It is developed by Ben Langmead and Cole Trapnell  Please cite  Langmead B  Trapnell C  Pop M  Salzberg SL  Ultrafast and memory efficient alignment of short DNA sequences to the human genome  Genome Biology 10 R25 ,bowtie_wrapper,"bowtie_base_index,fasta,fastqsanger,fastqillumina,fastqsolexa",Map with Bowtie for Illumina,"sam,txt,fastq"
806, ,,This tool uses functions from  yacca  library from R statistical package to perform Canonical Correlation Analysis  CCA  on the input data  It outputs two files  one containing the summary statistics of the performed CCA  and the other containing helioplots  which display structural loadings of X and Y variables on different canonical components    ,cca1,tabular,Canonical Correlation Analysis,"input,pdf"
807,satisfying criteria,,The program takes as input a set of categories  such that each category contains many elements  It also takes a table relating elements with criteria  such that each element is assigned a number representing the number of times the element satisfies a certain criterion  ,categorize_elements_satisfying_criteria,tabular,Categorize Elements,tabular
808,Control-based ChIP-seq Analysis Tool,,This tool allows ChIP seq peak region calling using CCAT ,peakcalling_ccat,bed,CCAT,"interval,txt"
809,"
        remove duplicates and detect chimaeras in sequencing reads
    ",,cd hit dup is a simple tool for removing duplicates from sequencing reads  with optional step to detect and remove chimeric reads  ,cd_hit_dup,"fastqsanger,fasta",cd-hit-dup,"fastqsanger,tabular"
810, of selected columns,,This tool selects specified columns from a dataset and converts the values of those columns to upper or lower case ,ChangeCase,txt,Change Case,tabular
811,multiple sequence alignment program for DNA or proteins,,   Note    This tool allows you to run a multiple sequence alignment with ClustalW  using the default options   You can align DNA or protein sequences in the input file which should be multiple sequences to be aligned in a FASTA file   The alignments will appear as a clustal format file or optionally  as PHYLIP or FASTA format files in your history  If you choose FASTA as the output format  you can create a  Logo  image using the Sequence Logo tool   If Clustal format is chosen  you have the option of adding basepair counts to the output   A subsequence of the alignment can be output by setting the Output complete parameter to  Partial  and defining the offset and end of the subsequence to be output           Attribution    The first iteration of this Galaxy wrapper was written by Hans Rudolf Hotz   It was modified by Ross Lazarus for the rgenetics project   tests and some additional parameters were added   This wrapper is released licensed under the LGPL        ClustalW        LGPL       ,clustalw,fasta,ClustalW,"clustal,nhx"
812,an expression on every row,,This tool computes an expression for every row of a dataset and appends the result as a new column  field  ,Add_a_column1,tabular,Compute,input
813,motif by motif,,This program computes the frequencies of each motif at a window size  determined by the user  in both upstream and downstream sequences flanking indels in all chromosomes ,compute_motif_frequencies_for_all_motifs,tabular,Compute Motif Frequencies For All Motifs,tabular
814,in indel flanking regions,,This program computes the frequency of motifs in the flanking regions of indels found in a chromosome or a genome  Each indel has an upstream flanking sequence and a downstream flanking one  Each of the upstream and downstream flanking  sequences will be divided into a certain number of windows according to the window size input by the user   The frequency of a motif in a certain window in one of the two flanking sequences is the total sum of occurrences of  that motif in that window of that flanking sequence over all indels  The indel flanking regions file will be taken from your history or it will be uploaded  whereas the motifs file should be uploaded ,compute_motifs_frequency,tabular,Compute Motif Frequencies,tabular
815,based on multiple simultaneous tests p-values,,This program computes the q values based on the p values of multiple simultaneous tests  The q values are computed using a specific R package  created by John Storey and Alan Dabney  called  qvalue   The program takes five inputs      The first input is a TABULAR format file consisting of one column only that represents the p values of multiple simultaneous tests  one line for every p value     The second input is the lambda parameter  The user can choose either the default  seq 0  0 95  0 05  or a decimal number between 0 0 and 1 0    The third input is PI method which is either  smoother  or  bootstrap     The fourth input is the FDR  false discovery rate  level which is a decimal number between 0 0 and 1 0    The fifth input is either TRUE or FALSE for the estimate robustness  ,compute_q_values,tabular,Compute q-values,"tabular,pdf"
816,consecutive characters,,This tool condenses all consecutive characters of a specified type ,Condense characters1,txt,Condense,input
817,delimiters to TAB,,Converts all delimiters of a specified type into TABs   Consecutive characters are condensed  For example  if columns are separated by 5 spaces they will converted into 1 tab ,Convert characters1,txt,Convert,tabular
818, to Nucleotides ,,This tool converts a color space sequence to nucleotides  The leading character must be a nucleotide  A  C  G  or T          ,color2nuc,txt,Convert Color Space,fasta
819,for numeric columns,,     class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert      class   warningmark  Missing data   nan   removed from each pairwise comparison           Syntax    This tool computes the matrix of correlation coefficients between numeric columns     All invalid  blank and comment lines are skipped when performing computations   The number of skipped lines is displayed in the resulting history item       Pearson s Correlation   reflects the degree of linear relationship between two variables  It ranges from  1 to  1  A correlation of  1 means that there is a perfect positive linear relationship between variables  The formula for Pearson s correlation is          image   pearson png      where n is the number of items      Kendall s rank correlation   is used to measure the degree of correspondence between two rankings and assessing the significance of this correspondence  The formula for Kendall s rank correlation is          image   kendall png      where n is the number of items  and P is the sum       Spearman s rank correlation   assesses how well an arbitrary monotonic function could describe the relationship between two variables  without making any assumptions about the frequency distribution of the variables  The formula for Spearman s rank correlation is         image   spearman png      where D is the difference between the ranks of corresponding values of X and Y  and N is the number of pairs of values            Example      Input file         Person Height Self Esteem     1  68  4 1     2   71   4 6     3   62   3 8     4   75   4 4     5   58   3 2     6   60   3 1     7   67   3 8     8   68   4 1     9   71   4 3     10   69   3 7     11   68   3 5     12   67   3 2     13   63   3 7     14   62   3 3     15   60   3 4     16   63   4 0     17   65   4 1     18   67   3 8     19   63   3 4     20   61   3 6    Computing the correlation coefficients between columns 2 and 3 of the above file  using Pearson s Correlation   the output is        1 0 0 730635686279     0 730635686279 1 0    So the correlation for our twenty cases is  73  which is a fairly strong positive relationship    ,cor2,tabular,Correlation,txt
820,,,         Counts the number of features in a GFF dataset  GFF features are often spread across multiple lines  this tool counts the number of          features in dataset rather than the number of lines      ,count_gff_features,gff,Count GFF Features,txt
821,"analysis of chemicals, diseases, or genes",,This tool extracts data related to the provided list of identifiers from the Comparative Toxicogenomics Database  CTD    The fields extracted vary with the type of data requested  the first row of the output identifies the columns ,ctdBatch_1,tabular,CTD,tabular
822,visualize Cuffdiff output,, This tool allows for persistent storage  access  exploration  and manipulation of Cufflinks high throughput sequencing data  In addition  provides numerous plotting functions for commonly used visualizations           Based on the  cummeRbund wrapper     written by James E  Johnson of the Minnesota Supercomputing Institute      ,cummeRbund,sqlite,cummeRbund,txt
823,tabular files from a cummeRbund database,,This tool extracts cuffdiff tabular files from a cummeRbund SQLite database ,cummerbund_to_cuffdiff,sqlite,Extract CuffDiff,tabular
824,columns from a table,,This tool selects  cuts out  specified columns from the dataset ,Cut1,txt,Cut,tabular
825,from a chromosome indels file,,This program detects overlapping indels in a chromosome and keeps all non overlapping indels  As for overlapping indels  the first encountered one is kept and all others are removed   It requires three inputs  ,delete_overlapping_indels,tabular,Delete Overlapping Indels,tabular
826,database info,, Annotates a tabular dataset with information from the  Drug Gene Interations database                 ,dgidb_annotate,tabular,Annotate with DGI,tabular
827,into columns,,This separates the alleles from a pgSnp dataset into separate columns  as well as the frequencies and scores that go with the alleles   It will skip any positions with more than 2 alleles   If only a single allele is given then  N  will be used for the second  with a frequency and score of zero   Or  if a  column with reference alleles is provided   the value in that column will be used in place of the  N  for single alleles ,dividePgSnp,interval,Separate pgSnp alleles,interval
828,of a numeric column,,     class   infomark    TIP    To remove comment lines that do not begin with a     character  use  Text Manipulation  Remove beginning       class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    This tool computes a histogram of the numerical values in a column of a dataset     All invalid  blank and comment lines in the dataset are skipped   The number of skipped lines is displayed in the resulting history item      Column for x axis     only numerical columns are possible      Number of breaks bars      breakpoints between histogram cells  Value of  0  will determine breaks automatically      Plot title     the histogram title      Label for x axis     the label of the x axis for the histogram      Include smoothed density     if checked  the resulting graph will join the given corresponding points with line segments            Example      Input file        1 68 4 1     2 71 4 6     3 62 3 8     4 75 4 4     5 58 3 2     6 60 3 1     7 67 3 8     8 68 4 1     9 71 4 3     10 69 3 7     Create a histogram on column 2 of the above dataset       image   histogram2 png  ,histogram_rpy,tabular,Histogram,pdf
829,for different categories and different criteria,,This program draws  in a pdf file  a stacked bars plot for different categories of data and for different criteria  For each criterion a stacked bar is drawn  such that the height of each stacked sub bar represents the number of elements in each category satisfying that criterion ,draw_stacked_barplots,tabular,Draw Stacked Bar Plots,pdf
830,between two datasets using Discrete Wavelet Transfoms,,This program generates plots and computes table matrix of coefficient correlations and p values at multiple scales for the correlation between the occurrences of features in one dataset and their occurrences in another using multiscale wavelet analysis technique  ,compute_p-values_correlation_coefficients_feature_occurrences_between_two_datasets_using_discrete_wavelet_transfom,tabular,Compute P-values and Correlation Coefficients for Feature Occurrences,"tabular,pdf"
831,between two datasets using Discrete Wavelet Transfoms,,This program generates plots and computes table matrix of coefficient correlations and p values at multiple scales for the correlation between the occurrences of features in one dataset and their occurrences in another using multiscale wavelet analysis technique  ,compute_p-values_correlation_coefficients_featureA_featureB_occurrences_between_two_datasets_using_discrete_wavelet_transfom,tabular,Compute P-values and Correlation Coefficients for Occurrences of Two Set of Features,"tabular,pdf"
832,between two datasets using Discrete Wavelet Transfoms,,This program generates plots and computes table matrix of second moments  p values  and test orientations at multiple scales for the correlation between the occurrences of features in one dataset and their occurrences in another using multiscale wavelet analysis technique  ,compute_p-values_second_moments_feature_occurrences_between_two_datasets_using_discrete_wavelet_transfom,tabular,Compute P-values and Second Moments for Feature Occurrences,"tabular,pdf"
833,in one dataset using Discrete Wavelet Transfoms,,This program generates plots and computes table matrix of maximum variances  p values  and test orientations at multiple scales for the occurrences of a class of features in one dataset of DNA sequences using multiscale wavelet analysis technique  ,compute_p-values_max_variances_feature_occurrences_in_one_dataset_using_discrete_wavelet_transfom,tabular,Compute P-values and Max Variances for Feature Occurrences,"tabular,pdf"
834,using Discrete Wavelet Transfoms,,This tool computes the scale specific variance in wavelet coeffients obtained from the discrete wavelet transform of a feature of interest ,dwt_var1,tabular,Wavelet variance,"tabular,pdf"
835,Quantify the abundances of a set of target sequences from sampled subsequences,,   eXpress Overview    eXpress is a streaming tool for quantifying the abundances of a set of target sequences from sampled subsequences  Example applications include transcript level RNA Seq quantification  allele specific haplotype expression analysis  from RNA Seq   transcription factor binding quantification in ChIP Seq  and analysis of metagenomic data       Ensembl             Input format    eXpress requires two input files     A multi FASTA file containing the transcript sequences    Read alignments to the multi FASTA file in BAM or SAM format             Outputs      The output for eXpress is saved in a file called results xprs in an easy to parse tab delimited format     Also  params xprs contains the values of the other parameters  besides abundances and counts  estimated by eXpress     If you choose to use to calculate the covariance between targets and outputs  an other output would be   varcov xprs      ,express,"fasta,sam,bam",eXpress,txt
836,,,This tool counts the length of each fasta sequence in the file  The output file has two columns per line  separated by tab   fasta titles and lengths of the sequences  The option  How many characters to keep   allows to select a specified number of letters from the beginning of each FASTA entry ,fasta_compute_length,fasta,Compute sequence length,tabular
837,FASTA alignment by species,,       ,fasta_concatenate0,fasta,Concatenate,fasta
838,,,  Example  ,fasta_filter_by_length,fasta,Filter sequences by length,fasta
839,converter,,This tool converts FASTA formatted sequences to TAB delimited format ,fasta2tab,fasta,FASTA-to-Tabular,tabular
840,by sliding window,,This tool allows you to trim the ends of reads based upon the aggregate value of quality scores found within a sliding window  a sliding window of size 1 is equivalent to  simple  trimming of the ends ,fastq_quality_trimmer,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",FASTQ Quality Trimmer,
841,extracts sequences and quality scores from FASTQSOLEXA data,,This tool extracts sequences and quality scores from FASTQ data   Solexa variant    producing a FASTA dataset and a QUAL dataset ,fastqsolexa_to_fasta_qual,fastqsolexa,FASTQSOLEXA-to-FASTA-QUAL,"fasta,qualsolexa"
842,,,This tool finds the coverage of intervals in the first dataset on intervals in the second dataset  The coverage and count are appended as 4 new columns in the resulting dataset ,featureCoverage1,interval,Feature coverage,interval
843,for using PC and LDA,,This tool consists of a module to generate a matrix to be used for running the Linear Discriminant Analysis as described in Carrel et al   2006  PMID  17009873 ,generate_matrix_for_pca_and_lda1,tabular,Generate A Matrix,tabular
844, for 3-way alignments,,This tool estimates the insertion and deletion rates for alignments in a window of specified size  Rates are computed over the total adjusted lengths  adjusted by disregarding masked bases  of all the alignments blocks from the indel file that fall within that window          ,indelRates_3way,"tabular,interval",Estimate Indel Rates,tabular
845, from pairwise alignments,,This tool estimates the number of indels for every alignment block of the MAF file  ,getIndels_2way,maf,Fetch Indels,tabular
846,Multiple Alignment Viewer,,GMAJ is an interactive viewer for MAF alignments  with support for optional annotation data   In addition to browsing the alignments  you can select and export them according to a variety of criteria and send the output back to your Galaxy history ,gmaj_1,"maf,bed,gff",GMAJ,gmaj.zip
847,spliced aligner,, Introduction               What is HISAT                   HISAT      is a fast and sensitive spliced alignment program  As part of HISAT  we have developed a new indexing scheme based on the Burrows Wheeler transform   BWT       and the  FM index       called hierarchical indexing  that employs two types of indexes   1  one global FM index representing the whole genome  and  2  many separate local FM indexes for small regions collectively covering the genome  Our hierarchical index for the human genome  about 3 billion bp  includes  48 000 local FM indexes  each representing a genomic region of  64 000bp  As the basis for non gapped alignment  the FM index is extremely fast with a low memory footprint  as demonstrated by  Bowtie       In addition  HISAT provides several alignment strategies specifically designed for mapping different types of RNA seq reads  All these together  HISAT enables extremely fast and sensitive alignment of reads  in particular those spanning two exons or more  As a result  HISAT is much faster  50 times than  TopHat2      with better alignment quality  Although it uses a large number of indexes  the memory requirement of HISAT is still modest  approximately 4 3 GB for human  HISAT uses the  Bowtie2      implementation to handle most of the operations on the FM index  In addition to spliced alignment  HISAT handles reads involving indels and supports a paired end alignment mode  Multiple processors can be used simultaneously to achieve greater alignment speed  HISAT outputs alignments in  SAM      format  enabling interoperation with a large number of other tools  e g   SAMtools        GATK       that use SAM  HISAT is distributed under the  GPLv3 license       and it runs on the command line under Linux  Mac OS X and Windows   Running HISAT                Reporting            The reporting mode governs how many alignments HISAT looks for  and how to report them   In general  when we say that a read has an alignment  we mean that it has a  valid alignment   valid alignments meet or exceed the minimum score threshold      When we say that a read has multiple alignments  we mean that it has multiple alignments that are valid and distinct from one another   Distinct alignments map a read to different places                                                     Two alignments for the same individual read are  distinct  if they map the same read to different places  Specifically  we say that two alignments are distinct if there are no alignment positions where a particular read offset is aligned opposite a particular reference offset in both alignments with the same orientation  E g  if the first alignment is in the forward orientation and aligns the read character at read offset 10 to the reference character at chromosome 3  offset 3 445 245  and the second alignment is also in the forward orientation and also aligns the read character at read offset 10 to the reference character at chromosome 3  offset 3 445 245  they are not distinct alignments   Two alignments for the same pair are distinct if either the mate 1s in the two paired end alignments are distinct or the mate 2s in the two alignments are distinct or both   Default mode  search for one or more alignments  report each                                                               HISAT searches for up to N distinct  primary alignments for each read  where N equals the integer specified with the    k   parameter  Primary alignments mean alignments whose alignment score is equal or higher than any other alignments  It is possible that multiple distinct alignments whave the same score  That is  if    k 2   is specified  HISAT will search for at most 2 distinct alignments  The alignment score for a paired end alignment equals the sum of the alignment scores of the individual mates  Each reported read or pair alignment beyond the first has the SAM  secondary  bit  which equals 256  set in its FLAGS field  See the  SAM specification      for details   HISAT does not  find  alignments in any specific order  so for reads that have more than N distinct  valid alignments  HISAT does not gaurantee that the N alignments reported are the best possible in terms of alignment score  Still  this mode can be effective and fast in situations where the user cares more about whether a read aligns  or aligns a certain number of times  than where exactly it originated   Alignment summmary                     When HISAT finishes running  it prints messages summarizing what happened  These messages are printed to the  standard error    stderr   filehandle  For datasets consisting of unpaired reads  the summary might look like this           20000 reads  of these        20000  100 00   were unpaired  of these          1247  6 24   aligned 0 times         18739  93 69   aligned exactly 1 time         14  0 07   aligned  1 times     93 77  overall alignment rate  For datasets consisting of pairs  the summary might look like this           10000 reads  of these        10000  100 00   were paired  of these          650  6 50   aligned concordantly 0 times         8823  88 23   aligned concordantly exactly 1 time         527  5 27   aligned concordantly  1 times                      650 pairs aligned concordantly 0 times  of these            34  5 23   aligned discordantly 1 time                      616 pairs aligned 0 times concordantly or discordantly  of these            1232 mates make up the pairs  of these              660  53 57   aligned 0 times             571  46 35   aligned exactly 1 time             1  0 08   aligned  1 times     96 70  overall alignment rate  The indentation indicates how subtotals relate to totals          ,hisat,"fasta,fastq,gtf",HISAT,bam
848,of a numeric column,,     class   infomark    TIP    To remove comment lines that do not begin with a     character  use  Text Manipulation  Remove beginning       class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    This tool computes a histogram of the numerical values in a column of a dataset     All invalid  blank and comment lines in the dataset are skipped   The number of skipped lines is displayed in the resulting history item      Column for x axis     only numerical columns are possible      Number of breaks bars      breakpoints between histogram cells  Value of  0  will determine breaks automatically      Plot title     the histogram title      Label for x axis     the label of the x axis for the histogram      Include smoothed density     if checked  the resulting graph will join the given corresponding points with line segments            Example      Input file        1 68 4 1     2 71 4 6     3 62 3 8     4 75 4 4     5 58 3 2     6 60 3 1     7 67 3 8     8 68 4 1     9 71 4 3     10 69 3 7     Create a histogram on column 2 of the above dataset       image   histogram2 png  ,histogram_rpy,tabular,Histogram,pdf
849, from 3-way alignments,,This tool consists of the first module from the computational pipeline to identify indels as described in Kvikstad et al   2007  Note that the generated output does not include subsequent filtering steps ,indels_3way,maf,Fetch Indels,tabular
850, ,,This tool uses functions from  kernlab  library from R statistical package to perform Kernel Canonical Correlation Analysis  kCCA  on the input data  ,kcca1,tabular,Kernel Canonical Correlation Analysis,input
851, ,,This tool uses functions from  kernlab  library from R statistical package to perform Kernel Principal Component Analysis  kPCA  on the input data  It outputs two files  one containing the summary statistics of the performed kPCA  and the other containing a scatterplot matrix of rotated values reported by kPCA    ,kpca1,tabular,Kernel Principal Component Analysis,"input,pdf"
852, map short reads against reference sequence,,     here           ,lastz_wrapper_2,fasta,Lastz,tabular
853, map short paired reads against reference sequence,,     here           ,lastz_paired_reads_wrapper,"fasta,qual454",Lastz paired reads,sam
854,Linear Discriminant Analysis,,This tool consists of the module to perform the Linear Discriminant Analysis as described in Carrel et al   2006  PMID  17009873 ,lda_analy1,tabular,Perform LDA,txt
855, ,,This tool uses the  lm  function from R statistical package to perform linear regression on the input data  It outputs two files  one containing the summary statistics of the performed regression  and the other containing diagnostic plots to check whether model assumptions are satisfied    ,LinearRegression1,tabular,Perform Linear Regression,"input,pdf"
856, ,,This tool uses the    glm    function from R statistical package to perform logistic regression on the input data  It outputs one file containing the summary statistics of the performed regression  Also  it calculates VIF Variance Inflation Factor  with    vif    function from library  car  in R ,LogisticRegression,tabular,Perform Logistic Regression with vif,input
857,Model-based Analysis of ChIP-Seq,,This tool allows ChIP seq peak calling using MACS ,peakcalling_macs,"elandmulti,bed,sam,bam,eland,elandmulti",MACS,"bed,interval,wig,html"
858, from MAF file,,This tool takes a MAF file as input and masks CpG sites in every alignment block of the MAF file  ,cpgFilter,maf,Mask CpG/non-CpG sites,maf
859, as UCSC custom track,,This tool turns mapping data generated by short read mappers into a format that can be displayed in the UCSC genome browser as a custom track  ,mapToUCSC,tabular,Format mapping data,customtrack
860," compare short reads against htgs, nt, and wgs databases",,This tool runs   megablast   function of BLAST  blastn tool   a high performance nucleotide local aligner developed by Webb Miller and colleagues ,megablast_wrapper,fasta,Megablast,tabular
861,,,This tool processes the XML output of any NCBI blast tool  if you run your own blast jobs  the XML output can be generated with    m 7   option  ,megablast_xml_parser,blastxml,Parse blast XML output,tabular
862,together,,This tool merges columns together  Any number of valid columns can be merged in any order ,mergeCols1,tabular,Merge Columns,tabular
863, and causal mutational mechanisms from previously identified orthologous microsatellite sets,,This tool uses raw orthologous microsatellite clusters  identified by the tool  Extract orthologous microsatellites   to identify microsatellite births and deaths along individual lineages of a phylogenetic tree ,microsatellite_birthdeath,"maf,txt",Identify microsatellite births and deaths,txt
864, from pair-wise alignments,,This tool uses a modified version of SPUTNIK to fetch microsatellite repeats from the input fasta sequences and extracts orthologous repeats from the sputnik output  The modified version allows detection of mononucleotide microsatellites  More information on SPUTNIK can be found on this website   The modified version is available here  ,microsats_align1,fasta,Extract Orthologous Microsatellites,tabular
865,by specified attributes,,This tool computes microsatellite mutability for the orthologous microsatellites fetched from   Extract Orthologous Microsatellites from pair wise alignments  tool ,microsats_mutability1,"tabular,interval",Estimate microsatellite mutability,tabular
866,- Maximal Information-based Nonparametric Exploration,,Applies the Maximal Information based Nonparametric Exploration strategy to an input dataset ,maximal_information_based_nonparametric_exploration,csv,MINE,"csv,txt"
867, for multiple (>2) species alignments,,This tool finds ortholgous microsatellite blocks between aligned species         ,multispecies_orthologous_microsats,maf,Extract orthologous microsatellites,txt
868,with SNPs,, This tool takes an interval file as input   This input should contain a set of codon locations and corresponding DNA sequence  such as from the  Extract Genomic DNA  tool  joined to SNP locations with observed values  such as  all fields from selected table  from the snp130 table of hg18 at the UCSC Table browser    This interval file should have the metadata  chromosome  start  end  strand  set for the columns containing the locations of the codons  The user needs to specify the columns containing the sequence for the codon as well as the genomic positions and observed values  values should be split by      for the SNP data as tool input  SNPs positions and sequence substitutes must have a length of exactly 1  Only genomic intervals which yield a different sequence string are output  All sequence characters are converted to uppercase during processing       For example  using these settings           metadata     chromosome      start      end   and   strand   set to   1      2      3   and   6    respectively       Codon Sequence column   set to   c8         SNP chromosome column   set to   c17         SNP start column   set to   c18         SNP end column   set to   c19         SNP strand column   set to   c22         SNP observed column   set to   c25        with the following input          chr1 58995 58998 NM 001005484 0   GAA GAA Glu GAA 1177632 28 96 0 2787607 0 422452662804 585 chr1 58996 58997 rs1638318 0   A A A G genomic single by submitter 0 0 unknown exact 3     chr1 59289 59292 NM 001005484 0   TTT TTT Phe TTT 714298 17 57 0 1538990 0 464134269878 585 chr1 59290 59291 rs71245814 0   T T G T genomic single unknown 0 0 unknown exact 3     chr1 59313 59316 NM 001005484 0   AAG AAG Lys AAG 1295568 31 86 0 2289189 0 565950648898 585 chr1 59315 59316 rs2854682 0   G G C T genomic single by submitter 0 0 unknown exact 3     chr1 59373 59376 NM 001005484 0   ACA ACA Thr ACA 614523 15 11 0 2162384 0 284187729839 585 chr1 59373 59374 rs2691305 0   A A C T genomic single unknown 0 0 unknown exact 3     chr1 59412 59415 NM 001005484 0   GCG GCG Ala GCG 299495 7 37 0 2820741 0 106176001271 585 chr1 59414 59415 rs2531266 0   G G C G genomic single by submitter 0 0 unknown exact 3     chr1 59412 59415 NM 001005484 0   GCG GCG Ala GCG 299495 7 37 0 2820741 0 106176001271 585 chr1 59414 59415 rs55874132 0   G G C G genomic single unknown 0 0 coding synon exact 1         will produce          chr1 58995 58998 NM 001005484 0   GAA GAA Glu GAA 1177632 28 96 0 2787607 0 422452662804 585 chr1 58996 58997 rs1638318 0   A A A G genomic single by submitter 0 0 unknown exact 3 GGA     chr1 59289 59292 NM 001005484 0   TTT TTT Phe TTT 714298 17 57 0 1538990 0 464134269878 585 chr1 59290 59291 rs71245814 0   T T G T genomic single unknown 0 0 unknown exact 3 TGT     chr1 59313 59316 NM 001005484 0   AAG AAG Lys AAG 1295568 31 86 0 2289189 0 565950648898 585 chr1 59315 59316 rs2854682 0   G G C T genomic single by submitter 0 0 unknown exact 3 AAA     chr1 59373 59376 NM 001005484 0   ACA ACA Thr ACA 614523 15 11 0 2162384 0 284187729839 585 chr1 59373 59374 rs2691305 0   A A C T genomic single unknown 0 0 unknown exact 3 GCA     chr1 59412 59415 NM 001005484 0   GCG GCG Ala GCG 299495 7 37 0 2820741 0 106176001271 585 chr1 59414 59415 rs2531266 0   G G C G genomic single by submitter 0 0 unknown exact 3 GCC     chr1 59412 59415 NM 001005484 0   GCG GCG Ala GCG 299495 7 37 0 2820741 0 106176001271 585 chr1 59414 59415 rs55874132 0   G G C G genomic single unknown 0 0 coding synon exact 1 GCC            Citation    If you use this tool  please cite  Blankenberg D  Taylor J  Nekrutenko A  The Galaxy Team  Making whole genome multiple alignments usable for biologists  Bioinformatics  2011 Sep 1 27 17  2426 2428         ,mutate_snp_codon_1,interval,Mutate Codons,interval
869, ,,This tool computes the Partial R squared for all possible variable subsets using the following formula ,partialRsq,tabular,Compute partial R square,input
870,between any two numeric columns,,Computes Pearsons correlation coefficient between any two numerical columns  Column numbers start at 1  ,Pearson_and_apos_Correlation1,txt,Pearson and apos Correlation,txt
871,Convert from pgSnp to gd_snp,,This tool converts a pgSnp dataset to gd snp format  either starting a new dataset or appending to an old one   When appending  if any new SNPs appear only in the pgSnp file they can either be skipped entirely  or backfilled with   1   meaning  unknown   for previous individuals groups in the input gd snp dataset  If any new SNPs are being added  either by creating a new table or by backfilling   then an extra column with the reference allele must be supplied in the pgSnp dataset  as shown in the example below ,pgSnp2gd_snp,"tab,gd_snp",pgSnp to gd_snp,gd_snp
872,condenses pileup format into ranges of bases,,         What is does    Reduces the size of a results set by taking a pileup file and producing a condensed version showing consecutive sequences of bases meeting coverage criteria  The tool works on six and ten column pileup formats produced with  samtools pileup  command  You also can specify columns for the input file manually  The tool assumes that the pileup dataset was produced by  samtools pileup  command  although you can override this by setting column assignments manually                Types of pileup datasets    The description of pileup format below is largely based on information that can be found on SAMTools  documentation page  The 6  and 10 column variants are described below       SAMTools      Six column pileup          1    2  3  4        5        6                                        chrM  412  A  2                II  chrM  413  G  4       t      IIIH  chrM  414  C  4        a     III2  chrM  415  C  4     TTTt     III7     where     Column Definition                                            1 Chromosome       2 Position  1 based        3 Reference base at that position       4 Coverage    reads aligning over that position        5 Bases within reads where  see Galaxy wiki for more info        6 Quality values  phred33 scale  see Galaxy wiki for more            Ten column pileup    The  ten column    pileup incorporates additional consensus information generated with   c  option of  samtools pileup  command         1    2  3  4   5   6   7   8       9       10                                                    chrM  412  A  A  75   0  25  2                II  chrM  413  G  G  72   0  25  4       t      IIIH  chrM  414  C  C  75   0  25  4        a     III2  chrM  415  C  T  75  75  25  4     TTTt     III7  where      Column Definition                                              1 Chromosome        2 Position  1 based         3 Reference base at that position        4 Consensus bases        5 Consensus quality        6 SNP quality        7 Maximum mapping quality        8 Coverage    reads aligning over that position         9 Bases within reads where  see Galaxy wiki for more info        10 Quality values  phred33 scale  see Galaxy wiki for more                       The output format    The output file condenses the information in the pileup file so that consecutive bases are listed together as sequences  The starting and ending points of the sequence range are listed  with the starting value converted to a 0 based value    Given the following input with minimum coverage set to 3        1    2  3  4        5        6                                        chr1  112  G  3       Ta     III6  chr1  113  T  2     aT       III5  chr1  114  A  5              IIH2  chr1  115  C  4               III  chrM  412  A  2                II  chrM  413  G  4       t      IIIH  chrM  414  C  4        a     III2  chrM  415  C  4     TTTt     III7  chrM  490  T  3        a        I   the following would be the output         1    2    3  4                       chr1  111  112  G  chr1  113  115  AC  chrM  412  415  GCC  chrM  489  490  T  where      Column Definition                                              1 Chromosome        2 Starting position  0 based         3 Ending position  1 based         4 Sequence of bases      ,pileup_interval,tabular,Pileup-to-Interval,tabular
873,on coverage and SNPs,,Allows one to find sequence variants and or sites covered by a specified number of reads with bases above a set quality threshold  The tool works on six and ten column pileup formats produced with  samtools pileup  command  However  it also allows you to specify columns in the input file manually  The tool assumes the following ,pileup_parser,pileup,Filter pileup,tabular
874,"on ""Perform LDA"" output",,This tool generates a Receiver Operating Characteristic  ROC  plot that shows LDA classification success rates for different values of the tuning parameter tau as Figure 3 in Carrel et al   2006  PMID  17009873  ,plot_for_lda_output1,txt,Draw ROC plot,pdf
875, ,,This tool performs Principal Component Analysis on the given numeric input data using functions from R statistical package    princomp  function  for Eigenvector based solution  and  prcomp  function  for Singular value decomposition based solution   It outputs two files  one containing the summary statistics of PCA  and the other containing biplots of the observations and principal components    ,pca1,tabular,Principal Component Analysis,"input,pdf"
876, based on quality scores,,This tool takes a MAF file as input and filters nucleotides in every alignment block of the MAF file based on their quality PHRED scores  ,qualityFilter,maf,Filter nucleotides,maf
877, ,,This tool computes the RCVE  Relative Contribution to Variance  for all possible variable subsets using the following formula ,rcve1,tabular,Compute RCVE,input
878,of a file,,This tool removes a specified number of lines from the beginning of a dataset ,Remove beginning1,txt,Remove beginning,input
879,for Solexa Short Reads Alignment,,This tool runs   rmap    for more information  please see the reference below   mapping Solexa reads onto a genome build    ,rmap_wrapper,fasta,RMAP,bed
880,for Solexa Short Reads Alignment with Quality Scores,,This tool runs   rmapq    for more information  please see the reference below   searching against a genome build with sequence qualities    ,rmapq_wrapper,"fasta,qualsolexa",RMAPQ,bed
881,to interval,,Converts positional information from a SAM dataset into interval format with 0 based start and 1 based end  CIGAR string of SAM format is used to compute the end coordinate ,sam2interval,sam,Convert SAM,interval
882,on bitwise flag values,,Allows parsing of SAM datasets using bitwise flag  the second column   The bits in the flag are defined as follows  ,sam_bw_filter,sam,Filter SAM,sam
883,merges BAM files together,,This tool uses the Picard  merge command to merge any number of BAM files together into one BAM file while preserving the BAM metadata such as read groups ,sam_merge2,"bam,sam",Merge BAM Files,bam
884,from BAM dataset,,Uses SAMTools   pileup command to produce a pileup dataset from a provided BAM dataset  It generates two types of pileup datasets depending on the specified options  If  Call consensus according to MAQ model   option is set to   No    the tool produces simple pileup  If the option is set to   Yes    a ten column pileup dataset with consensus is generated  Both types of datasets are briefly summarized below ,sam_pileup,"bam,fasta",Generate pileup,tabular
885,files on FLAG MAPQ RG LN or by region,,This tool uses the samtools view command in SAMtools  toolkit to filter a SAM or BAM file on the MAPQ  mapping quality   FLAG bits  Read Group  Library  or region ,samtool_filter2,"sam,bam,bed","Filter SAM or BAM, output SAM or BAM",sam
886,of two numeric columns,,    class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  gt Convert            Syntax    This tool creates a simple scatter plot between two variables containing numeric values of a selected dataset      All invalid  blank and comment lines in the dataset are skipped   The number of skipped lines is displayed in the resulting history item       Plot title   The scatterplot title     Label for x axis   and   Label for y axis   The labels for x and y axis of the scatterplot            Example      Input file        1   68  4 1     2   71  4 6     3   62  3 8     4   75  4 4     5   58  3 2     6   60  3 1     7   67  3 8     8   68  4 1     9   71  4 3     10  69  3 7     Create a simple scatterplot between the variables in column 2 and column 3 of the above dataset      image   scatterplot png  ,scatterplot_rpy,tabular,Scatterplot,pdf
887, of high quality score reads ,,This tool takes Quality Files generated by Roche  454   Illumina  Solexa   or ABI SOLiD machines and builds a histogram of lengths of high quality reads ,hist_high_quality_score,"qualsolexa,qual454,txtseq.zip",Histogram,pdf
888,,,This tool takes Quality Files generated by Roche  454   Illumina  Solexa   or ABI SOLiD machines and builds a graph showing score distribution like the one below  Such graph allows you to perform initial evaluation of data quality in a single pass ,quality_score_distribution,"qualsolexa, qual454",Build base quality distribution,png
889,,,This tool finds high quality segments within sequencing reads generated by by Roche  454   Illumina  Solexa   or ABI SOLiD machines ,trim_reads,"fasta,qualsolexa,qual454",Select high quality segments,fasta
890,lines from a dataset,,This tool outputs specified number of lines from the   beginning   of a dataset,Show beginning1,txt,Select first,input
891,lines from a dataset,,This tool outputs specified number of lines from the   end   of a dataset,Show tail1,txt,Select last,input
892,Statistical approach for the Identification of ChIP-Enriched Regions,,SICER first and foremost is a filtering tool  Its main functions are        1  Delineation of the significantly ChIP enriched regions  which can be used to associate with other genomic landmarks     2  Identification of reads on the ChIP enriched regions  which can be used for profiling and other quantitative analysis ,peakcalling_sicer,bed,SICER,"bed,bedgraph,wig,interval,txt"
893,,,     ,split_paired_reads,fastqsanger,Split paired end reads,fastqsanger
894, for non-coding regions,,This tool takes a pairwise MAF file as input and estimates substitution rate according to Jukes Cantor JC69 model  The 3 new columns appended to the output are explained below ,subRate1,"maf,interval",Estimate substitution rates ,tabular
895, from pairwise alignments,,This tool takes a pairwise MAF file as input and fetches substitutions per alignment block ,substitutions1,maf,Fetch substitutions ,tabular
896,,,This program implements the non pooled t test for two samples where the alternative hypothesis is two sided or one sided  The program takes four inputs ,t_test_two_samples,tabular,T Test for Two Samples,txt
897,with functional information using ANNOVAR,,This tool will annotate variants using specified gene annotations  regions  and filtering databases  Input is a VCF dataset  and output is a table of annotations for each variant in the VCF dataset or a VCF dataset with the annotations in INFO fields ,table_annovar,vcf,ANNOVAR Annotate VCF,tabular
898,converts tabular file to FASTA format,,Converts tab delimited data into FASTA formatted sequences ,tab2fasta,tabular,Tabular-to-FASTA,fasta
899,Find splice junctions using RNA-seq data,,   TopHat Overview    TopHat  is a fast splice junction mapper for RNA Seq reads  It aligns RNA Seq reads to mammalian sized genomes using the ultra high throughput short read aligner Bowtie  and then analyzes the mapping results to identify splice junctions between exons       TopHat              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in splice junction identification  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          manual shtml            Input formats    TopHat accepts files in Sanger FASTQ format  Use the FASTQ Groomer to prepare your files             Outputs    TopHat produces two output files     junctions    A UCSC BED  track of junctions reported by TopHat  Each junction consists of two connected BED blocks  where each block is as long as the maximal overhang of any read spanning the junction  The score is the number of alignments spanning the junction    accepted hits    A list of read alignments in BAM  format       BED   format1     BAM    Two other possible outputs  depending on the options you choose  are insertions and deletions  both of which are in BED format              TopHat settings    All of the options have a default value  You can change any of them  Some of the options in TopHat have been implemented here             TopHat parameter list    This is a list of implemented TopHat options       r                                This is the expected  mean  inner distance between mate pairs  For  example  for paired end runs with fragments                                     selected at 300bp  where each end is 50bp  you should set  r to be 200  There is no default  and this parameter                                     is required for paired end runs      mate std dev INT                The standard deviation for the distribution on inner distances between mate pairs  The default is 20bp     a   min anchor length INT        The  anchor length   TopHat will report junctions spanned by reads with at least this many bases on each side of the junction  Note that individual spliced                                     alignments may span a junction with fewer than this many bases on one side  However  every junction involved in spliced alignments is supported by at least one                                     read with this many bases on each side  This must be at least 3 and the default is 8     m   splice mismatches INT        The maximum number of mismatches that may appear in the  anchor  region of a spliced alignment  The default is 0     i   min intron length INT        The minimum intron length  TopHat will ignore donor acceptor pairs closer than this many bases apart  The default is 70     I   max intron length INT        The maximum intron length  When searching for junctions ab initio  TopHat will ignore donor acceptor pairs farther than this many bases apart  except when such a pair is supported by a split segment alignment of a long read  The default is 500000     g   max multihits INT            Instructs TopHat to allow up to this many alignments to the reference for a given read  and suppresses all alignments for reads with more than this many                                     alignments  The default is 40     G   GTF  GTF 2 2 file            Supply TopHat with a list of gene model annotations  TopHat will use the exon records in this file to build a set of known splice junctions for each gene  and will attempt to align reads to these junctions even if they would not normally be covered by the initial mapping     j   raw juncs  juncs file        Supply TopHat with a list of raw junctions  Junctions are specified one per line  in a tab delimited format  Records look like   chrom   left   right         left and right are zero based coordinates  and specify the last character of the left sequenced to be spliced to the first character of the right sequence  inclusive     no novel juncs                   Only look for junctions indicated in the supplied GFF file   ignored without  G      no closure search               Disables the mate pair closure based search for junctions  Currently  has no effect   closure search is off by default      closure search                  Enables the mate pair closure based search for junctions  Closure based search should only be used when the expected inner distance between mates is small  about or less than 50bp      no coverage search              Disables the coverage based search for junctions      coverage search                 Enables the coverage based search for junctions  Use when coverage search is disabled by default  such as for reads 75bp or longer   for maximum sensitivity      microexon search                With this option  the pipeline will attempt to find alignments incident to microexons  Works only for reads 50bp or longer      butterfly search                TopHat will use a slower but potentially more sensitive algorithm to find junctions in addition to its standard search  Consider using this if you expect that your experiment produced a lot of reads from pre mRNA  that fall within the introns of your transcripts      segment mismatches              Read segments are mapped independently  allowing up to this many mismatches in each segment alignment  The default is 2      segment length                  Each read is cut up into segments  each at least this long  These segments are mapped independently  The default is 25      min closure exon                During closure search for paired end reads  exonic hops in the potential splice graph must be at least this long  The default is 50      min closure intron              The minimum intron length that may be found during closure search  The default is 50      max closure intron              The maximum intron length that may be found during closure search  The default is 5000      min coverage intron             The minimum intron length that may be found during coverage search  The default is 50      max coverage intron             The maximum intron length that may be found during coverage search  The default is 20000      min segment intron              The minimum intron length that may be found during split segment search  The default is 50      max segment intron              The maximum intron length that may be found during split segment search  The default is 500000      ,tophat,"fastqsanger,gtf,gff3,interval",TopHat for Illumina,"bed,bam"
900,Gapped-read mapper for RNA-seq data,,   TopHat Overview    TopHat  is a fast splice junction mapper for RNA Seq reads  It aligns RNA Seq reads to mammalian sized genomes using the ultra high throughput short read aligner Bowtie 2   and then analyzes the mapping results to identify splice junctions between exons       TopHat              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in splice junction identification  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          manual shtml            Input formats    TopHat accepts files in Sanger FASTQ format  Use the FASTQ Groomer to prepare your files             Outputs    TopHat produces two output files     junctions    A UCSC BED  track of junctions reported by TopHat  Each junction consists of two connected BED blocks  where each block is as long as the maximal overhang of any read spanning the junction  The score is the number of alignments spanning the junction    accepted hits    A list of read alignments in BAM  format       BED   format1     BAM    Two other possible outputs  depending on the options you choose  are insertions and deletions  both of which are in BED format              TopHat settings    All of the options have a default value  You can change any of them  Some of the options in TopHat have been implemented here             TopHat parameter list    This is a list of implemented TopHat options       r                                This is the expected  mean  inner distance between mate pairs  For  example  for paired end runs with fragments                                     selected at 300bp  where each end is 50bp  you should set  r to be 200  There is no default  and this parameter                                     is required for paired end runs      mate std dev INT                The standard deviation for the distribution on inner distances between mate pairs  The default is 20bp     a   min anchor length INT        The  anchor length   TopHat will report junctions spanned by reads with at least this many bases on each side of the junction  Note that individual spliced                                     alignments may span a junction with fewer than this many bases on one side  However  every junction involved in spliced alignments is supported by at least one                                     read with this many bases on each side  This must be at least 3 and the default is 8     m   splice mismatches INT        The maximum number of mismatches that may appear in the  anchor  region of a spliced alignment  The default is 0     i   min intron length INT        The minimum intron length  TopHat will ignore donor acceptor pairs closer than this many bases apart  The default is 70     I   max intron length INT        The maximum intron length  When searching for junctions ab initio  TopHat will ignore donor acceptor pairs farther than this many bases apart  except when such a pair is supported by a split segment alignment of a long read  The default is 500000     g   max multihits INT            Instructs TopHat to allow up to this many alignments to the reference for a given read  and suppresses all alignments for reads with more than this many                                     alignments  The default is 40     G   GTF  GTF 2 2 file            Supply TopHat with a list of gene model annotations  TopHat will use the exon records in this file to build a set of known splice junctions for each gene  and will attempt to align reads to these junctions even if they would not normally be covered by the initial mapping     j   raw juncs  juncs file        Supply TopHat with a list of raw junctions  Junctions are specified one per line  in a tab delimited format  Records look like   chrom   left   right         left and right are zero based coordinates  and specify the last character of the left sequenced to be spliced to the first character of the right sequence  inclusive     no novel juncs                   Only look for junctions indicated in the supplied GFF file   ignored without  G      no coverage search              Disables the coverage based search for junctions      coverage search                 Enables the coverage based search for junctions  Use when coverage search is disabled by default  such as for reads 75bp or longer   for maximum sensitivity      microexon search                With this option  the pipeline will attempt to find alignments incident to microexons  Works only for reads 50bp or longer      segment mismatches              Read segments are mapped independently  allowing up to this many mismatches in each segment alignment  The default is 2      segment length                  Each read is cut up into segments  each at least this long  These segments are mapped independently  The default is 25      min coverage intron             The minimum intron length that may be found during coverage search  The default is 50      max coverage intron             The maximum intron length that may be found during coverage search  The default is 20000      min segment intron              The minimum intron length that may be found during split segment search  The default is 50      max segment intron              The maximum intron length that may be found during split segment search  The default is 500000      ,tophat2,fastqsanger,TopHat,"txt,tabular,bed,bam"
901,post-processing to identify fusion genes,,,tophat_fusion_post,"bam,tabular",Tophat Fusion Post,"tabular,html"
902,leading or trailing characters,,Trims specified number of characters from a dataset or its field  if dataset is tab delimited  ,trimmer,"tabular,txt",Trim,input
903,for UCSC genome browser,,     class   infomark  This tool allows you to build custom tracks using datasets in your history for the UCSC genome browser  You can view these custom tracks on the UCSC genome browser by clicking on   display at UCSC main test   link in the history panel of the output dataset             class   warningmark  Please note that this tool requires   all input datasets tracks  to have the same genome build    The tool throws an error when this requirement is not met  You may then have to choose a valid dataset or remove invalid tracks   ,build_ucsc_custom_track_1,"interval,wig",Build custom track,customtrack
904,for variant detection,,   VarScan Overview    VarScan  performs variant detection for massively parallel sequencing data  such as exome  WGS  and transcriptome data  It calls variants from a mpileup dataset and produces a VCF 4 1 Full documentation is available online        VarScan       online  using varscan html    Input          mpileup file   The SAMtools mpileup file      Output    VarScan produces a VCF 4 1 dataset as output     Parameters          analysis type     single nucleotide detection     Identify SNPs from an mpileup file     insertions and deletion       Identify indels an mpileup file     consensus genotype     Call consensus and variants from an mpileup file    min coverage       Minimum read depth at a position to make a call  8     min reads2         Minimum supporting reads at a position to call variants  2     min avg qual       Minimum base quality at a position to count a read  15     min var freq           Minimum variant allele frequency threshold  0 01     min freq for hom     Minimum frequency to call homozygote  0 75       p value     Default p value threshold for calling variants  99e 02       strand filter     Ignore variants with  90  support on one strand  1       output vcf     If set to 1  outputs in VCF format      vcf sample list     For VCF output  a list of sample names in order  one per line      variants     Report only variant  SNP indel  positions  0      ,varscan,pileup,VarScan,vcf
905,Convert from VCF to pgSnp format,,This converts a VCF dataset to pgSnp with the frequency counts being chromosome counts   If there is more than one column of SNP data it will either accumulate all columns as a population or convert the column indicated to pgSnp ,vcf2pgSnp,vcf,VCF to pgSnp,interval
906,"a VCF file (dbSNP, hapmap)",,This tool uses vcfPytools   annotate command annotate a VCF file,vcf_annotate,vcf,Annotate,vcf
907,reads from a specified region,,This tool uses vcfPytools   extract command to extract reads from a specified region of a VCF file,vcf_extract,vcf,Extract,vcf
908,a VCF file,,This tool uses vcfPytools   filter command,vcf_filter,vcf,Filter,vcf
909,Generate the intersection of two VCF files,,This tool uses vcfPytools   intersect command to generate the intersection of two VCF files,vcf_intersect,"vcf,bed",Intersect,vcf
910,Velvet sequence assembler for very short reads,,Velvet  is a de novo genomic assembler specially designed for short read sequencing technologies  such as Solexa or 454  developed by Daniel Zerbino and Ewan Birney at the European Bioinformatics Institute  EMBL EBI   near Cambridge  in the United Kingdom ,velvetg,velvet,velvetg,"txt,afg,fasta,tabular"
911,Prepare a dataset for the Velvet velvetg Assembler,,Velvet  is a de novo genomic assembler specially designed for short read sequencing technologies  such as Solexa or 454  developed by Daniel Zerbino and Ewan Birney at the European Bioinformatics Institute  EMBL EBI   near Cambridge  in the United Kingdom ,velveth,"fasta,fastq,eland,gerald",velveth,velvet
912, of the values of features overlapping an interval ,,For each interval in your first dataset  this tool calculates the weighted average value of the overlapping features in your second dataset ,wtavg,interval,Assign weighted-average,input
913,,,This tool splits the intervals in the input file into smaller intervals based on the specified window size and window type ,winSplitter,interval,Make windows,interval
914,for multiple series and graph types,,    class   infomark  This tool allows you to plot values contained in columns of a dataset against each other and also allows you to have different series corresponding to the same or different datasets in one plot             class   warningmark  This tool throws an error if the columns selected for plotting are absent or are not numeric and also if the lengths of these columns differ            Example    Input file        1   68  4 1     2   71  4 6     3   62  3 8     4   75  4 4     5   58  3 2     6   60  3 1     7   67  3 8     8   68  4 1     9   71  4 3     10  69  3 7  Create a two series XY plot on the above data     Series 1  Red Dashed Line plot between columns 1 and 2   Series 2  Blue Circular Point plot between columns 3 and 2     image   xy example jpg ,XY_Plot_1,tabular,Plotting tool,"pdf,png"
915,compare assembled transcripts to a reference annotation and track Cufflinks transcripts across multiple experiments,,   Cuffcompare Overview    Cuffcompare is part of Cufflinks   Cuffcompare helps you   a  compare your assembled transcripts to a reference annotation and  b  track Cufflinks transcripts across multiple experiments  e g  across a time course   Please cite  Trapnell C  Williams BA  Pertea G  Mortazavi AM  Kwan G  van Baren MJ  Salzberg SL  Wold B  Pachter L  Transcript assembly and abundance estimation from RNA Seq reveals thousands of new transcripts and switching among isoforms  Nature Biotechnology doi 10 1038 nbt 1621      Cufflinks              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in expression analysis  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          cuffcompare             Input format    Cuffcompare takes Cufflinks  GTF output as input  and optionally can take a  reference  annotation  such as from Ensembl        Ensembl              Outputs    Cuffcompare produces the following output files   Transcripts Accuracy File   Cuffcompare reports various statistics related to the  accuracy  of the transcripts in each sample when compared to the reference annotation data  The typical gene finding measures of  sensitivity  and  specificity   as defined in Burset  M   Guig   R    Evaluation of gene structure prediction programs  1996  Genomics  34  3   pp  353 367  doi  10 1006 geno 1996 0298  are calculated at various levels  nucleotide  exon  intron  transcript  gene  for each input file and reported in this file  The Sn and Sp columns show specificity and sensitivity values at each level  while the fSn and fSp columns are  fuzzy  variants of these same accuracy calculations  allowing for a very small variation in exon boundaries to still be counted as a  match    Transcripts Combined File   Cuffcompare reports a GTF file containing the  union  of all transfrags in each sample  If a transfrag is present in both samples  it is thus reported once in the combined gtf   Transcripts Tracking File   This file matches transcripts up between samples  Each row contains a transcript structure that is present in one or more input GTF files  Because the transcripts will generally have different IDs  unless you assembled your RNA Seq reads against a reference transcriptome   cuffcompare examines the structure of each the transcripts  matching transcripts that agree on the coordinates and order of all of their introns  as well as strand  Matching transcripts are allowed to differ on the length of the first and last exons  since these lengths will naturally vary from sample to sample due to the random nature of sequencing  If you ran cuffcompare with the  r option  the first and second columns contain the closest matching reference transcript to the one described by each row   Here s an example of a line from the tracking file      TCONS 00000045 XLOC 000023 Tcea uc007afj 1        j               q1 exp 115 exp 115 0 100 3 061355 0 350242 0 350207        q2 60hr 292 60hr 292 0 100 4 094084 0 000000 0 000000  In this example  a transcript present in the two input files  called exp 115 0 in the first and 60hr 292 0 in the second  doesn t match any reference transcript exactly  but shares exons with uc007afj 1  an isoform of the gene Tcea  as indicated by the class code j  The first three columns are as follows      Column number   Column name               Example          Description                                                                             1               Cufflinks transfrag id    TCONS 00000045   A unique internal id for the transfrag   2               Cufflinks locus id        XLOC 000023      A unique internal id for the locus   3               Reference gene id         Tcea             The gene name attribute of the reference GTF record for this transcript  or     if no reference transcript overlaps this Cufflinks transcript   4               Reference transcript id   uc007afj 1       The transcript id attribute of the reference GTF record for this transcript  or     if no reference transcript overlaps this Cufflinks transcript   5               Class code                c                The type of match between the Cufflinks transcripts in column 6 and the reference transcript  See class codes  Each of the columns after the fifth have the following format    qJ gene id transcript id FMI FPKM conf lo conf hi  A transcript need be present in all samples to be reported in the tracking file  A sample not containing a transcript will have a     in its entry in the row for that transcript   Class Codes  If you ran cuffcompare with the  r option  tracking rows will contain the following values  If you did not use  r  the rows will all contain     in their class code column      Priority         Code           Description                                       1                                 Match   2                 c               Contained   3                 j               New isoform   4                 e               A single exon transcript overlapping a reference exon and at least 10 bp of a reference intron  indicating a possible pre mRNA fragment    5                 i               A single exon transcript falling entirely with a reference intron   6                 o               Generic exonic overlap with a reference transcript   7                 p               Possible polymerase run on fragment   8                 r               Repeat  Currently determined by looking at the soft masked reference sequence and applied to transcripts where at least 50  of the bases are lower case   9                 u               Unknown  intergenic transcript   10                x               Exonic overlap with reference on the opposite strand   11                s               An intron of the transfrag overlaps a reference intron on the opposite strand  likely due to read mapping errors    12                                  tracking file only  indicates multiple classifications              Settings    All of the options have a default value  You can change any of them  Most of the options in Cuffcompare have been implemented here             Cuffcompare parameter list    This is a list of implemented Cuffcompare options       r    An optional  reference  annotation GTF  Each sample is matched against this file  and sample isoforms are tagged as overlapping  matching  or novel where appropriate  See the refmap and tmap output file descriptions below     R    If  r was specified  this option causes cuffcompare to ignore reference transcripts that are not overlapped by any transcript in one of cuff1 gtf     cuffN gtf  Useful for ignoring annotated transcripts that are not present in your RNA Seq samples and thus adjusting the  sensitivity  calculation in the accuracy report written in the transcripts accuracy file     ,cuffcompare,"gff3,gtf,fasta",Cuffcompare,"txt,tabular,gtf"
916,"find significant changes in transcript expression, splicing, and promoter use",,   Cuffdiff Overview    Cuffdiff is part of Cufflinks   Cuffdiff find significant changes in transcript expression  splicing  and promoter use  Please cite  Trapnell C  Williams BA  Pertea G  Mortazavi AM  Kwan G  van Baren MJ  Salzberg SL  Wold B  Pachter L  Transcript assembly and abundance estimation from RNA Seq reveals thousands of new transcripts and switching among isoforms  Nature Biotechnology doi 10 1038 nbt 1621      Cufflinks              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in expression analysis  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          cuffdiff             Input format    Cuffdiff takes Cufflinks or Cuffcompare GTF files as input along with two SAM files containing the fragment alignments for two or more samples             Outputs    Cuffdiff produces many output files   1  Transcript FPKM   count  expression tracking  2  Gene FPKM   count  expression tracking  tracks the summed FPKM of transcripts sharing each gene id 3  Primary transcript FPKM   count  tracking  tracks the summed FPKM of transcripts sharing each tss id 4  Coding sequence FPKM   count  tracking  tracks the summed FPKM of transcripts sharing each p id  independent of tss id 5  Transcript differential FPKM  6  Gene differential FPKM  Tests difference sin the summed FPKM of transcripts sharing each gene id 7  Primary transcript differential FPKM  Tests difference sin the summed FPKM of transcripts sharing each tss id 8  Coding sequence differential FPKM  Tests difference sin the summed FPKM of transcripts sharing each p id independent of tss id 9  Differential splicing tests  this tab delimited file lists  for each primary transcript  the amount of overloading detected among its isoforms  i e  how much differential splicing exists between isoforms processed from a single primary transcript  Only primary transcripts from which two or more isoforms are spliced are listed in this file  10  Differential promoter tests  this tab delimited file lists  for each gene  the amount of overloading detected among its primary transcripts  i e  how much differential promoter use exists between samples  Only genes producing two or more distinct primary transcripts  i e  multi promoter genes  are listed here  11  Differential CDS tests  this tab delimited file lists  for each gene  the amount of overloading detected among its coding sequences  i e  how much differential CDS output exists between samples  Only genes producing two or more distinct CDS  i e  multi protein genes  are listed here              Settings    All of the options have a default value  You can change any of them  Most of the options in Cuffdiff have been implemented here             Cuffdiff parameter list    This is a list of implemented Cuffdiff options       m INT                         Average fragment length  SE reads   default 200    s INT                         Fragment legnth standard deviation  SE reads   default 80    c INT                         The minimum number of alignments in a locus for needed to conduct significance testing on changes in that locus observed between samples  If no testing is performed  changes in the locus are deemed not significant  and the locus  observed changes don t contribute to correction for multiple testing  The default is 1 000 fragment alignments  up to 2 000 paired reads       FDR FLOAT                    The allowed false discovery rate  The default is 0 05      max mle iterations INT       Sets the number of iterations allowed during maximum likelihood estimation of abundances  Default  5000     library norm method          Library Normalization method   Geometric  default   classic fpkm  quartile     dispersion method            Dispersion estimation method   Pooled  default   per condition  blind  poisson    u                             Multi read correction tells Cufflinks to do an initial estimation procedure to more accurately weight reads mapping to multiple locations in the genome     b ref fasta                         bias correction  Bias detection and correction can significantly improve accuracy of transcript abundance estimates      no effective length correction  Use standard length correction     no length correction         Disable all length correction      library type                 ff firststrand ff secondstrand ff unstranded fr firstrand fr secondstrand fr unstranded transfrags     mask file  gff3 gtf          Ignore all alignment within transcripts in this file     time series                  Treat provided sam files as time series     compatible hits norm         With this option  Cufflinks counts only those fragments compatible with some reference transcript towards the number of mapped fragments used in the FPKM denominator  Using this mode is generally recommended in Cuffdiff to reduce certain types of bias caused by differential amounts of ribosomal reads which can create the impression of falsely differentially expressed genes      total hits norm              With this option  Cufflinks counts all fragments  including those not compatible with any reference transcript  towards the number of mapped fragments used in the FPKM denominator     max bundle frags             Sets the maximum number of fragments a locus may have before being skipped  Skipped loci are listed in skipped gtf      num frag count draws         Cuffdiff will make this many draws from each transcript s predicted negative binomial random numbder generator  Each draw is a number of fragments that will be probabilistically assigned to the transcripts in the transcriptome  Used to estimate the variance covariance matrix on assigned fragment counts      num frag assign draws        For each fragment drawn from a transcript  Cuffdiff will assign it this many times  probabilistically   thus estimating the assignment uncertainty for each transcript  Used to estimate the variance covariance matrix on assigned fragment counts      min reps for js test         Cuffdiff won t test genes for differential regulation unless the conditions in question have at least this many replicates      ,cuffdiff,"gtf,gff3,fasta",Cuffdiff,"tabular,txt,sqlite"
917,transcript assembly and FPKM (RPKM) estimates for RNA-Seq data,,   Cufflinks Overview    Cufflinks  assembles transcripts  estimates their abundances  and tests for differential expression and regulation in RNA Seq samples  It accepts aligned RNA Seq reads and assembles the alignments into a parsimonious set of transcripts  Cufflinks then estimates the relative abundances of these transcripts based on how many reads support each one   Please cite  Trapnell C  Williams BA  Pertea G  Mortazavi AM  Kwan G  van Baren MJ  Salzberg SL  Wold B  Pachter L  Transcript assembly and abundance estimation from RNA Seq reveals thousands of new transcripts and switching among isoforms  Nature Biotechnology doi 10 1038 nbt 1621      Cufflinks              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in expression analysis  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          cufflinks             Input formats    Cufflinks takes a text file of SAM alignments as input  The RNA Seq read mapper TopHat produces output in this format  and is recommended for use with Cufflinks  However Cufflinks will accept SAM alignments generated by any read mapper  Here s an example of an alignment Cufflinks will accept      s6 25mer txt 913508    16    chr1 4482736 255 14M431N11M   0 0        CAAGATGCTAGGCAAGTCTTGGAAG IIIIIIIIIIIIIIIIIIIIIIIII NM i 0 XS A    Note the use of the custom tag XS  This attribute  which must have a value of     or      indicates which strand the RNA that produced this read came from  While this tag can be applied to any alignment  including unspliced ones  it must be present for all spliced alignment records  those with a  N  operation in the CIGAR string   The SAM file supplied to Cufflinks must be sorted by reference position  If you aligned your reads with TopHat  your alignments will be properly sorted already  If you used another tool  you may want to make sure they are properly sorted as follows      sort  k 3 3  k 4 4n hits sam   hits sam sorted  NOTE  Cufflinks currently only supports SAM alignments with the CIGAR match   M   and reference skip   N   operations  Support for the other operations  such as insertions  deletions  and clipping  will be added in the future             Outputs    Cufflinks produces three output files   Transcripts and Genes   This GTF file contains Cufflinks  assembled isoforms  The first 7 columns are standard GTF  and the last column contains attributes  some of which are also standardized  e g  gene id  transcript id   There one GTF record per row  and each record represents either a transcript or an exon within a transcript  The columns are defined as follows      Column number   Column name   Example     Description                                                           1               seqname       chrX        Chromosome or contig name   2               source        Cufflinks   The name of the program that generated this file  always  Cufflinks     3               feature       exon        The type of record  always either  transcript  or  exon      4               start         77696957    The leftmost coordinate of this record  where 0 is the leftmost possible coordinate    5               end           77712009    The rightmost coordinate of this record  inclusive    6               score         77712009    The most abundant isoform for each gene is assigned a score of 1000  Minor isoforms are scored by the ratio  minor FPKM major FPKM    7               strand                    Cufflinks  guess for which strand the isoform came from  Always one of                7               frame                     Cufflinks does not predict where the start and stop codons  if any  are located within each transcript  so this field is not used    8               attributes    See below  Each GTF record is decorated with the following attributes      Attribute       Example       Description                                               gene id         CUFF 1        Cufflinks gene id   transcript id   CUFF 1 1      Cufflinks transcript id   FPKM            101 267       Isoform level relative abundance in Reads Per Kilobase of exon model per Million mapped reads   frac            0 7647        Reserved  Please ignore  as this attribute may be deprecated in the future   conf lo         0 07          Lower bound of the 95  confidence interval of the abundance of this isoform  as a fraction of the isoform abundance  That is  lower bound   FPKM    1 0   conf lo    conf hi         0 1102        Upper bound of the 95  confidence interval of the abundance of this isoform  as a fraction of the isoform abundance  That is  upper bound   FPKM    1 0   conf lo    cov             100 765       Estimate for the absolute depth of read coverage across the whole transcript  Transcripts only    This file is simply a tab delimited file containing one row per transcript and with columns containing the attributes above  There are a few additional attributes not in the table above  but these are reserved for debugging  and may change or disappear in the future   Genes only  This file contains gene level coordinates and expression values              Cufflinks settings    All of the options have a default value  You can change any of them  Most of the options in Cufflinks have been implemented here             Cufflinks parameter list    This is a list of implemented Cufflinks options       m INT    This is the expected  mean  inner distance between mate pairs  For  example  for paired end runs with fragments selected at 300bp  where each end is 50bp  you should set  r to be 200  The default is 45bp     s INT    The standard deviation for the distribution on inner distances between mate pairs  The default is 20bp     I INT    The minimum intron length  Cufflinks will not report transcripts with introns longer than this  and will ignore SAM alignments with REF SKIP CIGAR operations longer than this  The default is 300 000     F         After calculating isoform abundance for a gene  Cufflinks filters out transcripts that it believes are very low abundance  because isoforms expressed at extremely low levels often cannot reliably be assembled  and may even be artifacts of incompletely spliced precursors of processed transcripts  This parameter is also used to filter out introns that have far fewer spliced alignments supporting them  The default is 0 05  or 5  of the most abundant isoform  the major isoform  of the gene     j        Some RNA Seq protocols produce a significant amount of reads that originate from incompletely spliced transcripts  and these reads can confound the assembly of fully spliced mRNAs  Cufflinks uses this parameter to filter out alignments that lie within the intronic intervals implied by the spliced alignments  The minimum depth of coverage in the intronic region covered by the alignment is divided by the number of spliced reads  and if the result is lower than this parameter value  the intronic alignments are ignored  The default is 5      G        Tells Cufflinks to use the supplied reference annotation to estimate isoform expression  It will not assemble novel transcripts  and the program will ignore alignments not structurally compatible with any reference transcript     N        With this option  Cufflinks excludes the contribution of the top 25 percent most highly expressed genes from the number of mapped fragments used in the FPKM denominator  This can improve robustness of differential expression calls for less abundant genes and transcripts      ,cufflinks,"sam,bam,gff3,gtf,fasta",Cufflinks,"tabular,gtf,txt"
918,merge together several Cufflinks assemblies,,   Cuffmerge Overview    Cuffmerge is part of Cufflinks   Please cite  Trapnell C  Williams BA  Pertea G  Mortazavi AM  Kwan G  van Baren MJ  Salzberg SL  Wold B  Pachter L  Transcript assembly and abundance estimation from RNA Seq reveals thousands of new transcripts and switching among isoforms  Nature Biotechnology doi 10 1038 nbt 1621      Cufflinks              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in expression analysis  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          cuffmerge             Input format    Cuffmerge takes Cufflinks  GTF output as input  and optionally can take a  reference  annotation  such as from Ensembl        Ensembl               Outputs    Cuffmerge produces the following output files   Merged transcripts file   Cuffmerge produces a GTF file that contains an assembly that merges together the input assemblies      ,cuffmerge,"gff3,gtf,fasta",Cuffmerge,gtf
919,Create normalized expression levels,,   Cuffnorm Overview    Cuffnorm is part of Cufflinks   Running Cuffnorm is very similar to running Cuffdiff  Cuffnorm takes a GTF2 GFF3 file of transcripts as input  along with two or more SAM  BAM  or CXB files for two or more samples  It produces a number of output files that contain expression levels and normalized fragment counts at the level of transcripts  primary transcripts  and genes  It also tracks changes in the relative abundance of transcripts sharing a common transcription start site  and in the relative abundances of the primary transcripts of each gene  Tracking the former allows one to see changes in splicing  and the latter lets one see changes in relative promoter use within a gene   Please cite  Trapnell C  Williams BA  Pertea G  Mortazavi AM  Kwan G  van Baren MJ  Salzberg SL  Wold B  Pachter L  Transcript assembly and abundance estimation from RNA Seq reveals thousands of new transcripts and switching among isoforms  Nature Biotechnology doi 10 1038 nbt 1621      Cufflinks              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in expression analysis  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          cuffnorm             Input format    Cuffdiff takes Cufflinks or Cuffcompare GTF files as input along with two SAM files containing the fragment alignments for two or more samples             Outputs    Cuffnorm outputs a set of files containing normalized expression levels for each gene  transcript  TSS group  and CDS group in the experiment  It does not perform differential expression analysis  To assess the significance of changes in expression for genes and transcripts between conditions  use Cuffdiff  Cuffnorm s output files are useful when you have many samples and you simply want to cluster them or plot expression levels of genes important in your study  By default  Cuffnorm reports expression levels in the  simple table  tab delimted text files  The program also reports information about your samples and about the genes  transcripts  TSS groups  and CDS groups as tab delimited text files  Note that these files have a different format than the files used by Cuffdiff  However  you can direct Cuffnorm to report its output in the same format as used by Cuffdiff if you wish  Simply supply the option   output format cuffdiff at the command line  Cuffnorm will report both FPKM values and normalized  estimates for the number of fragments that originate from each gene  transcript  TSS group  and CDS group  Note that because these counts are already normalized to account for differences in library size  they should not be used with downstream differential expression tools that require raw counts as input  To see the details of the simple table format used by Cuffnorm  refer to the simple table expression format  simple table sample attribute format  and simple table feature  e g  gene  attribute format sections below                   Settings    All of the options have a default value  You can change any of them  Most of the options in Cuffdiff have been implemented here             Cuffdiff parameter list    This is a list of implemented Cuffdiff options        library norm method          Library Normalization method   Geometric  default   classic fpkm  quartile     library type                 ff firststrand ff secondstrand ff unstranded fr firstrand fr secondstrand fr unstranded transfrags     compatible hits norm         With this option  Cufflinks counts only those fragments compatible with some reference transcript towards the number of mapped fragments used in the FPKM denominator  Using this mode is generally recommended in Cuffdiff to reduce certain types of bias caused by differential amounts of ribosomal reads which can create the impression of falsely differentially expressed genes      total hits norm              With this option  Cufflinks counts all fragments  including those not compatible with any reference transcript  towards the number of mapped fragments used in the FPKM denominator     ,cuffnorm,"gtf,gff3",Cuffnorm,"tabular,txt"
920,Precompute gene expression levels,,   Cuffquant Overview    Cuffquant is part of Cufflinks   Cuffquant provides pre calculation of gene expression levels  The resulting file can be provided to cuffdiff or cuffnorm for further processing   Please cite  Trapnell C  Williams BA  Pertea G  Mortazavi AM  Kwan G  van Baren MJ  Salzberg SL  Wold B  Pachter L  Transcript assembly and abundance estimation from RNA Seq reveals thousands of new transcripts and switching among isoforms  Nature Biotechnology doi 10 1038 nbt 1621      Cufflinks              Know what you are doing       class   warningmark  There is no such thing  yet  as an automated gearshift in expression analysis  It is all like stick shift driving in San Francisco  In other words  running this tool with default parameters will probably not give you meaningful results  A way to deal with this is to   understand   the parameters by carefully reading the  documentation    and experimenting  Fortunately  Galaxy makes experimenting easy          cuffquant             Input format    Cuffquant takes Cufflinks or Cuffcompare GTF files as input along with two or more SAM files containing the fragment alignments for two or more samples             Outputs    Cuffquant produces one output file   1  Transcript expression values in binary format              Settings    All of the options have a default value  You can change any of them  Most of the options in Cuffdiff have been implemented here             Cuffdiff parameter list    This is a list of implemented Cuffdiff options       m INT                         Average fragment length  SE reads   default 200    s INT                         Fragment legnth standard deviation  SE reads   default 80     max mle iterations INT       Sets the number of iterations allowed during maximum likelihood estimation of abundances  Default  5000    u                             Multi read correction tells Cufflinks to do an initial estimation procedure to more accurately weight reads mapping to multiple locations in the genome     b ref fasta             bias correction  Bias detection and correction can significantly improve accuracy of transcript abundance estimates      no effective length correction  Use standard length correction     no length correction         Disable all length correction      library type                 ff firststrand ff secondstrand ff unstranded fr firstrand fr secondstrand fr unstranded transfrags     mask file  gff3 gtf          Ignore all alignment within transcripts in this file     max bundle frags             Sets the maximum number of fragments a locus may have before being skipped  Skipped loci are listed in skipped gtf      ,cuffquant,"gtf,gff3,sam,bam,fasta",Cuffquant,cxb
921,Filters and/or converts GFF3/GTF2 records,,    gffread   Filters and or converts GFF3 GTF2 records    The gffread command is distributed with the cufflinks  package       cufflinks    Usage       gffread  input gff    g  genomic seqs fasta     dir    s  seq info fsize        o  outfile gff     t  tname     r    strand   chr    start    end    R        CTVNJMKQAFGUBHZWTOLE    w  exons fa     x  cds fa     y  tr cds fa        i  maxintron    Options         g  full path to a multi fasta file with the genomic sequences       for all input mappings  OR a directory with single fasta files        one per genomic sequence  with file names matching sequence names     s   seq info fsize  is a tab delimited file providing this info       for each of the mapped sequences         seq name   seq length   seq description         useful for  A option with mRNA EST protein mappings     i  discard transcripts having an intron larger than  maxintron     r  only show transcripts overlapping coordinate range  start    end         on chromosome contig  chr   strand  strand  if provided     R  for  r option  discard all transcripts that are not fully       contained within the given range    U  discard single exon transcripts    C  coding only  discard mRNAs that have no CDS feature    F  full GFF attribute preservation  all attributes are shown     G  only parse additional exon attributes from the first exon       and move them to the mRNA level  useful for GTF input     A  use the description field from  seq info fsize  and add it       as the value for a  descr  attribute to the GFF record     O  process also non transcript GFF records  by default non transcript       records are ignored     V  discard any mRNAs with CDS having in frame stop codons    H  for  V option  check and adjust the starting CDS phase       if the original phase leads to a translation with an       in frame stop codon    B  for  V option  single exon transcripts are also checked on the       opposite strand    N  discard multi exon mRNAs that have any intron with a non canonical       splice site consensus  i e  not GT AG  GC AG or AT AC     J  discard any mRNAs that either lack initial START codon       or the terminal STOP codon  or have an in frame stop codon        only print mRNAs with a fulll  valid CDS      no pseudo  filter out records matching the  pseudo  keyword     M   merge   cluster the input transcripts into loci  collapsing matching        transcripts  those with the same exact introns and fully contained     d  dupinfo    for  M option  write collapsing info to file  dupinfo      cluster only  same as   merge but without collapsing matching transcripts    K  for  M option  also collapse shorter  fully contained transcripts       with fewer introns than the container    Q  for  M option  remove the containment restriction         multi exon transcripts will be collapsed if just their introns match        while single exon transcripts can partially overlap  80         force exons  make sure that the lowest level GFF features are printed as        exon  features    E  expose  warn about  duplicate transcript IDs and other potential       problems with the given GFF GTF records    D  decode url encoded characters within attributes    Z  merge close exons into a single exon  for intron size 4     w  write a fasta file with spliced exons for each GFF transcript    x  write a fasta file with spliced CDS for each GFF transcript    W  for  w and  x options  also write for each fasta record the exon       coordinates projected onto the spliced sequence    y  write a protein fasta file with the translation of CDS for each record    L  Ensembl GTF to GFF3 conversion  implies  F  should be used with  m     m   chr replace  is a reference  genomic  sequence replacement table with       this format         original ref ID   new ref ID        For example from UCSC naming to Ensembl naming        chr1 1       chr2 2       GFF records on reference sequences that are not found among the        original ref ID  entries in this file will be filtered out    o  the  filtered  GFF records will be written to  outfile gff         use  o  for printing to stdout     t  use  trackname  in the second column of each GFF output line    T   o option will output GTF format instead of GFF3       ,gffread,"gff3,gtf,tabular,fasta",gffread,"gff3,gtf,fasta,txt"
922,chart,,This tool creates a histogram image of sequence lengths distribution in a given fasta dataset file ,cshl_fasta_clipping_histogram,fasta,Length Distribution,png
923,formatter,,This tool re formats a FASTA file  changing the width of the nucleotides lines ,cshl_fasta_formatter,fasta,FASTA Width,fasta
924,converter,,This tool converts RNA FASTA files to DNA  and vice versa  ,cshl_fasta_nucleotides_changer,fasta,RNA/DNA,
925,,,Creates a boxplot graph for the quality scores in the library ,cshl_fastq_quality_boxplot,txt,Draw quality score boxplot,png
926,(ASCII-Numeric),,Converts a Solexa FASTQ file to from numeric or ASCII quality format ,cshl_fastq_quality_converter,fastq,Quality format converter,fastq
927,,,This tool filters reads based on quality scores ,cshl_fastq_quality_filter,"fastqsolexa,fastqsanger",Filter by quality,
928,converter from FASTX-toolkit,,This tool converts data from Solexa format to FASTA format  scroll down for format description  ,cshl_fastq_to_fasta,"fastqsanger,fastqsolexa,fastqillumina",FASTQ to FASTA,fasta
929,,,This tool filters sequencing artifacts  reads with all but 3 identical bases  ,cshl_fastx_artifacts_filter,"fasta,fastqsanger,fastqsolexa,fastqillumina",Remove sequencing artifacts,
930,,,This tool splits a Solexa library  FASTQ file  or a regular FASTA file into several files  using barcodes as the split criteria ,cshl_fastx_barcode_splitter,"txt,fasta,fastqsanger,fastqsolexa,fastqillumina",Barcode Splitter,html
931,adapter sequences,,This tool clips adapters from the 3  end of the sequences in a FASTA FASTQ file ,cshl_fastx_clipper,"fasta,fastqsanger,fastqsolexa,fastqillumina",Clip,
932,sequences,,This tool collapses identical sequences in a FASTA file into a single sequence ,cshl_fastx_collapser,"fasta,fastqsanger,fastqsolexa",Collapse,fasta
933,,,Creates a stacked histogram graph for the nucleotide distribution in the Solexa library ,cshl_fastx_nucleotides_distribution,txt,Draw nucleotides distribution chart,png
934,,,Creates quality statistics report for the given Solexa FASTQ library ,cshl_fastx_quality_statistics,fastqsanger,Compute quality statistics,txt
935,,,This tool renames the sequence identifiers in a FASTQ A file ,cshl_fastx_renamer,"fastqsolexa,fasta,fastqsanger",Rename sequences,
936,,,This tool reverse complements each sequence in a library  If the library is a FASTQ  the quality scores are also reversed ,cshl_fastx_reverse_complement,"fasta,fastqsolexa,fastqsanger",Reverse-Complement,
937,,,This tool trims  cut bases from  sequences in a FASTA Q file ,cshl_fastx_trimmer,"fasta,fastqsolexa,fastqsanger",Trim sequences,
938,into FASTQ,,This tool joins a FASTA file to a Quality Score file  creating a single FASTQ block for each read ,fastq_combiner,"fasta,csfasta,qual",Combine FASTA and QUAL,fastqsanger
939,reads by quality score and length,, This tool allows you to build complex filters to be applied to each read in a FASTQ file     Basic Options          You can specify a minimum and maximum read lengths        You can specify minimum and maximum per base quality scores  with optionally specifying the number of bases that are allowed to deviate from this range  default of 0 deviant bases         If your data is paired end  select the proper checkbox  this will cause each read to be internally split down the middle and filters applied to each half using the offsets specified     Advance Options          You can specify any number of advanced filters        5  and 3  offsets are defined  starting at zero  increasing from the respective end of the reads  For example  a quality string of  ABCDEFG   with 5  and 3  offsets of 1 and 1  respectively  specified will yield  BCDEF         You can specify either absolute offset values  or percentage offset values   Absolute Values  based offsets are useful for fixed length reads  e g  Illumina or SOLiD data    Percentage of Read Length  based offsets are useful for variable length reads  e g  454 data   When using the percent based method  offsets are rounded to the nearest integer        The user specifies the aggregating action  min  max  sum  mean  to perform on the quality score values found between the specified offsets to be used with the user defined comparison operation and comparison value        If a set of offsets is specified that causes the remaining quality score list to be of length zero  then the read will   pass   the quality filter unless the size range filter is used to remove these reads             class   warningmark  Adapter bases in color space reads are excluded from filtering      ,fastq_filter,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",Filter FASTQ,
940,convert between various FASTQ quality formats,,This tool offers several conversions options relating to the FASTQ format ,fastq_groomer,"fastq,fastq.gz,fastq.bz2",FASTQ Groomer,fastqsanger
941,reads on various attributes,, This tool allows you to build complex manipulations to be applied to each matching read in a FASTQ file  A read must match all matching directives in order for it to be manipulated  if a read does not match  it is output in a non modified manner  All reads matching will have each of the specified manipulations performed upon them  in the order specified   Regular Expression Matches are made using re search  see  for more information    All matching is performed on a single line string  regardless if e g  the sequence or quality score spans multiple lines in the original file   String translations are performed using string translate  see  string translate and  string maketrans for more information      class   warningmark  Only color space reads can have adapter bases substituted            Example    Suppose you have a color space sanger formatted sequence  fastqcssanger  and you want to double encode the color space into psuedo nucleotide space  this is different from converting  to allow these reads to be used in tools which do not natively support it  using specially designed indexes   This tool can handle this manipulation  however  this is generally not recommended as results tend to be poorer than those produced from tools which are specially designed to handle color space data   Steps   1  Click   Add new Match Reads   and leave the matching options set to the default  Matching by sequence name identifier using the regular expression        thereby matching all reads   2  Click   Add new Manipulate Reads    change   Manipulate Reads on   to  Sequence Content   set   Sequence Manipulation Type   to  Change Adapter Base  and set   New Adapter   to     an empty text field   3  Click   Add new Manipulate Reads    change   Manipulate Reads on   to  Sequence Content   set   Sequence Manipulation Type   to  String Translate  and set   From   to  0123   and   To   to  ACGTN   4  Click Execute  The new history item will contained double encoded psuedo nucleotide space reads      ,fastq_manipulation,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",Manipulate FASTQ,
942,by quality score,,This tool allows masking base characters in FASTQ format files dependent upon user specified quality score value and comparison method ,fastq_masker_by_quality,"fastqsanger,fastqsanger.gz,fastqsanger.bz2",FASTQ Masker,
943,on paired end reads,,De interlaces a single fastq dataset representing paired end run into two fastq datasets containing only the first or second mate read  Reads without mate are saved in separate output files ,fastq_paired_end_deinterlacer,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",FASTQ de-interlacer,
944,on paired end reads,,This tool joins paired end FASTQ reads from two separate files  one with the left mates and one with the right mates  into a single files where left mates alternate with their right mates  The join is performed using sequence identifiers  allowing the two files to contain differing ordering  If a sequence identifier does not appear in both files  it is included in a separate file ,fastq_paired_end_interlacer,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",FASTQ interlacer,
945,on paired end reads,,This tool joins paired end FASTQ reads from two separate files into a single read in one file   The join is performed using sequence identifiers  allowing the two files to contain differing ordering   If a sequence identifier does not appear in both files  it is excluded from the output ,fastq_paired_end_joiner,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",FASTQ joiner,
946,on joined paired end reads,,Splits a single fastq dataset representing paired end run into two datasets  one for each end   This tool works only for datasets where both ends have   the same   length ,fastq_paired_end_splitter,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",FASTQ splitter,
947,by column,,   What is does    This tool creates summary statistics on a FASTQ file      class   infomark    TIP    This statistics report can be used as input for the   Boxplot   tools            The output file will contain the following fields       column        column number  1 to 36 for a 36 cycles read Solexa file    count         number of bases found in this column    min           Lowest quality score value found in this column    max           Highest quality score value found in this column    sum           Sum of quality score values for this column    mean          Mean quality score value for this column    Q1            1st quartile quality score    med           Median quality score    Q3            3rd quartile quality score    IQR           Inter Quartile range  Q3 Q1     lW             Left Whisker  value  for boxplotting     rW             Right Whisker  value  for boxplotting     outliers      Scores falling beyond the left and right whiskers  comma separated list     A Count       Count of  A  nucleotides found in this column    C Count       Count of  C  nucleotides found in this column    G Count       Count of  G  nucleotides found in this column    T Count       Count of  T  nucleotides found in this column    N Count       Count of  N  nucleotides found in this column    Other Nucs    Comma separated list of other nucleotides found in this column    Other Count   Comma separated count of other nucleotides found in this column   For example       column   count   min max sum mean    Q1  med Q3  IQR lW  rW  outliers    A Count C Count G Count T Count N Count other bases other base count   1   14336356    2   33  450600675   31 4306281875   32 0    33 0    33 0    1 0 31  33  2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30    4482314 2199633 4425957 3208745 19707   2   14336356    2   34  441135033   30 7703737965   30 0    33 0    33 0    3 0 26  34  2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25   4419184 2170537 4627987 3118567 81   3   14336356    2   34  433659182   30 2489127642   29 0    32 0    33 0    4 0 23  34  2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22    4310988 2941988 3437467 3645784 129   4   14336356    2   34  433635331   30 2472490917   29 0    32 0    33 0    4 0 23  34  2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22    4110637 3007028 3671749 3546839 103   5   14336356    2   34  432498583   30 167957813    29 0    32 0    33 0    4 0 23  34  2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22    4348275 2935903 3293025 3759029 124            class   warningmark  Adapter bases in color space reads are excluded from statistics      ,fastq_stats,"fastqsanger,fastqillumina,fastqsolexa,fastqcssanger,fastqsanger.gz,fastqillumina.gz,fastqsolexa.gz,fastqcssanger.gz,fastqsanger.bz2,fastqillumina.bz2,fastqsolexa.bz2,fastqcssanger.bz2",FASTQ Summary Statistics,tabular
948,converter,,This tool converts FASTQ sequencing reads to a Tabular file ,fastq_to_tabular,"fastqsanger,fastqcssanger,fastqillumina,fastqsolexa,fastqsanger.gz,fastqcssanger.gz,fastqillumina.gz,fastqsolexa.gz,fastqsanger.bz2,fastqcssanger.bz2,fastqillumina.bz2,fastqsolexa.bz2",FASTQ to Tabular,tabular
949,by column,,   What is does    This tool allows you to trim the ends of reads   You can specify either absolute or percent based offsets  Offsets are calculated  starting at 0  from the respective end to be trimmed  When using the percent based method  offsets are rounded to the nearest integer   For example  if you have a read of length 36       Some FASTQ Sanger Read   CAATATGTNCTCACTGATAAGTGGATATNAGCNCCA             B   8 CBA  7 7BBCA4 48      B   And you set absolute offsets of 2 and 9       Some FASTQ Sanger Read   ATATGTNCTCACTGATAAGTGGATA           B   8 CBA  7 7BBCA4 4  Or you set percent offsets of 6  and 20   corresponds to absolute offsets of 2 7 for a read length of 36        Some FASTQ Sanger Read   ATATGTNCTCACTGATAAGTGGATATN           B   8 CBA  7 7BBCA4 48             class   warningmark  Trimming a color space read will cause any adapter base to be lost      ,fastq_trimmer,"fastqsanger,fastqcssanger,fastqsanger.gz,fastqcssanger.gz,fastqsanger.bz2,fastqcssanger.bz2",FASTQ Trimmer,
950,converter,,This tool converts FASTQ sequencing reads to FASTA sequences      ,fastq_to_fasta_python,"fastq,fastq.gz,fastq.bz2",FASTQ to FASTA,fasta
951,converter,,This tool attempts to convert a tabular file containing sequencing read data to a FASTQ formatted file  The FASTQ Groomer tool should always be used on the output of this tool      ,tabular_to_fastq,tabular,Tabular to FASTQ,fastq
952,- draw plots,,Create collapsed versions of the recal csv file and call R scripts to plot residual error versus the various covariates ,gatk_analyze_covariates,csv,Analyze Covariates,"html,txt"
953,on BAM files,,This walker is designed to work as the first pass in a two pass processing step  It does a by locus traversal operating only at sites that are not in dbSNP  We assume that all reference mismatches we see are therefore errors and indicative of poor base quality  This walker generates tables based on various user specified covariates  such as read group  reported quality score  cycle  and dinucleotide  Since there is a large amount of data one can then calculate an empirical probability of error given the particular covariates seen at this site  where p error    num mismatches   num observations The output file is a CSV list of  the several covariate values  num observations  num mismatches  empirical quality score  The first non comment line of the output file gives the name of the covariates that were used for this calculation   Note  ReadGroupCovariate and QualityScoreCovariate are required covariates and will be added for the user regardless of whether or not they were specified Note  This walker is designed to be used in conjunction with TableRecalibrationWalker ,gatk_count_covariates,"bam,fasta,vcf,gatk_dbsnp,bed",Count Covariates,"csv,txt"
954,on BAM files,,DepthOfCoverage processes a set of bam files to determine coverage at different levels of partitioning and aggregation  Coverage can be analyzed per locus  per interval  per gene  or in total  can be partitioned by sample  by read group  by technology  by center  or by library  and can be summarized by mean  median  quartiles  and or percentage of bases covered to or beyond a threshold  Additionally  reads and bases can be filtered by mapping or base quality score  ,gatk_depth_of_coverage,"bam,fasta,data",Depth of Coverage,tabular
955,- perform local realignment,,Performs local realignment of reads based on misalignments due to the presence of indels  Unlike most mappers  this walker uses the full alignment context to determine whether an appropriate alternate reference  i e  indel  exists and updates SAMRecords accordingly ,gatk_indel_realigner,"bam,fasta,gatk_interval,bed,picard_interval_list,vcf",Indel Realigner,"bam,txt"
956,from BAM files,,PrintReads can dynamically merge the contents of multiple input BAM files  resulting in merged output sorted in coordinate order ,gatk_print_reads,"bam,fasta,txt",Print Reads,"bam,txt"
957,for use in local realignment,,Emits intervals for the Local Indel Realigner to target for cleaning   Ignores 454 reads  MQ0 reads  and reads with consecutive indel operators in the CIGAR string ,gatk_realigner_target_creator,"bam,fasta,vcf",Realigner Target Creator,"gatk_interval,txt"
958,on BAM files,,This walker is designed to work as the second pass in a two pass processing step  doing a by read traversal   For each base in each read this walker calculates various user specified covariates  such as read group  reported quality score  cycle  and dinuc  Using these values as a key in a large hashmap the walker calculates an empirical base quality score and overwrites the quality score currently in the read  This walker then outputs a new bam file with these updated  recalibrated  reads   Note  This walker expects as input the recalibration table file generated previously by CovariateCounterWalker  Note  This walker is designed to be used in conjunction with CovariateCounterWalker ,gatk_table_recalibration,"csv,bam,fasta",Table Recalibration,"bam,txt"
959,SNP and indel caller,,A variant caller which unifies the approaches of several disparate callers   Works for single sample and multi sample data   The user can choose from several different incorporated calculation models ,gatk_unified_genotyper,"bam,fasta,vcf",Unified Genotyper,"vcf,txt"
960,,,Annotates variant calls with context information   Users can specify which of the available annotations to use ,gatk_variant_annotator,"vcf,bam,fasta",Variant Annotator,"vcf,txt"
961,,,Applies cuts to the input vcf file  by adding filter lines  to achieve the desired novel FDR levels which were specified during VariantRecalibration,gatk_variant_apply_recalibration,"vcf,gatk_recal,gatk_tranche,fasta",Apply Variant Recalibration,"vcf,txt"
962,,,Combines VCF records from different sources  supports both full merges and set unions  Merge  combines multiple records into a single one  if sample names overlap then they are uniquified  Union  assumes each rod represents the same set of samples  although this is not enforced   using the priority list  if provided   emits a single record instance at every position represented in the rods ,gatk_variant_combine,"vcf,fasta",Combine Variants,"vcf,txt"
963,,,General purpose tool for variant evaluation    in dbSNP  genotype concordance  Ti Tv ratios  and a lot more ,gatk_variant_eval,"vcf,fasta,bed,gatk_interval,picard_interval_list",Eval Variants,"gatk_report,txt"
964,on VCF files,,Filters variant calls using a number of user selectable  parameterizable criteria ,gatk_variant_filtration,"vcf,fasta,bed,gatk_dbsnp,vcf",Variant Filtration,"vcf,txt"
965,,,Takes variant calls as  vcf files  learns a Gaussian mixture model over the variant annotations and evaluates the variant    assigning an informative lod score,gatk_variant_recalibrator,"vcf,fasta",Variant Recalibrator,"gatk_recal,gatk_tranche,txt,pdf"
966,from VCF files,,Often  a VCF containing many samples and or variants will need to be subset in order to facilitate certain analyses  e g  comparing and contrasting cases vs  controls  extracting variant or non variant loci that meet certain requirements  displaying just a few samples in a browser like IGV  etc    SelectVariants can be used for this purpose  Given a single VCF file  one or more samples can be extracted from the file  based on a complete sample name or a pattern match   Variants can be further selected by specifying criteria for inclusion  i e   DP   1000   depth of coverage greater than 1000x    AF   0 25   sites with allele frequency less than 0 25   These JEXL expressions are documented in the Using JEXL expressions section   One can optionally include concordance or discordance tracks for use in selecting overlapping variants  ,gatk_variant_select,"vcf,fasta,txt",Select Variants,"vcf,txt"
967,,,Validates a variants file ,gatk_validate_variants,"vcf,fasta",Validate Variants,txt
968,of all intervals,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns   This operation counts the total bases covered by a set of intervals   Bases that are covered by more than one interval are   not   counted more than once towards the total    SCREENCASTS     Example       image   gops baseCoverage gif     ,gops_basecoverage_1,interval,Base Coverage,txt
969,the intervals of a dataset,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns    SCREENCASTS     Syntax        Maximum distance   is greatest distance in base pairs allowed between intervals that will be considered  quot clustered quot      Negative   values for distance are allowed  and are useful for clustering intervals that overlap      Minimum intervals per cluster   allow a threshold to be set on the minimum number of intervals to be considered a cluster   Any area with less than this minimum will not be included in the output      Merge clusters into single intervals   outputs intervals that span the entire cluster      Find cluster intervals  preserve comments and order   filters out non cluster intervals while maintaining the original ordering and comments in the file      Find cluster intervals  output grouped by clusters   filters out non cluster intervals  but outputs the cluster intervals so that they are grouped together  Comments and original ordering in the file are lost            Examples    Find Clusters      image   gops clusterFind gif  Merge Clusters      image   gops clusterMerge gif     ,gops_cluster_1,interval,Cluster,
970,intervals of a dataset,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns   This operation complements the regions of a set of intervals   Regions are returned that represent the empty space in the input interval    SCREENCASTS     Syntax        Genome wide complement   will complement all chromosomes of the genome   Leaving this option unchecked will only complement chromosomes present in the dataset            Example       image   gops complement gif     ,gops_complement_1,interval,Complement,
971,two datasets into one dataset,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu    it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns    SCREENCASTS     Syntax        Both datasets are exactly the same filetype   will preserve all extra fields in both files   Leaving this unchecked will force the second dataset to use the same column assignments for chrom  start  end and strand  but will fill extra fields with a period      In both cases  the output fields are truncated or padded with fields of periods to maintain a truly tabular output            Example       image   gops concatenate gif     ,gops_concat_1,interval,Concatenate,
972,of a set of intervals on second set of intervals,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu    it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns   Find the coverage of intervals in the first dataset on intervals in the second dataset   The coverage is added as two columns  the first being bases covered  and the second being the fraction of bases covered by that interval    SCREENCASTS     Example        if   First dataset   are genes           chr11 5203271 5204877 NM 000518 0         chr11 5210634 5212434 NM 000519 0         chr11 5226077 5227663 NM 000559 0         chr11 5226079 5232587 BC020719  0         chr11 5230996 5232587 NM 000184 0        and   Second dataset   are repeats           chr11      5203895 5203991 L1MA6     500          chr11      5204163 5204239 A rich    219          chr11      5211034 5211167  CATATA n 245          chr11      5211642 5211673 AT rich    24          chr11      5226551 5226606  CA n     303          chr11      5228782 5228825  TTTTTG n 208          chr11      5229045 5229121 L1PA11    440          chr11      5229133 5229319 MER41A   1106          chr11      5229374 5229485 L2        244          chr11      5229751 5230083 MLT1A     913          chr11      5231469 5231526  CA n     330        the Result is the coverage density of repeats in the genes           chr11 5203271 5204877 NM 000518 0   172   0 107098        chr11 5210634 5212434 NM 000519 0   164   0 091111        chr11 5226077 5227663 NM 000559 0    55   0 034678        chr11 5226079 5232587 BC020719  0   860   0 132145        chr11 5230996 5232587 NM 000184 0    57   0 035827      For example  the following line of output          chr11 5203271 5204877 NM 000518 0   172   0 107098     implies that 172 nucleotides accounting for 10 7  of the this interval  chr11 5203271 5204877  overlap with repetitive elements      ,gops_coverage_1,interval,Coverage,
973,for every interval,,For every interval in the   interval   dataset  this tool fetches the   closest non overlapping   upstream and   or downstream features from the   features   dataset ,flanking_features_1,"interval,gff",Fetch closest non-overlapping feature,
974,returns flanking region/s for every gene,, This tool finds the upstream and or downstream flanking region s  of all the selected regions in the input file     Note    Every line should contain at least 3 columns  Chromosome number  Start and Stop co ordinates  If any of these columns is missing or if start and stop co ordinates are not numerical  the tool may encounter exceptions and such lines are skipped as invalid  The number of invalid skipped lines is documented in the resulting history item as a  Data issue             Example 1      For the following dataset       chr22  1000  7000  NM 174568 0      running get flanks with Region  Around start  Offset   200  Flank length  300 and Location  Upstream will return    Red  Dataset positive strand  Blue  Flanks output          chr22  500  800  NM 174568 0       image   flanks ex1 gif    Example 2      For the following dataset       chr22  1000  7000  NM 028946 0      running get flanks with Region  Whole  Offset  200  Flank length  300 and Location  Downstream will return    Orange  Dataset negative strand  Magenta  Flanks output          chr22  500  800  NM 028946 0       image   flanks ex2 gif     ,get_flanks1,interval,Get flanks,
975,the intervals of two datasets,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns    SCREENCASTS     Syntax        Where overlap is at least   sets the minimum length  in base pairs  of overlap between elements of the two datasets     Overlapping Intervals   returns entire intervals from the first dataset  that overlap the second dataset   The returned intervals are completely unchanged  and this option only filters out intervals that do not overlap with the second dataset      Overlapping pieces of Intervals   returns intervals that indicate the exact base pair overlap between the first dataset and the second dataset   The intervals returned are from the first dataset  and all fields besides start and end are guaranteed to remain unchanged            Examples    Overlapping Intervals      image   gops intersectOverlappingIntervals gif  Overlapping Pieces of Intervals      image   gops intersectOverlappingPieces gif     ,gops_intersect_1,"interval,gff",Intersect,
976,the intervals of two datasets side-by-side,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns    SCREENCASTS     Syntax        Where overlap   specifies the minimum overlap between intervals that allows them to be joined      Return only records that are joined   returns only the records of the first dataset that join to a record in the second dataset  This is analogous to an INNER JOIN      Return all records of first dataset  fill null with  quot   quot     returns all intervals of the first dataset  and any intervals that do not join an interval from the second dataset are filled in with a period     This is analogous to a LEFT JOIN      Return all records of second dataset  fill null with  quot   quot     returns all intervals of the second dataset  and any intervals that do not join an interval from the first dataset are filled in with a period       Note that this may produce an invalid interval file  since a period    is not a valid chrom  start  end or strand        Return all records of both datasets  fill nulls with  quot   quot     returns all records from both datasets  and fills on either the right or left with periods    Note that this may produce an invalid interval file  since a period    is not a valid chrom  start  end or strand              Examples       image   gops joinRecordsList gif  Only records that are joined  inner join       image   gops joinInner gif  All records of first dataset      image   gops joinLeftOuter gif  All records of second dataset      image   gops joinRightOuter gif  All records of both datasets      image   gops joinFullOuter gif     ,gops_join_1,interval,Join,
977,the overlapping intervals of a dataset,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns    SCREENCASTS   This operation merges all overlapping intervals into single intervals     Example       image   gops merge gif     ,gops_merge_1,interval,Merge,
978,the intervals of two datasets,,    class   infomark    TIP    If your dataset does not appear in the pulldown menu  it means that it is not in interval format  Use  edit attributes  to set chromosome  start  end  and strand columns    SCREENCASTS     Syntax        Where overlap is at least   sets the minimum length  in base pairs  of overlap between elements of the two datasets      Intervals with no overlap   returns entire intervals from the first dataset that do not overlap the second dataset   The returned intervals are completely unchanged  and this option only filters out intervals that overlap with the second dataset      Non overlapping pieces of intervals   returns intervals from the first dataset that have the intervals from the second dataset removed   Any overlapping base pairs are removed from the range of the interval   All fields besides start and end are guaranteed to remain unchanged            Example    Intervals with no overlap      image   gops subtractOverlappingIntervals gif  Non overlapping pieces of intervals      image   gops subtractOverlappingPieces gif     ,gops_subtract_1,"interval,gff",Subtract,
979,from another dataset,,    class   infomark    TIP    This tool complements the tool in the   Operate on Genomic Intervals   tool set which subtracts the intervals of two datasets            Syntax    This tool subtracts an entire dataset from another dataset     Any text format is valid    If both dataset formats are tabular  you may restrict the subtraction to specific columns   contained in both datasets   and the resulting dataset will include only the columns specified    The begin column must be less than or equal to the end column   If it is not  begin column is switched with end column    If begin column is specified but end column is not  end column will default to begin column  and vice versa     All blank and comment lines are skipped and not included in the resulting dataset  comment lines are lines beginning with a   character     Duplicate lines are eliminated from both dataset prior to subtraction   If any duplicate lines were eliminated from the first dataset  the number is displayed in the resulting history item            Example    If this is the   First dataset        chr1            4225    19670   chr10           6       8   chr1            24417   24420   chr6 hla hap2   0       150   chr2            1       5   chr10           2       10   chr1            30      55   chrY            1       20   chr1            1225979 42287290   chr10           7       8  and this is the   Second dataset        chr1            4225    19670   chr10           6       8   chr1            24417   24420   chr6 hla hap2   0       150   chr2            1       5   chr1            30      55   chrY            1       20   chr1            1225979 42287290  Subtracting the   Second dataset   from the   First dataset    including all columns  will yield      chr10           7       8   chr10           2       10  Conversely  subtracting the   First dataset   from the   Second dataset    including all columns  will result in an empty dataset   Subtracting the   Second dataset   from the   First dataset    restricting to columns c1 and c2  will yield      chr10           7   chr10           2     ,subtract_query1,txt,Subtract Whole Dataset,
980,on tables,,This program implements arithmetic operations on tabular files data  The program takes three inputs ,tables_arithmetic_operations,tabular,Arithmetic Operations,tabular
981,human genes associated with disease terms,,This tool searches the disease term field of the DOLite mappings used by the FunDO project and returns a set of genes that  are associated with terms matching the specified pattern    This is the reverse of what FunDO s own server does  ,hgv_funDo,,FunDO,interval
982,visualization of genomic data with the Hilbert curve,,HilbertVis uses the Hilbert space filling curve to visualize the structure of position dependent data   It maps the traditional one dimensional line visualization onto a two dimensional square   For example  here is a diagram showing the path of a level 2 Hilbert curve ,hgv_hilbertvis,"interval,gff",HVIS,pdf
983,significant SNPs in case-control data,,This tool performs a basic analysis of bi allelic SNPs in case control data  using the R statistical environment and Fisher s exact test to identify SNPs with a significant difference in the allele frequencies between the two groups   R s  qvalue  package is used to correct for multiple testing ,hgv_snpFreq,"tabular,snp,ind",snpFreq,tabular
984,,,When performing metagenomic analyses it is often necessary to identify sequence reads corresponding to a particular taxonomic group  or  in other words  diagnostic of a particular taxonomic rank  This utility performs this analysis  It takes data generated by  Taxonomy manipulation  Fetch Taxonomic Ranks  as input and outputs either a list of sequence reads unique to a particular taxonomic rank  or a list of taxonomic ranks and the count of unique reads corresponding to each rank  ,find_diag_hits,taxonomy,Find diagnostic hits,tabular
985,,,Fetches taxonomic information for a list of GI numbers  sequences identifiers used by the National Center for Biotechnology Information ,Fetch Taxonomic Ranks,tabular,Fetch taxonomic representation,taxonomy
986,data to Galaxy taxonomy representation,,This tool is designed to translate results of the Kraken metagenomic classifier  see citations below  to the full representation of NCBI taxonomy  It does so by using Taxonomic ID field provided by Kraken  The output of this tool can be directly visualized by the Krona tool  It is based on  gb taxonomy tools  developed by ,Kraken2Tax,tabular,Convert Kraken,taxonomy
987,,,This tool identifies the lowest taxonomic rank for which a mategenomic sequencing read is diagnostic  It takes datasets produced by  Fetch Taxonomic Ranks  tool  aka Taxonomy format  as the input  ,lca1,taxonomy,Find lowest diagnostic rank,taxonomy
988,,,Suppose you have metagenomic samples from two different locations and have classified the reads unique to various taxa  Now you want to test if the number of reads that fall in a particular taxon in location 1 is different from those that fall in the same taxon in location 2   This utility performs this analysis  It assumes that the data comes from a Poisson process and calculates two Z scores  Z1 and Z2  based on the work by Shiue and Bain  1982  Z1  and Huffman  1984  Z2  ,poisson2test,tabular,Poisson two-sample test,tabular
989,,,Given taxonomy representation  produced by  Fetch taxonomic representation  tool  this utility produces a graphical representations of phylogenetic tree in PDF format ,Draw_phylogram,taxonomy,Draw phylogeny,pdf
990,,,Given taxonomy representation  produced by  Taxonomy manipulation  Fetch Taxonomic Ranks  tool  this utility computes a summary of all taxonomic ranks  ,t2t_report,taxonomy,Summarize taxonomy,tabular
991,a VCF dataset with custom filters,, Annotates VCF dataset with custom annotations  For example  if this format tag is used for allele frequency     FORMAT  ID FREQ Number 1 Type String Description  Variant allele frequency    you can add a filter for allele frequency using  FORMAT FREQ  as the tag name and the condition      desired allele freq    Please see the VCFtools  documentation    for help and further information           vcf annotate     ,vcftools_annotate,vcf,Annotate,vcf
992,multiple VCF datasets,,         Please see the VCFtools  documentation    for help and further information                       ,vcftools_compare,vcf,Compare,tabular
993,Apply VCF variants to a fasta file to create consensus sequence,,         Please see the VCFtools  documentation    for help and further information                       ,vcftools_consensus,"fasta,vcf",Consensus,fasta
994,multiple VCF datasets,,         Please see the VCFtools  documentation    for help and further information                       ,vcftools_isec,vcf,Intersect,vcf
995,multiple VCF datasets,,         Please see the VCFtools  documentation    for help and further information                       ,vcftools_merge,vcf,Merge,vcf
996,to get data from selected regions,,         Please see the VCFtools  documentation    for help and further information                       ,vcftools_slice,"vcf,bed",Slice VCF,vcf
997,columns from a VCF dataset,,         Please see the VCFtools  documentation    for help and further information                       ,vcftools_subset,vcf,Subset,vcf
998,stored locally,,,library_access1,,Access Libraries,
999,creates a bed or xbed file containing from text query,,User specifies delimiter  header information  and column assignments and the file will be converted to BED or xBED  ,BED File Converter1,tabular,BED File Converter,bed
1000,Ensembl server,,,biomart,,BioMart,tabular
1001,Test server,,,biomart_test,,BioMart,tabular
1002,rice mart,,,cbi_rice_mart,,CBI Rice Mart,tabular
1003,ENA SRA,,,ebi_sra_main,,EBI SRA,auto
1004,server,,,eupathdb,,EuPathDB,tabular
1005,server,,,modENCODEfly,,modENCODE fly,txt
1006,server,,,flymine,,Flymine,txt
1007,server,,,flymine_test,,Flymine test,txt
1008,,, At the moment this tool allows the following simple searches     by GI    51594135     by accession    CF622840     using text    human hbb1    this feature is experimental    ,genbank,,Connect to Genbank,fasta
1009, Central server,,,gramenemart,,GrameneMart,tabular
1010,HapMap Biomart,,,hapmapmart,,HapMapMart,tabular
1011,Human Hemoglobin Variants and Thalassemias,,,hbvar,,HbVar,auto
1012,(PSU prepared queries),,,Featured datasets4,,Featured datasets,bed
1013,server,,,metabolicmine,,metabolicMine,txt
1014,,,  This tool will allow you to obtain various genomic datasets for any completed Microbial Genome Project as listed at NCBI        NCBI    Current datasets available include   1  CDS   2  tRNA   3  rRNA   4  FASTA Sequences   5  GeneMark Annotations   6  GeneMarkHMM Annotations   7  Glimmer3 Annotations         Organisms in   bold   are available at the UCSC Browser    ,microbial_import1,,Get Microbial Data,bed
1015,server,,,modmine,,modENCODE modMine,txt
1016,server,,,mousemine,,MouseMine,txt
1017,server,,,ratmine,,Ratmine,txt
1018,table browser,,,ucsc_table_direct1,,UCSC Main,tabular
1019,table browser,,,ucsc_table_direct_archaea1,,UCSC Archaea,tabular
1020,table browser,,,ucsc_table_direct_test1,,UCSC Test,tabular
1021,"
    from your computer  
  ",,      Auto detect    The system will attempt to detect Axt  Fasta  Fastqsolexa  Gff  Gff3  Html  Lav  Maf  Tabular  Wiggle  Bed and Interval  Bed with headers  formats  If your file is not detected properly as one of the known formats  it most likely means that it has some format problems  e g   different number of columns on different rows   You can still coerce the system to set your data to the format you think it should be   You can also upload compressed files  which will automatically be decompressed             Ab1    A binary sequence file in  ab1  format with a   ab1  file extension   You must manually select this  File Format  when uploading the file            Axt    blastz pairwise alignment format   Each alignment block in an axt file contains three lines  a summary line and 2 sequence lines   Blocks are separated from one another by blank lines   The summary line contains chromosomal position and size information about the alignment  It consists of 9 required fields            Bam    A binary file compressed in the BGZF format with a   bam  file extension            Bed      Tab delimited format  tabular    Does not require header line   Contains 3 required fields       chrom   The name of the chromosome  e g  chr3  chrY  chr2 random  or contig  e g  ctgY1       chromStart   The starting position of the feature in the chromosome or contig  The first base in a chromosome is numbered 0      chromEnd   The ending position of the feature in the chromosome or contig  The chromEnd base is not included in the display of the feature  For example  the first 100 bases of a chromosome are defined as chromStart 0  chromEnd 100  and span the bases numbered 0 99     May contain 9 additional optional BED fields       name   Defines the name of the BED line  This label is displayed to the left of the BED line in the Genome Browser window when the track is open to full display mode or directly to the left of the item in pack mode      score   A score between 0 and 1000  If the track line useScore attribute is set to 1 for this annotation data set  the score value will determine the level of gray in which this feature is displayed  higher numbers   darker gray       strand   Defines the strand   either     or          thickStart   The starting position at which the feature is drawn thickly  for example  the start codon in gene displays       thickEnd   The ending position at which the feature is drawn thickly  for example  the stop codon in gene displays       itemRgb   An RGB value of the form R G B  e g  255 0 0   If the track line itemRgb attribute is set to  On   this RBG value will determine the display color of the data contained in this BED line  NOTE  It is recommended that a simple color scheme  eight colors or less  be used with this attribute to avoid overwhelming the color resources of the Genome Browser and your Internet browser      blockCount   The number of blocks  exons  in the BED line      blockSizes   A comma separated list of the block sizes  The number of items in this list should correspond to blockCount      blockStarts   A comma separated list of block starts  All of the blockStart positions should be calculated relative to chromStart  The number of items in this list should correspond to blockCount     Example        chr22 1000 5000 cloneA 960   1000 5000 0 2 567 488  0 3512     chr22 2000 6000 cloneB 900   2000 6000 0 2 433 399  0 3601           Fasta    A sequence in FASTA format consists of a single line description  followed by lines of sequence data   The first character of the description line is a greater than       symbol in the first column   All lines should be shorter than 80 characters         sequence1     atgcgtttgcgtgc     gtcggtttcgttgc      sequence2     tttcgtgcgtatag     tggcgcggtga           FastqSolexa    FastqSolexa is the Illumina  Solexa  variant of the Fastq format  which stores sequences and quality scores in a single file         seq1       GACAGCTTGGTTTTTAGTGAGTTGTTCCTTTCTTT        seq1       hhhhhhhhhhhhhhhhhhhhhhhhhhPW hhhhhh        seq2       GCAATGACGGCAGCAATAAACTCAACAGGTGCTGG        seq2       hhhhhhhhhhhhhhYhhahhhhWhAhFhSIJGChO      Or          seq1     GAATTGATCAGGACATAGGACAACTGTAGGCACCAT      seq1     40 40 40 40 35 40 40 40 25 40 40 26 40 9 33 11 40 35 17 40 40 33 40 7 9 15 3 22 15 30 11 17 9 4 9 4      seq2     GAGTTCTCGTCGCCTGTAGGCACCATCAATCGTATG      seq2     40 15 40 17 6 36 40 40 40 25 40 9 35 33 40 14 14 18 15 17 19 28 31 4 24 18 27 14 15 18 2 8 12 8 11 9               Gff    GFF lines have nine required fields that must be tab separated            Gff3    The GFF3 format addresses the most common extensions to GFF  while preserving backward compatibility with previous formats            Interval  Genomic Intervals       Tab delimited format  tabular    File must start with definition line in the following format  columns may be in any order           CHROM START END STRAND    CHROM   The name of the chromosome  e g  chr3  chrY  chr2 random  or contig  e g  ctgY1     START   The starting position of the feature in the chromosome or contig  The first base in a chromosome is numbered 0    END   The ending position of the feature in the chromosome or contig  The chromEnd base is not included in the display of the feature  For example  the first 100 bases of a chromosome are defined as chromStart 0  chromEnd 100  and span the bases numbered 0 99    STRAND   Defines the strand   either     or         Example         CHROM START END   STRAND NAME COMMENT     chr1   10    100          exon myExon     chrX   1000  10050        gene myGene           Lav    Lav is the primary output format for BLASTZ   The first line of a  lav file begins with   lav             MAF    TBA and multiz multiple alignment format   The first line of a  maf file begins with   maf  This word is followed by white space separated  variable value  pairs  There should be no white space surrounding the                Scf    A binary sequence file in  scf  format with a   scf  file extension   You must manually select this  File Format  when uploading the file            Sff    A binary file in  Standard Flowgram Format  with a   sff  file extension            Tabular  tab delimited     Any data in tab delimited format  tabular            Table  delimiter separated     Any delimiter separated tabular data  CSV or TSV             Wig    The wiggle format is line oriented   Wiggle data is preceded by a track definition line  which adds a number of options for controlling the default display of this track            Other text type    Any text file    ,upload1,,Upload File,
1022,server,,,modENCODEworm,,modENCODE worm,txt
1023,server,,,wormbase,,WormBase,txt
1024,test server,,,wormbase_test,,Wormbase,txt
1025,server,,,yeastmine,,YeastMine,txt
1026,server,,,zebrafishmine,,ZebrafishMine,txt
1027,interspecies conservation scores,,This tool adds a column that measures interspecies conservation at each SNP position  using conservation scores for primates pre computed by the phyloP program   PhyloP performs an exact P value computation under a continuous Markov substitution model ,hgv_add_scores,interval,phyloP,
1028,amino-acid changes caused by a set of SNPs,,This tool identifies which SNPs create amino acid changes in the specified  coding regions   The first input file contains the SNPs and must be an interval file  It needs the chromosome  start  and end position as well as the SNP   The  SNP can be given using ambiguous nucleotide symbols or a list of two to four alleles  separated by       Any other columns in the first input file will not be used but will be kept for the output   The second input file contains the genes to be used for defining the coding regions   This file must be a BED file with the first 12 columns standard BED columns   The output is the same as the first input file with several columns added  the name field from the line of the gene input file used  the amino acids  the codon number  the reference nucleotide that  changed in the amino acid  in the same strand as the gene   and the codons  that go with the amino acids  The amino acids are listed with the reference amino acid first  then a colon  and then the amino acids for the alleles   If a SNP is not in a coding region or is synonymous then it is not included in the output file ,hgv_codingSnps,interval,aaChanges,interval
1029,using coordinates from assembled/unassembled genomes,,This tool uses coordinate  strand  and build information to fetch genomic DNAs in FASTA or interval format ,Extract genomic DNA 1,"interval,gff,fasta",Extract Genomic DNA,
1030, between assemblies and genomes,,This tool is based on the LiftOver utility and Chain track from  the UC Santa Cruz Genome Browser    ,liftOver1,"interval,gff,gtf",Convert genome coordinates,
1031,as a new dataset,,This tool allows you to create a single genomic interval  The resulting history item will be in the BED format ,createInterval,,Create single interval,bed
1032,Converts an AXT formatted file to a concatenated FASTA alignment,,     class   warningmark    IMPORTANT    AXT formatted alignments will be phased out from Galaxy in the coming weeks  They will be replaced with pairwise MAF alignments  which are already available  To try pairwise MAF alignments use  Extract Pairwise MAF blocks  tool in  Fetch Sequences and Alignments  section               Syntax    This tool converts an AXT formatted file to the FASTA format  and concatenates the results in the same build       AXT format   The alignments are produced from Blastz  an alignment tool available from Webb Miller s lab at Penn State University  The lav format Blastz output  which does not include the sequence  was converted to AXT format with lavToAxt  Each alignment block in an AXT file contains three lines  a summary line and 2 sequence lines  Blocks are separated from one another by blank lines        FASTA format   a text based format for representing both nucleic and protein sequences  in which base pairs or proteins are represented using a single letter code       This format contains an one line header  It starts with a      symbol  The first word on this line is the name of the sequence  The rest of the line is a description of the sequence      The remaining lines contain the sequence itself      Blank lines in a FASTA file are ignored  and so are spaces or other gap symbols  dashes  underscores  periods  in a sequence      Fasta files containing multiple sequences are just the same  with one sequence listed right after another  This format is accepted for many multiple sequence alignment programs            Example      AXT format        0 chr19 3001012 3001075 chr11 70568380 70568443   3500     TCAGCTCATAAATCACCTCCTGCCACAAGCCTGGCCTGGTCCCAGGAGAGTGTCCAGGCTCAGA     TCTGTTCATAAACCACCTGCCATGACAAGCCTGGCCTGTTCCCAAGACAATGTCCAGGCTCAGA      1 chr19 3008279 3008357 chr11 70573976 70574054   3900     CACAATCTTCACATTGAGATCCTGAGTTGCTGATCAGAATGGAAGGCTGAGCTAAGATGAGCGACGAGGCAATGTCACA     CACAGTCTTCACATTGAGGTACCAAGTTGTGGATCAGAATGGAAAGCTAGGCTATGATGAGGGACAGTGCGCTGTCACA    Convert the above file to concatenated FASTA format         hg16     TCAGCTCATAAATCACCTCCTGCCACAAGCCTGGCCTGGTCCCAGGAGAGTGTCCAGGCTCAGACACAATCTTCACATTGAGATCCTGAGTTGCTGATCAGAATGGAAGGCTGAGCTAAGATGAGCGACGAGGCAATGTCACA      mm5     TCTGTTCATAAACCACCTGCCATGACAAGCCTGGCCTGTTCCCAAGACAATGTCCAGGCTCAGACACAGTCTTCACATTGAGGTACCAAGTTGTGGATCAGAATGGAAAGCTAGGCTATGATGAGGGACAGTGCGCTGTCACA    ,axt_to_concat_fasta,axt,AXT to concatenated FASTA,fasta
1033,Converts an AXT formatted file to FASTA format,,     class   warningmark    IMPORTANT    AXT formatted alignments will be phased out from Galaxy in the coming weeks  They will be replaced with pairwise MAF alignments  which are already available  To try pairwise MAF alignments use  Extract Pairwise MAF blocks  tool in  Fetch Sequences and Alignments  section                Syntax    This tool converts an AXT formatted file to the FASTA format       AXT format   The alignments are produced from Blastz  an alignment tool available from Webb Miller s lab at Penn State University  The lav format Blastz output  which does not include the sequence  was converted to AXT format with lavToAxt  Each alignment block in an AXT file contains three lines  a summary line and 2 sequence lines  Blocks are separated from one another by blank lines       FASTA format   a text based format for representing both nucleic and protein sequences  in which base pairs or proteins are represented using a single letter code       This format contains an one line header  It starts with a      symbol  The first word on this line is the name of the sequence  The rest of the line is a description of the sequence      The remaining lines contain the sequence itself      Blank lines in a FASTA file are ignored  and so are spaces or other gap symbols  dashes  underscores  periods  in a sequence      Fasta files containing multiple sequences are just the same  with one sequence listed right after another  This format is accepted for many multiple sequence alignment programs            Example      AXT format        0 chr19 3001012 3001075 chr11 70568380 70568443   3500     TCAGCTCATAAATCACCTCCTGCCACAAGCCTGGCCTGGTCCCAGGAGAGTGTCCAGGCTCAGA     TCTGTTCATAAACCACCTGCCATGACAAGCCTGGCCTGTTCCCAAGACAATGTCCAGGCTCAGA      1 chr19 3008279 3008357 chr11 70573976 70574054   3900     CACAATCTTCACATTGAGATCCTGAGTTGCTGATCAGAATGGAAGGCTGAGCTAAGATGAGCGACGAGGCAATGTCACA     CACAGTCTTCACATTGAGGTACCAAGTTGTGGATCAGAATGGAAAGCTAGGCTATGATGAGGGACAGTGCGCTGTCACA    Convert the above file to FASTA format         hg16 chr19    3001012 3001075 hg16 0     TCAGCTCATAAATCACCTCCTGCCACAAGCCTGGCCTGGTCCCAGGAGAGTGTCCAGGCTCAGA      mm5 chr11    70568380 70568443 mm5 0     TCTGTTCATAAACCACCTGCCATGACAAGCCTGGCCTGTTCCCAAGACAATGTCCAGGCTCAGA       hg16 chr19    3008279 3008357 hg16 1     CACAATCTTCACATTGAGATCCTGAGTTGCTGATCAGAATGGAAGGCTGAGCTAAGATGAGCGACGAGGCAATGTCACA      mm5 chr11    70573976 70574054 mm5 1     CACAGTCTTCACATTGAGGTACCAAGTTGTGGATCAGAATGGAAAGCTAGGCTATGATGAGGGACAGTGCGCTGTCACA    ,axt_to_fasta,axt,AXT to FASTA,fasta
1034,Converts an AXT formatted file to LAV format,,     class   warningmark    IMPORTANT    AXT formatted alignments will be phased out from Galaxy in the coming weeks  They will be replaced with pairwise MAF alignments  which are already available  To try pairwise MAF alignments use  Extract Pairwise MAF blocks  tool in  Fetch Sequences and Alignments  section                Syntax    This tool converts an AXT formatted file to the LAV format       AXT format   The alignments are produced from Blastz  an alignment tool available from Webb Miller s lab at Penn State University  The lav format Blastz output  which does not include the sequence  was converted to AXT format with lavToAxt  Each alignment block in an AXT file contains three lines  a summary line and 2 sequence lines  Blocks are separated from one another by blank lines       LAV format   LAV is an alignment format developed by Webb Miller s group  It is the primary output format for BLASTZ       FASTA format   a text based format for representing both nucleic and protein sequences  in which base pairs or proteins are represented using a single letter code       This format contains an one line header  It starts with a     symbol  The first word on this line is the name of the sequence  The rest of the line is a description of the sequence      The remaining lines contain the sequence itself      Blank lines in a FASTA file are ignored  and so are spaces or other gap symbols  dashes  underscores  periods  in a sequence      Fasta files containing multiple sequences are just the same  with one sequence listed right after another  This format is accepted for many multiple sequence alignment programs            Example      AXT format        0 chr19 3001012 3001075 chr11 70568380 70568443   3500     TCAGCTCATAAATCACCTCCTGCCACAAGCCTGGCCTGGTCCCAGGAGAGTGTCCAGGCTCAGA     TCTGTTCATAAACCACCTGCCATGACAAGCCTGGCCTGTTCCCAAGACAATGTCCAGGCTCAGA      1 chr19 3008279 3008357 chr11 70573976 70574054   3900     CACAATCTTCACATTGAGATCCTGAGTTGCTGATCAGAATGGAAGGCTGAGCTAAGATGAGCGACGAGGCAATGTCACA     CACAGTCTTCACATTGAGGTACCAAGTTGTGGATCAGAATGGAAAGCTAGGCTATGATGAGGGACAGTGCGCTGTCACA    Convert the above file to LAV format          lav     s           galaxy data hg16 seq chr19 nib  1 63811651 0 1         galaxy data mm5 seq chr11 nib   1 121648857 0 1           h            hg16 chr19           mm5 chr11  reverse complement             a         s 3500       b 3001012 70568380       e 3001075 70568443       l 3001012 70568380 3001075 70568443 81           a         s 3900       b 3008279 70573976       e 3008357 70574054       l 3008279 70573976 3008357 70574054 78             eof    With two files in the FASTA format         hg16 chr19   3001011 3001075     TCAGCTCATAAATCACCTCCTGCCACAAGCCTGGCCTGGTCCCAGGAGAGTGTCCAGGCTCAGA       hg16 chr19   3008278 3008357     CACAATCTTCACATTGAGATCCTGAGTTGCTGATCAGAATGGAAGGCTGAGCTAAGATGAGCGACGAGGCAATGTCACA     and           mm5 chr11   70568379 70568443     TCTGTTCATAAACCACCTGCCATGACAAGCCTGGCCTGTTCCCAAGACAATGTCCAGGCTCAGA       mm5 chr11   70573975 70574054     CACAGTCTTCACATTGAGGTACCAAGTTGTGGATCAGAATGGAAAGCTAGGCTATGATGAGGGACAGTGCGCTGTCACA   ,axt_to_lav_1,axt,AXT to LAV,"lav,fasta"
1035,converter,,This tool converts data from BED format to GFF format  scroll down for format description  ,bed2gff1,bed,BED-to-GFF,gff
1036,converter,,  This tool converts a   sorted   BED file into a bigBed file   Currently  the bedFields option to specify the number of non standard fields is not supported as an AutoSQL file must be provided  which is a format currently not supported by Galaxy   ,bed_to_bigBed,bed,BED-to-bigBed,bigbed
1037,tail-to-head,,Concatenates datasets,cat1,,Concatenate datasets,input
1038, of selected columns,,This tool selects specified columns from a dataset and converts the values of those columns to upper or lower case ,ChangeCase,txt,Change Case,tabular
1039,between two datasets,, This tool is based on UNIX shell command comm  It compares two datasets and returns similarities or differences  For example  if you have two datasets       a  1  b  2  c  3  and     a  1  f  6  h  8  Using this tool with   Lines unique to Dataset1   option will return     b  2  c  3  If you use   Lines shared between Dataset1 and Dataset2   option output will look like this     a  1  ,Comm1,tabular,Find Similarities and Differences,input
1040,to find common or distinct rows,,     class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    This tool finds lines in one dataset that HAVE or DO NOT HAVE a common field with another dataset            Example    If this is   First dataset        chr1 10 20 geneA    chr1 50 80 geneB   chr5 10 40 geneL  and this is   Second dataset        geneA tumor suppressor   geneB Foxp2   geneC Gnas1   geneE INK4a  Finding lines of the   First dataset   whose 4th column matches the 1st column of the   Second dataset   yields      chr1 10 20 geneA    chr1 50 80 geneB  Conversely  using option   Non Matching rows of First dataset   on the same fields will yield      chr5 10 40 geneL  ,comp1,tabular,Compare two Datasets,input
1041,consecutive characters,,This tool condenses all consecutive characters of a specified type ,Condense characters1,txt,Condense,input
1042,delimiters to TAB,,Converts all delimiters of a specified type into TABs  Consecutive delimiters can be condensed in a single TAB ,Convert characters1,txt,Convert,tabular
1043,columns from a table,,This tool selects  cuts out  specified columns from the dataset ,Cut1,txt,Cut,tabular
1044,a column from one Query against another Query,, This tool is based on UNIX command grep with option  f  It matches content of one query against another  For example  assume you have two queries   one that contains EST accession numbers and some other information      AA001229 12 12   A001501 7 7   AA001641 6 6   AA001842 6 6   AA002047 6 6   AA004638 3 3  and another that is a typical BED file describing genomic location of some ESTs      chr7 115443235 115443809 CA947954 exon 0 0 chr7 115443236 f 0     chr7 115443236 115443347 DB338189 exon 0 0 chr7 115443237 f 0     chr7 115443347 115443768 DB338189 exon 1 0 chr7 115443348 f 0     chr7 115443239 115443802 AA001842 exon 0 0 chr7 115443240 f 0     chr7 115443243 115443347 DB331869 exon 0 0 chr7 115443244 f 0     chr7 115443347 115443373 DB331869 exon 1 0 chr7 115443348 f 0    Using this tool you will be able to tell how many ESTs in Query1 are also preset in Query2 and will output this      chr7 115443239 115443802 AA001842 exon 0 0 chr7 115443240 f 0   if   Match   option is chosen   ,fileGrep1,tabular,Match,input
1045,to an existing dataset,,You can enter any value and it will be added as a new column to your dataset,addValue,tabular,Add column,input
1046,converter,,This tool converts data from GFF format to BED format  scroll down for format description  ,gff2bed1,gff,GFF-to-BED,bed
1047,lines that match an expression,,     class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    The select tool searches the data for lines containing or not containing a match to the given pattern  Regular Expression is introduced in this tool  A Regular Expression is a pattern describing a certain amount of text                                    are all special characters         can be used to  escape  a special character  allowing that special character to be searched for        A   matches the beginning of a string but not an internal line         d   matches a digit  same as  0 9         D   matches a non digit        s   matches a whitespace character        S   matches anything BUT a whitespace        t   matches a tab        w   matches an alphanumeric character        W   matches anything but an alphanumeric character                   groups a particular pattern        Z   matches the end of a string but not a internal line           n or n  or n m       specifies an expected number of repetitions of the preceding pattern          n    The preceding item is matched exactly n times         n     The preceding item is matched n or more times          n m    The preceding item is matched at least n times but not more than m times                      creates a character class  Within the brackets  single characters can be placed  A dash     may be used to indicate a range such as   a z            Matches any single character except a newline          The preceding item will be matched zero or more times          The preceding item is optional and matched at most once          The preceding item will be matched one or more times          has two meaning      matches the beginning of a line or string       indicates negation in a character class  For example         matches every character except the ones inside brackets          matches the end of a line or string           Separates alternate possibilities             Example         chr  0 9A Za z      would match lines that begin with chromosomes  such as lines in a BED format file       ACGT  1 5    would match at least 1  ACGT  and at most 5  ACGT  consecutively            0 9  1 3     0 9  3       would match a large integer that is properly separated with commas such as 23 078 651       abc   def    would match either  abc  or  def          W     would match any line that is a comment  ,Grep1,txt,Select,input
1048,converter,,This tool converts data from GTF format to BEDGraph format  scroll down for format description  ,gtf2bedgraph,gtf,GTF-to-BEDGraph,bedgraph
1049,lines from a dataset,,This tool outputs specified number of lines from the   beginning   of a dataset,Show beginning1,txt,Select first,input
1050,side by side on a specified field,,     class   warningmark    This tool will attempt to reuse the metadata from your first input    To change metadata assignments click on the  edit attributes  link of the history item generated by this tool      class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    This tool joins lines of two datasets on a common field  An empty string      is not a valid identifier  You may choose to include lines of your first input that do not join with your second input     Columns are referenced with a   number    For example    3   refers to the 3rd column of a tab delimited file            Example    Dataset1      chr1 10 20 geneA   chr1 50 80 geneB   chr5 10 40 geneL  Dataset2      geneA tumor supressor   geneB Foxp2   geneC Gnas1   geneE INK4a  Joining the 4th column of Dataset1 with the 1st column of Dataset2 will yield      chr1 10 20 geneA geneA tumor suppressor   chr1 50 80 geneB geneB Foxp2  Joining the 4th column of Dataset1 with the 1st column of Dataset2  while keeping all lines from Dataset1  will yield      chr1 10 20 geneA geneA tumor suppressor   chr1 50 80 geneB geneB Foxp2   chr5 10 40 geneL  ,join1,tabular,Join two Datasets,
1051,two datasets a specific column of which has the same value,,,joiner2,tabular,Relational join 2,input
1052,Converts a LAV formatted file to BED format,,    Syntax    This tool converts a LAV formatted file to the BED format       LAV format   LAV is an alignment format developed by Webb Miller s group at Penn State University  It is the primary output format for BLASTZ       BED format   Browser Extensible Data format was designed at UCSC for displaying data tracks in the Genome Browser            Example      Convert LAV format          lav     s           galaxy data hg16 seq chr19 nib  1 63811651 0 1         galaxy data mm5 seq chr11 nib  1 121648857 0 1           h            hg16 chr19           mm5 chr11  reverse complement             a         s 3500       b 3001012 70568380       e 3001075 70568443       l 3001012 70568380 3001075 70568443 81           a         s 3900       b 3008279 70573976       e 3008357 70574054       l 3008279 70573976 3008357 70574054 78             eof    To two BED formatted files        chr19 3001011 3001075 hg16 0 0       chr19 3008278 3008357 hg16 1 0       and          chr11 70568379 70568443 mm5 0 0       chr11 70573975 70574054 mm5 1 0     ,lav_to_bed1,lav,LAV to BED,bed
1053,together,,This tool merges columns together  Any number of valid columns can be merged in any order ,mergeCols1,tabular,Merge Columns,tabular
1054,two files side by side,,This tool merges two datasets side by side  If the first  left  dataset contains column assignments such as chromosome  start  end and strand  these will be preserved  However  if you would like to change column assignments  click the pencil icon in the history item ,Paste1,txt,Paste,
1055,from a file,,This tool selects N random lines from a file  with no repeats  and preserving ordering ,random_lines1,txt,Select random lines,input
1056,of a file,,This tool removes a specified number of lines from the beginning of a dataset ,Remove beginning1,txt,Remove beginning,input
1057,on a dataset,,This tool outputs Secure Hashes   Message Digests of a dataset using the user selected algorithms ,secure_hash_message_digest,data,Secure Hash / Message Digest,tabular
1058,,,This tool extracts data from the 454 Sequencer SFF format and creates three files containing the   Sequences  FASTA   Qualities  QUAL  and  Clippings  XML ,Sff_extractor,sff,SFF converter,"fastqsanger,xml,fasta,qual"
1059,data in ascending or descending order,,    class   infomark            TIP    If your data is not TAB delimited  use  Text Manipulation  Convert                    Syntax    This tool sorts the dataset on any number of columns in either ascending or descending order       Numerical sort   orders numbers by their magnitude  ignores all characters besides numbers  and evaluates a string of numbers to the value they signify      General numeric sort   orders numbers by their general numerical value  Unlike the numerical sort option  it can handle numbers in scientific notation too      Alphabetical sort   is a phonebook type sort based on the conventional order of letters in an alphabet  Each nth letter is compared with the nth letter of other words in the list  starting at the first letter of each word and advancing to the second  third  fourth  and so on  until the order is established  Therefore  in an alphabetical sort  2 comes after 100  1   2                     Examples    The list of numbers 4 17 3 5 collates to 3 4 5 17 by numerical sorting  while it collates to 17 3 4 5 by alphabetical sorting   Sorting the following        Q     d    7   II    jhu  45     A     kk   4   I     h    111     Pd    p    1   ktY   WS   113     A     g    10  H     ZZ   856     A     edf  4   tw    b    234     BBB   rt   10  H     ZZ   100     A     rew  10  d     b    1111     C     sd   19  YH    aa   10     Hah   c    23  ver   bb   467     MN    gtr  1   a     X    32     N     j    9   a     T    205     BBB   rrf  10  b     Z    134     odfr  ws   6   Weg   dew  201     C     f    3   WW    SW   34     A     jhg  4   I     b    345     Pd    gf   7   Gthe  de   567     rS    hty  90  YY    LOp  89     A     g    10  H     h    43     A     g    4   I     h    500  on columns 1  alphabetical   3  numerical   and 6  numerical  in ascending order will yield        A     kk   4   I     h    111     A     edf  4   tw    b    234     A     jhg  4   I     b    345     A     g    4   I     h    500     A     g    10  H     h    43     A     g    10  H     ZZ   856     A     rew  10  d     b    1111     BBB   rt   10  H     ZZ   100     BBB   rrf  10  b     Z    134     C     f    3   WW    SW   34     C     sd   19  YH    aa   10     Hah   c    23  ver   bb   467     MN    gtr  1   a     X    32     N     j    9   a     T    205     odfr  ws   6   Weg   dew  201     Pd    p    1   ktY   WS   113     Pd    gf   7   Gthe  de   567     Q     d    7   II    jhu  45     rS    hty  90  YY    LOp  89   Sorting the following        chr10  100  200  feature1  100 01         chr20  800  900  feature2  1 1            chr2   500  600  feature3  1000 1         chr1   300  400  feature4  1 1e 05        chr21  300  500  feature5  1 1e2          chr15  700  800  feature6  1 1e4       on column 5  numerical  in ascending order will yield        chr1   300  400  feature4  1 1e 05        chr15  700  800  feature6  1 1e4          chr20  800  900  feature2  1 1            chr21  300  500  feature5  1 1e2          chr10  100  200  feature1  100 01         chr2   500  600  feature3  1000 1      on column 5  general numeric  in ascending order will yield        chr1   300  400  feature4  1 1e 05        chr20  800  900  feature2  1 1            chr10  100  200  feature1  100 01         chr21  300  500  feature5  1 1e2          chr2   500  600  feature3  1000 1         chr15  700  800  feature6  1 1e4           ,sort1,tabular,Sort,input
1060,lines from a dataset,,This tool outputs specified number of lines from the   end   of a dataset,Show tail1,txt,Select last,input
1061,leading or trailing characters,,Trims specified number of characters from a dataset or its field  if dataset is tab delimited  ,trimmer,"tabular,txt",Trim,
1062,expander,,BED format can be used to represent a single gene in just one line  which contains the information about exons  coding sequence location  CDS   and positions of untranslated regions  UTRs    This tool  unpacks  this information by converting a single line describing a gene into a collection of lines representing individual exons  introns  UTRs  etc  ,gene2exon1,bed,Gene BED To Exon/Intron/Codon BED,bed
1063,expander,,    Syntax    This tool converts a UCSC gene bed format file to a list of bed format lines corresponding to requested features of each gene       BED format   Browser Extensible Data format was designed at UCSC for displaying data tracks in the Genome Browser  It has three required fields and twelve additional optional ones        The first three BED fields  required  are      1  chrom   The name of the chromosome  e g  chr1  chrY random       2  chromStart   The starting position in the chromosome   The first base in a chromosome is numbered 0       3  chromEnd   The ending position in the chromosome  plus 1  i e   a half open interval        The twelve additional BED fields  optional  are      4  name   The name of the BED line      5  score   A score between 0 and 1000      6  strand   Defines the strand   either     or          7  thickStart   The starting position where the feature is drawn thickly at the Genome Browser      8  thickEnd   The ending position where the feature is drawn thickly at the Genome Browser      9  reserved   This should always be set to zero     10  blockCount   The number of blocks  exons  in the BED line     11  blockSizes   A comma separated list of the block sizes  The number of items in this list should correspond to blockCount     12  blockStarts   A comma separated list of block starts  All of the blockStart positions should be calculated relative to chromStart  The number of items in this list should correspond to blockCount     13  expCount   The number of experiments     14  expIds   A comma separated list of experiment ids  The number of items in this list should correspond to expCount     15  expScores   A comma separated list of experiment scores  All of the expScores should be relative to expIds  The number of items in this list should correspond to expCount            Example      A UCSC gene bed format file        chr7 127475281 127491632 NM 000230 0   127486022 127488767 0 3 29 172 3225     0 10713 13126     chr7 127486011 127488900 D49487    0   127486022 127488767 0 2 155 490         0 2399    Converts the above file to a list of bed lines  which has the introns        chr7 127475311 127475993 NM 000230 0       chr7 127486167 127488406 NM 000230 0       chr7 127486167 127488409 D49487    0    ,gene2intron1,interval,Gene BED To Intron BED,bed
1064,Parse a UCSC Gene Table dump,, Read a table dump in the UCSC gene table format and create a BED file corresponding to the requested feature of each gene  ,ucsc_gene_table_to_intervals1,inverval,Gene Table To BED,bed
1065,occurrences of each record,,    class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    This tool counts occurrences of unique values in selected column s      If multiple columns are selected  counting is performed on each unique group of all values in the selected columns    The first column of the resulting dataset will be the count of unique values in the selected column s  and will be followed by each value            Example      Input file                chr1   10  100  gene1        chr1  105  200  gene2        chr1  205  300  gene3        chr2   10  100  gene4        chr2 1000 1900  gene5        chr3   15 1656  gene6        chr4   10 1765  gene7        chr4   10 1765  gene8    Counting unique values in column c1 will result in           3 chr1        2 chr2        1 chr3        2 chr4       Counting unique values in the grouping of columns c2 and c3 will result in           2    10    100        2    10    1765        1    1000  1900        1    105   200        1    15    1656        1    205   300  ,Count1,tabular,Count,tabular
1066,of a dataset,,This tool outputs counts of specified attributes  lines  words  characters  of a dataset  ,wc_gnu,txt,Line/Word/Character count,tabular
1067,converter,,   Syntax    This tool converts bedgraph or wiggle data into bigWig type       Wiggle format    The  wig format is line oriented  Wiggle data is preceded by a UCSC track definition line   Following the track definition line is the track data  which can be entered in three different formats described below         BED format   with no declaration line and four columns of data          chromA  chromStartA  chromEndA  dataValueA       chromB  chromStartB  chromEndB  dataValueB        variableStep   two column data  started by a declaration line and followed with chromosome positions and data values          variableStep  chrom chrN   span windowSize        chromStartA  dataValueA       chromStartB  dataValueB        fixedStep   single column data  started by a declaration line and followed with data values          fixedStep  chrom chrN  start position  step stepInterval   span windowSize        dataValue1       dataValue2    The   BedGraph format   is described in detail at the  UCSC Bioinformatics website        UCSC Bioinformatics website    ,wig_to_bigWig,"wig,bedgraph",Wig/BedGraph-to-bigWig,bigwig
1068,converter,,   Syntax    This tool converts wiggle data into interval type       Wiggle format    The  wig format is line oriented  Wiggle data is preceded by a UCSC track definition line   Following the track definition line is the track data  which can be entered in three different formats described below         BED format   with no declaration line and four columns of data          chromA  chromStartA  chromEndA  dataValueA       chromB  chromStartB  chromEndB  dataValueB        variableStep   two column data  started by a declaration line and followed with chromosome positions and data values          variableStep  chrom chrN   span windowSize        chromStartA  dataValueA       chromStartB  dataValueB        fixedStep   single column data  started by a declaration line and followed with data values          fixedStep  chrom chrN  start position  step stepInterval   span windowSize        dataValue1       dataValue2           Example      input wiggle format file         track type wiggle 0 name  Bed Format  description  BED format      chr19 59302000 59302300  1 0     chr19 59302300 59302600  0 75     chr19 59302600 59302900  0 50     chr19 59302900 59303200  0 25     chr19 59303200 59303500 0 0      track type wiggle 0 name  variableStep  description  variableStep format      variableStep chrom chr19 span 150     59304701 10 0     59304901 12 5     59305401 15 0     59305601 17 5      track type wiggle 0 name  fixedStep  description  fixed step  visibility full     fixedStep chrom chr19 start 59307401 step 300 span 200     1000     900     800     700     600    convert the above file to interval file        chr19 59302000 59302300    1 0     chr19 59302300 59302600    0 75     chr19 59302600 59302900    0 5     chr19 59302900 59303200    0 25     chr19 59303200 59303500   0 0     chr19 59304701 59304851   10 0     chr19 59304901 59305051   12 5     chr19 59305401 59305551   15 0     chr19 59305601 59305751   17 5     chr19 59307701 59307901   1000 0     chr19 59308001 59308201   900 0     chr19 59308301 59308501   800 0     chr19 59308601 59308801   700 0     chr19 59308901 59309101   600 0  ,wiggle2simple1,wig,Wiggle-to-Interval,interval
1069, - send data to GenomeSpace,, This Tool allows you to export data to GenomeSpace  Click the Browse button to select a file to export  The tool will automatically fetch your GenomeSpace token when you select a file from the export dialog   Alternatively  you can be logged in using your GenomeSpace OpenID  and the tool will use this ID if no token is entered  This allows you to simply paste the filepath into the location box and leave the token empty   You can associate your OpenID credentials under the User Preferences panel  Click here  to refresh your GenomeSpace token       here     static path     user openid auth openid provider genomespace auto associate True     ,genomespace_exporter,data,GenomeSpace Exporter,auto
1070, - receive data from GenomeSpace,, This tool allows you to import data from GenomeSpace  Click the Browse button to select a file to import  The tool will automatically fetch your GenomeSpace token when you select a file from the import dialog   Alternatively  you can be logged in using your GenomeSpace OpenID  and the tool will use this ID if no token is entered  This allows you to simply paste the filepath into the location box and leave the token empty   You can associate your OpenID credentials under the User Preferences panel  Click here  to refresh your GenomeSpace token         here     static path     user openid auth openid provider genomespace auto associate True     ,genomespace_importer,,GenomeSpace Importer,auto
1071, - Push data from GenomeSpace to Galaxy,, This tool is a variant of the genomespace importer which behaves like a data source and allows you to pull data from GenomeSpace  The URL parameter must contain a comma separated list of files to pull from GenomeSpace  The user must be logged into GenomeSpace through OpenID so that the authentication token can be obtained   You can associate your OpenID credentials under the User Preferences panel  Click here  to refresh your GenomeSpace token         here     static path     user openid auth openid provider genomespace auto associate True     ,genomespace_push,,GenomeSpace Push,auto
1072,given a set of coding exon intervals,,The coding sequence of genes are usually composed of several coding exons  Each of these coding exons is an individual genomic region  which when concatenated with each other constitutes the coding sequence  A single genomic region can be covered by multiple alignment blocks  In many cases it is desirable to stitch these alignment blocks together  This tool accepts a list of gene based intervals  in the Gene BED format  For every interval it performs the following ,GeneBed_Maf_Fasta2,"bed,maf",Stitch Gene blocks,fasta
1073,given a set of genomic intervals,,This tool takes genomic coordinates  superimposes them on multiple alignments  in MAF format  stored on the Galaxy site or from your history  and excises alignment blocks corresponding to each set of coordinates  Alignment blocks that extend past START and or END positions of an interval are trimmed  Note that a single genomic interval may correspond to two or more alignment blocks ,Interval2Maf1,"interval,maf",Extract MAF blocks,maf
1074,given a set of genomic intervals,,This tool takes genomic coordinates  superimposes them on pairwise alignments  in MAF format  stored on the Galaxy site  and excises alignment blocks corresponding to each set of coordinates  Alignment blocks that extend past START and or END positions of an interval are trimmed  Note that a single genomic interval may correspond to two or more alignment blocks ,Interval2Maf_pairwise1,interval,Extract Pairwise MAF blocks,maf
1075,given a set of genomic intervals,,A single genomic region can be covered by multiple alignment blocks  In many cases it is desirable to stitch these alignment blocks together  This tool accepts a list of genomic intervals  For every interval it performs the following ,Interval_Maf_Merged_Fasta2,"interval,maf",Stitch MAF blocks,fasta
1076,given a set of block numbers and a MAF file,,This tool takes a list of block numbers  one per line  and extracts the corresponding MAF blocks from the provided file  Block numbers start at 0      ,maf_by_block_number1,"txt,maf",Extract MAF by block number,maf
1077,by specified attributes,, This tool allows you to build complex filters to be applied to each alignment block of a MAF file  You can define restraints on species based upon chromosome and strand  You can specify comma separated lists of chromosomes where appropriate      class   infomark  For example  this tool is useful to restrict a set of alignments to only those blocks which contain alignments between chromosomes that are considered homologous             class   warningmark  If a species is not found in a particular block  all filters on that species are ignored          This tool allows the user to remove any undesired species from a MAF file  If no species are specified then all species will be kept  If species are specified  columns which contain only gaps are removed  The options for this are        Exclude blocks which have missing species     suppose you want to restrict an 8 way alignment to human  mouse  and rat   The tool will first remove all other species  Next  if this option is set to   YES   the tool WILL NOT return MAF blocks  which do not include human  mouse  or rat  This means that all alignment blocks returned by the tool will have exactly three sequences in this example        Exclude blocks which have only one species     if this option is set to   YES   all single sequence alignment blocks WILL NOT be returned          You can also provide a size range and limit your output to the MAF blocks which fall within the specified range      ,MAF_filter,maf,Filter MAF,maf
1078,by Size,,This tool takes a MAF file and a size range and extracts the MAF blocks which fall within the specified range      ,maf_limit_size1,maf,Filter MAF blocks,maf
1079,by Species,,   What It Does    This tool allows the user to remove any undesired species from a MAF file  Columns which contain only gaps are removed  The options for this tool are        Exclude blocks which have missing species     suppose you want to restrict an 8 way alignment to human  mouse  and rat   The tool will first remove all other species  Next  if this option is set to   YES   the tool WILL NOT return MAF blocks  which do not include human  mouse  or rat  This means that all alignment blocks returned by the tool will have exactly three sequences in this example        Exclude blocks with have only one species     if this option is set to   YES   all single sequence alignment blocks WILL NOT be returned      ,MAF_Limit_To_Species1,maf,Filter MAF blocks,maf
1080,a MAF file,,This tool takes a MAF file and creates a new MAF file  where each block has been reversed complemented ,MAF_Reverse_Complement_1,maf,Reverse Complement,maf
1081,by Species,,This tool examines each MAF block for multiple occurrences of a species in a single block  When this occurs  a block is split into multiple blocks where every combination of one sequence per species per block is represented ,MAF_split_blocks_by_species1,maf,Split MAF blocks,maf
1082,Alignment coverage information,,This tool takes a MAF file and an interval file and relates coverage information by interval for each species  If a column does not exist in the reference genome  it is not included in the output ,maf_stats1,"interval,maf",MAF Coverage Stats,interval
1083,by Species,,This tool allows the user to merge MAF blocks which are adjoining in each specified species from a MAF file  Columns which contain only gaps are removed  Species which are not desired are removed from the output ,MAF_Thread_For_Species1,maf,Join MAF blocks,maf
1084,Converts a MAF formatted file to the BED format,,This tool converts every MAF block to an interval line  in BED format  scroll down for description of MAF and BED formats  describing position of that alignment block within a corresponding genome ,MAF_To_BED1,maf,MAF to BED,bed
1085,Converts a MAF formatted file to FASTA format,,This tool converts MAF blocks to FASTA format and concatenates them into a single FASTA block or outputs multiple FASTA blocks separated by empty lines ,MAF_To_Fasta1,maf,MAF to FASTA,fasta
1086,Converts a MAF formatted file to the Interval format,,This tool converts every MAF block to a set of genomic intervals describing the position of that alignment block within a corresponding genome  Sequences from aligning species are also included in the output ,MAF_To_Interval1,maf,MAF to Interval,interval
1087,for display at UCSC,,This tool converts a Variant Call Format  VCF  file into a Multiple Alignment Format  MAF  custom track file suitable for display at genome browsers ,vcf_to_maf_customtrack1,tabular,VCF to MAF Custom Track,mafcustomtrack
1088,- Find Individual Motif Occurrences,,     class   warningmark    WARNING  This tool is only available for non commercial use  Use for educational  research and non profit purposes is permitted  Before using  be sure to review  agree  and comply with the license        class   infomark    To cite FIMO     Grant CE  Bailey TL  Noble WS  FIMO  scanning for occurrences of a given motif  Bioinformatics  2011 Apr 1 27 7  1017 8        For detailed information on FIMO  click here   To view the license              Citation    If you use this tool in Galaxy  please cite Blankenberg D  et al   In preparation         here       license      ,meme_fimo,"memexml,fasta,txt",FIMO,"html,tabular,cisml,interval"
1089,- Multiple Em for Motif Elicitation,,     class   warningmark    WARNING  This tool is only available for non commercial use  Use for educational  research and non profit purposes is permitted  Before using  be sure to review  agree  and comply with the license     If you want to specify sequence weights  you must include them at the top of your input FASTA file      class   infomark    To cite MEME    Timothy L  Bailey and Charles Elkan   Fitting a mixture model by expectation maximization to discover motifs in biopolymers   Proceedings of the Second International Conference on Intelligent Systems for Molecular Biology  pp  28 36  AAAI Press  Menlo Park  California  1994     For detailed information on MEME  click here   To view the license              Citation    If you use this tool in Galaxy  please cite Blankenberg D  et al   In preparation        here       license      ,meme_meme,"fasta,txt",MEME,"html,txt,memexml"
1090, compare sequencing reads against UCSC genome builds,,  seq1  TGGTAATGGTGGTTTTTTTTTTTTTTTTTTATTTTT,blat_wrapper,fasta,BLAT,tabular
1091,reads mapping against reference sequence ,,SHRiMP  SHort Read Mapping Package  is a software package for aligning genomic reads against a target genome ,shrimp_color_wrapper,"csfasta,fasta",SHRiMP for Color-space,tabular
1092,reads mapping against reference sequence ,,SHRiMP  SHort Read Mapping Package  is a software package for aligning genomic reads against a target genome ,shrimp_wrapper,"fastqsolexa,fasta",SHRiMP for Letter-space,tabular
1093,converts between FASTQ data and other data formats,,This tool offers several conversions options relating to the FASTQ format  ,fastq_conversions,"fastqsolexa,fastqsanger,fastqsolexa, fastqsanger",FASTQ Conversions,"fastqsanger,fastqsolexa,fasta"
1094,converts any FASTQ to Sanger,,Galaxy pipeline for mapping of Illumina data requires data to be in fastq format with quality values conforming to so called  Sanger  format  Unfortunately there are many other types of fastq  Thus the main objective of this tool is to  groom  multiple types of fastq into Sanger conforming fastq that can be used in downstream application such as mapping ,fastq_gen_conv,fastq,FASTQ Groomer,fastqsanger
1095,SOLiD output to fastq,,Converts output of SOLiD instrument  versions 3 5 and earlier  to fastq format suitable for bowtie  bwa  and PerM mappers ,solid2fastq,"csfasta,qualsolid",Convert,fastqcssanger
1096,converts SOLiD data to FASTQ data,,This tool takes reads and quality files and converts them to FASTQ data   Sanger variant    Any  1 qualities are converted to 1 before being converted to FASTQ  Note that it also converts sequences to base pairs ,solid_to_fastq,"csfasta,qualsolid",SOLiD-to-FASTQ,fastqsanger
1097,Illumina runs,,This tool simulates an Illumina run and provides plots of false positives and false negatives  It allows for a range of simulation parameters to be set  Note that this simulation sets only one  randomly chosen  position in the genome as polymorphic  according to the value specified  Superimposed on this are  sequencing errors   which are uniformly  and randomly  distributed  Polymorphisms are assigned using the detection threshold  so if the detection threshold is set to the same as the minor allele frequency  the expected false negative rate is 50  ,ngs_simulation,fasta,Simulate,"png,tabular"
1098,significant single- and multi-locus SNP associations in case-control studies,,BEAM  Bayesian Epistasis Association Mapping  uses a Markov Chain Monte Carlo  MCMC  method to infer SNP block structures and detect both single marker and interaction effects from case control SNP data  This tool also partitions SNPs into blocks based on linkage disequilibrium  LD    The method utilized is Bayesian  so the outputs are posterior probabilities of association  along with block partitions   An advantage of this method is that it provides uncertainty measures for the associations and block partitions  and it scales well from small to large sample sizes  It is powerful in detecting gene gene interactions  although slow for large datasets ,hgv_beam,lped,BEAM,tabular
1099,significant single-SNP associations in case-control studies,,GPASS  Genome wide Poisson Approximation for Statistical Significance  detects significant single SNP associations in case control studies at a user specified FDR   Unlike previous methods  this tool can accurately approximate the genome wide significance and FDR of SNP associations  while adjusting for millions of multiple comparisons  within seconds or minutes ,hgv_gpass,lped,GPASS,tabular
1100,linkage disequilibrium and tag SNPs,,This tool can be used to analyze the patterns of linkage disequilibrium  LD  between polymorphic sites in a locus   SNPs are grouped based on the threshold level of LD as measured by r   sup  2   regardless of genomic position   and a representative  tag SNP  is reported for each group  The other SNPs in the group are in LD with the tag SNP  but not necessarily with each other ,hgv_ldtools,tabular,LD,tabular
1101,functional annotation for a list of genes,,This tool creates a link to the Database for Annotation  Visualization  and Integrated Discovery  DAVID  website at NIH  sending a list of IDs from the selected column of a tabular Galaxy dataset   To follow the created link  click on the eye icon once the Galaxy tool has finished running ,hgv_david,tabular,DAVID,html
1102,tools for functional profiling of gene lists,,This tool creates a link to the g GOSt tool  Gene Group Functional Profiling   which is part of the g Profiler site at the University of Tartu in Estonia   g GOSt retrieves the most significant Gene Ontology  GO  terms  KEGG and REACTOME pathways  and TRANSFAC motifs for a user specified group of genes  proteins  or microarray probes  g GOSt also allows analysis of ranked or ordered lists of genes  visual browsing of GO graph structure  interactive visualization of retrieved results  and many other features   Multiple testing corrections are applied to extract only statistically important results ,hgv_linkToGProfile,tabular,g:Profiler,html
1103,LASSO-Patternsearch algorithm,,The LASSO Patternsearch algorithm fits your dataset to an L1 regularized logistic regression model   A benefit of using L1 regularization is that it typically yields a weight vector with relatively few non zero coefficients ,hgv_lps,tabular,LPS,"tabular,txt"
1104,Convert from MasterVar to gd_snp table,,This converts a Complete Genomics MasterVar file to gd snp format  so it can be used with the genome diversity tools  It can either  start a new dataset or append to an old one  When appending  if any new SNPs  appear only in the MasterVar file they can either be skipped or backfilled with    1   unknown  for previous individuals groups in the gd snp dataset   Positions homozygous for the reference are skipped ,master2gd_snp,"tab,gd_snp",MasterVar to gd_snp,gd_snp
1105,Convert from MasterVar to pgSnp format,,This converts a Complete Genomics MasterVar file to pgSnp format   so it can be viewed in browsers or used with the phenotype association and  interval operations tools  Positions homozygous for the reference are skipped ,master2pgSnp,tab,MasterVar to pgSnp,interval
1106,significant transcription factor binding sites from ChIP data,,PASS  Poisson Approximation for Statistical Significance  detects significant transcription factor binding sites in the genome from ChIP data   This is probably the only peak calling method that accurately controls the false positive rate and FDR in ChIP data  which is important given the huge discrepancy in results obtained from different peak calling algorithms   At the same time  this method achieves a similar or better power than previous methods ,hgv_pass,gff,PASS,tabular
1107,predictions of functional sites,,SIFT predicts whether an amino acid substitution affects protein function  based on sequence homology and the physical properties of amino acids  SIFT can be applied to naturally occurring non synonymous polymorphisms and laboratory induced missense mutations   This tool uses SQLite databases containing pre computed SIFT scores and annotations for all possible nucleotide substitutions at each position in the human exome   Allele frequency data are from the HapMap frequency database  and additional transcript and  gene level data are from Ensembl BioMart ,hgv_sift,tabular,SIFT,tabular
1108,for multiple columns,,This tool builds a bar chart on one or more columns  Suppose you have dataset like this one  ,barchart_gnuplot,tabular,Bar chart,png
1109,of quality statistics,,Creates a boxplot graph  Its main purpose is to display a distribution of quality scores produced by  NGS  QC and maniupulation    FASTQ Summary Statistics  tool ,qual_stats_boxplot,tabular,Boxplot,png
1110, ,,This tool maps SOLiD color space reads against the target genome using MAQ  It produces three output datasets  ,maq_cs_wrapper,"fasta,csfasta,qualsolid",MAQ for SOLiD,"tabular,customtrack"
1111,for SOLiD data,,Creates a boxplot graph for the quality scores in the library ,solid_qual_boxplot,txt,Draw quality score boxplot,png
1112,for SOLiD data,,Creates quality statistics report for the given SOLiD quality score file ,solid_qual_stats,qualsolid,Compute quality statistics,txt
1113,Velvet sequence assembler for very short reads,,   Velvet Overview    Velvet  is a de novo genomic assembler specially designed for short read sequencing technologies  such as Solexa or 454  developed by Daniel Zerbino and Ewan Birney at the European Bioinformatics Institute  EMBL EBI   near Cambridge  in the United Kingdom   Velvet currently takes in short read sequences  removes errors then produces high quality unique contigs  It then uses paired end read and long read information  when available  to retrieve the repeated areas between contigs   Read the Velvet  documentation    for details on using the Velvet Assembler        Velvet   zerbino velvet           zerbino velvet Manual pdf            Input formats    Velvet can input sequence files in the following formats  fasta fastq fasta gz fastq gz eland gerald  The input files are prepared for the velvet assembler using   velveth               Outputs      Contigs    The  contigs fa  file    This fasta file contains the sequences of the contigs longer than 2k  where k is the word length used in velveth  If you have specified a min contig length threshold  then the contigs shorter than that value are omitted  Note that the length and coverage information provided in the header of each contig should therefore be understood in k mers and in k mer coverage  cf  5 1  respectively  The N s in the sequence correspond to gaps between scaffolded contigs  The number of N s corresponds to the estimated length of the gap  For reasons of compatibility with the archives  any gap shorter than 10bp is represented by a sequence of 10 N s     Stats    The  stats txt  file    This file is a simple tabbed delimited description of the nodes  The column names are pretty much self explanatory  Note however that node lengths are given in k mers  To obtain the length in nucleotides of each node you simply need to add k   1  where k is the word length used in velveth  The in and out columns correspond to the number of arcs on the 5  and 3  ends of the contig respectively  The coverages in columns short1 cov  short1 Ocov  short2 cov  and short2 Ocov are provided in k mer coverage  5 1   Also  the difference between   cov and   Ocov is the way these values are computed  In the first count  slightly divergent sequences are added to the coverage tally  However  in the second  stricter count  only the sequences which map perfectly onto the consensus sequence are taken into account     LastGraph    The  LastGraph  file    This file describes in its entirety the graph produced by Velvet      AMOS afg    The  velvet asm afg  file    This file is mainly designed to be read by the open source AMOS genome assembly package  Nonetheless  a number of programs are available to transform this kind of file into other assembly file formats  namely ACE  TIGR  Arachne and Celera   See  for more information  The file describes all the contigs contained in the contigs fa file  cf 4 2 1              Velvet parameter list    This is a list of implemented Velvetg options      Standard options           cov cutoff  floating point auto   removal of low coverage nodes AFTER tour bus or allow the system to infer it                  default  no removal           ins length  integer               expected distance between two paired end reads  default  no read pairing           read trkg  yes no                 tracking of short read positions in assembly  default  no tracking           min contig lgth  integer          minimum contig length exported to contigs fa file  default  hash length   2           amos file  yes no                 export assembly to AMOS file  default  no export           exp cov  floating point auto      expected coverage of unique regions or allow the system to infer it                  default  no long or paired end read resolution        Advanced options           ins length2  integer              expected distance between two paired end reads in the second short read dataset  default  no read pairing           ins length long  integer          expected distance between two long paired end reads  default  no read pairing           ins length  sd  integer           est  standard deviation of respective dataset  default  10  of corresponding length                   replace     by nothing   2  or   long  as necessary           scaffolding  yes no               scaffolding of contigs used paired end information  default  on           max branch length  integer        maximum length in base pair of bubble  default  100           max divergence  floating point    maximum divergence rate between two branches in a bubble  default  0 2           max gap count  integer            maximum number of gaps allowed in the alignment of the two branches of a bubble  default  3           min pair count  integer           minimum number of paired end connections to justify the scaffolding of two long contigs  default  10           max coverage  floating point      removal of high coverage nodes AFTER tour bus  default  no removal           long mult cutoff  int             minimum number of long reads required to merge contigs  default  2           unused reads  yes no              export unused reads in UnusedReads fa file  default  no        Output          directory contigs fa               fasta file of contigs longer than twice hash length         directory stats txt                stats file  tab spaced  useful for determining appropriate coverage cutoff         directory LastGraph                special formatted file with all the information on the final graph         directory velvet asm afg            if requested  AMOS compatible assembly file    ,velvetg,velvet,velvetg,"txt,afg,fasta,tabular"
1114,Prepare a dataset for the Velvet velvetg Assembler,,   Velvet Overview    Velvet  is a de novo genomic assembler specially designed for short read sequencing technologies  such as Solexa or 454  developed by Daniel Zerbino and Ewan Birney at the European Bioinformatics Institute  EMBL EBI   near Cambridge  in the United Kingdom   Velvet currently takes in short read sequences  removes errors then produces high quality unique contigs  It then uses paired end read and long read information  when available  to retrieve the repeated areas between contigs   Read the Velvet  documentation    for details on using the Velvet Assembler       Velvet   zerbino velvet           zerbino velvet Manual pdf            Velveth    Velveth takes in a number of sequence files  produces a hashtable  then outputs two files in an output directory  creating it if necessary   Sequences and Roadmaps  which are necessary to velvetg             Hash Length    The hash length  also known as k mer length  corresponds to the length  in base pairs  of the words being hashed    The hash length is the length of the k mers being entered in the hash table  Firstly  you must observe three technical constraints      it must be an odd number  to avoid palindromes  If you put in an even number  Velvet will just decrement it and proceed    it must be below or equal to MAXKMERHASH length  cf  2 3 3  by default 31bp   because it is stored on 64 bits   it must be strictly inferior to read length  otherwise you simply will not observe any overlaps between reads  for obvious reasons   Now you still have quite a lot of possibilities  As is often the case  it s a trade  off between specificity and sensitivity  Longer kmers bring you more specificity  i e  less spurious overlaps  but lowers coverage  cf  below       so there s a sweet spot to be found with time and experience  We like to think in terms of  k mer coverage   i e  how many times has a k mer been seen among the reads  The relation between k mer coverage Ck and standard  nucleotide wise  coverage C is Ck   C    L   k   1  L where k is your hash length  and L you read length  Experience shows that this kmer coverage should be above 10 to start getting decent results  If Ck is above 20  you might be  wasting  coverage  Experience also shows that empirical tests with different values for k are not that costly to run     Input Files    Velvet works mainly with fasta and fastq formats  For paired end reads  the assumption is that each read is next to its mate read  In other words  if the reads are indexed from 0  then reads 0 and 1 are paired  2 and 3  4 and 5  etc   Supported file formats are      fasta   fastq    fasta gz    fastq gz    eland   gerald  Read categories are      short  default    shortPaired   short2  same as short  but for a separate insert size library    shortPaired2  see above    long  for Sanger  454 or even reference sequences    longPaired    ,velveth,"fasta,fastq,eland,gerald",velveth,velvet
1115,for SOLiD and Illumina,,PerM is a short read aligner designed to be ultrafast with long SOLiD reads to the whole genome or transcriptions  PerM can be fully sensitive to alignments with up to four mismatches and highly sensitive to a higher number of mismatches ,PerM,"fasta,fastqcssanger,fastqsanger",Map with PerM,"sam,fastqsanger,fastqcssanger"
1116,,,BFAST facilitates the fast and accurate mapping of short reads to reference sequences  Some advantages of BFAST include    Speed  enables billions of short reads to be mapped quickly    Accuracy  A priori probabilities for mapping reads with defined set of variants   An easy way to measurably tune accuracy at the expense of speed   Specifically  BFAST was designed to facilitate whole genome resequencing  where mapping billions of short reads with variants is of utmost importance ,bfast_wrapper,"fastqsanger,fastqcssanger,fasta,tabular,text",Map with BFAST,sam
1117,for Solexa file,,Creates quality statistics report for the given Solexa FASTQ library ,cshl_fastq_statistics,fastqsolexa,FASTQ Statistics,txt
1118,,, This tool uses Mosaik to align reads to a reference sequence    ,mosaik_wrapper,"fasta,fastq",Map with Mosaik,sam
1119,,,SRMA is a short read micro re aligner for next generation high throughput sequencing data ,srma_wrapper,"fasta,bam",Re-align with SRMA,bam
1120,"Appends the average, min, max of datapoints per interval",,    class   warningmark  This tool currently only has cached data for genome builds hg16  hg17 and hg18  However  you may use your own data point  wiggle  data  such as those available from UCSC  If you are trying to use your own data point file and it is not appearing as an option  make sure that the builds for your history items are the same      class   warningmark  This tool assumes that the input dataset is in interval format and contains at least a chrom column  a start column and an end column   These 3 columns can be dispersed throughout any number of other data columns             class   infomark    TIP    Computing summary information may throw exceptions if the data type  e g   string  integer  in every line of the columns is not appropriate for the computation  e g   attempting numerical calculations on strings    If an exception is thrown when computing summary information for a line  that line is skipped as invalid for the computation   The number of invalid skipped lines is documented in the resulting history item as a  Data issue             Syntax    This tool appends columns of summary information for each interval matched against a selected dataset   For each interval  the average  minimum and maximum for the data falling within the interval is computed     Several quantitative scores are provided for the ENCODE regions       Various Scores         Regulatory Potential         Neutral rate  Ancestral Repeats          GC fraction     Conservation Scores         PhastCons         binCons         GERP           Example    If your original data has the following format                                    other1 chrom start end other2                                   and you choose to aggregate phastCons scores  your output will look like this                                                other1 chrom start end other2 avg min max                                               where       avg     average phastCons score for each region     min     minimum phastCons score for each region     max     maximum phastCons score for each region   ,aggregate_scores_in_intervals2,"interval,wig",Aggregate datapoints,interval
1121,data on any column using simple expressions,,     class   warningmark  Double equal signs      must be used as   equal to    e g     c1     chr22         class   infomark    TIP    Attempting to apply a filtering condition may throw exceptions if the data type  e g   string  integer  in every line of the columns being filtered is not appropriate for the condition  e g   attempting certain numerical calculations on strings    If an exception is thrown when applying the condition to a line  that line is skipped as invalid for the filter condition   The number of invalid skipped lines is documented in the resulting history item as a  Condition data issue       class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    The filter tool allows you to restrict the dataset using simple conditional statements     Columns are referenced with   c   and a   number    For example    c1   refers to the first column of a tab delimited file   Make sure that multi character operators contain no white space   e g          is valid while         is not valid     When using  equal to  operator   double equal sign      must be used     e g     c1   chr1        Non numerical values must be included in single or double quotes   e g     c6            Filtering condition can include logical operators  but   make sure operators are all lower case     e g      c1   chrX  and c1   chrY   or not c6                    Example        c1   chr1    selects lines in which the first column is chr1     c3 c2 100 c4   selects lines where subtracting column 3 from column 2 is less than the value of column 4 times 100     len c2 split         4   will select lines where the second column has less than four comma separated elements     c2  1   selects lines in which the value of column 2 is greater than or equal to 1   Numbers should not contain commas     c2  44 554 350   will not work  but   c2  44554350   will   Some words in the data can be used  but must be single or double quoted   e g     c3   exon       ,Filter1,tabular,Filter,input
1122,data by a column and perform aggregate operation on other columns.,,     class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert            Syntax    This tool allows you to group the input dataset by a particular column and perform aggregate functions  Mean  Median  Mode  Sum  Max  Min  Count  Concatenate  and Randomly pick on any column s    The Concatenate function will take  for each group  each item in the specified column and build a comma delimited list  Concatenate Unique will do the same but will build a list of unique items with no repetition   Count and Count Unique are equivalent to Concatenate and Concatenate Unique  but will only count the number of items and will return an integer     If multiple modes are present  all are reported            Example      For the following input       chr22  1000  1003  TTT    chr22  2000  2003  aaa    chr10  2200  2203  TTT    chr10  1200  1203  ttt    chr22  1600  1603  AAA      Grouping on column 4   while ignoring case  and performing operation   Count on column 1   will return       AAA    2    TTT    3         Grouping on column 4   while not ignoring case  and performing operation   Count on column 1   will return       aaa    1    AAA    1    ttt    1    TTT    2   ,Grouping1,tabular,Group,tabular
1123,for any numerical column,The application of statistical methods to biological problems  Statistics and probability Biostatistics Probability Statistics ,     class   warningmark  This tool expects input datasets consisting of tab delimited columns  blank or comment lines beginning with a   character are automatically skipped       class   infomark    TIP    If your data is not TAB delimited  use  Text Manipulation  Convert delimiters to TAB      class   infomark    TIP    Computing summary statistics may throw exceptions if the data value in every line of the columns being summarized is not numerical   If a line is missing a value or contains a non numerical value in the column being summarized  that line is skipped and the value is not included in the statistical computation   The number of invalid skipped lines is documented in the resulting history item      class   infomark    USING R FUNCTIONS    Most functions  like  abs   take only a single expression   log  can take one or two parameters  like  log expression base    Currently  these R functions are supported   abs  sign  sqrt  floor  ceiling  trunc  round  signif  exp  log  cos  sin  tan  acos  asin  atan  cosh  sinh  tanh  acosh  asinh  atanh  lgamma  gamma  gammaCody  digamma  trigamma  cumsum  cumprod  cummax  cummin            Syntax    This tool computes basic summary statistics on a given column  or on a valid expression containing one or more columns     Columns are referenced with   c   and a   number    For example    c1   refers to the first column of a tab delimited file     For example         log c5    calculates the summary statistics for the natural log of column 5        c5   c6   c7    3   calculates the summary statistics on the average of columns 5 7       log c5 10    summary statistics of the base 10 log of column 5       sqrt c5 c9    summary statistics of the square root of column 5   column 9           Examples      Input Dataset        c1      c2      c3      c4      c5              c6     586     chrX    161416  170887  41108 at        16990     73      chrX    505078  532318  35073 at        1700     595     chrX    1361578 1388460 33665 s at      1960     74      chrX    1420620 1461919 1185 at         8600    Summary Statistics on column c6 of the above input dataset         sum       mean      stdev     0         25        50        75         100      29250 000  7312 500  7198 636  1700 000  1895 000  5280 000  10697 500  16990 000  ,Summary_Statistics1,tabular,Summary Statistics,tabular
1124,Pairwise Alignment Viewer,, You can use this tool to view a set of LAV alignments   You may include FASTA formatted sequences for both species   For detailed information on LAJ  click here        here    Laj is a tool for viewing and manipulating the output from pairwise alignment programs such as blastz  It can display interactive dotplot  pip  and text representations of the alignments  a diagram showing the locations of exons and repeats  and annotation links to other web sites containing additional information about particular regions      class   infomark    Note    If you save output from the applet  you will need to manually refresh your history     ,laj_1,"lav,fasta,txt",LAJ,laj
